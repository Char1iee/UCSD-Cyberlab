{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13a810e4-7de6-4410-ad4d-e5c9332208bf",
   "metadata": {},
   "source": [
    "## GET DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e674ea1-6f0f-4d83-a043-511f2994810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fdeb121-ee9c-4751-8e4f-21faccb22d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90f712d1-fd8f-493f-b2a8-befd029174a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the arrays from the .npz file\n",
    "data = np.load('data_arrays.npz')\n",
    "\n",
    "# Access the arrays\n",
    "x_train = data['X_train']\n",
    "x_test = data['X_test']\n",
    "x_val = data['X_val']\n",
    "y_train = data['y_train']\n",
    "y_test = data['y_test']\n",
    "y_val = data['y_val']\n",
    "X_combined = np.concatenate((x_train, x_test, x_val), axis=0)\n",
    "y_combined = np.concatenate((y_train, y_test, y_val), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b67b5ec-ddb9-488e-8546-7f93edc70b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.int64)\n",
    "X_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.int64)\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2e47f21-4c69-4ca6-a808-977f3d322272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.5436\n",
      "Epoch [2/20], Loss: 1.5936\n",
      "Epoch [3/20], Loss: 1.6436\n",
      "Epoch [4/20], Loss: 1.6686\n",
      "Epoch [5/20], Loss: 1.6436\n",
      "Epoch [6/20], Loss: 1.7436\n",
      "Epoch [7/20], Loss: 1.7686\n",
      "Epoch [8/20], Loss: 1.5186\n",
      "Epoch [9/20], Loss: 1.6436\n",
      "Epoch [10/20], Loss: 1.7936\n",
      "Epoch [11/20], Loss: 1.6436\n",
      "Epoch [12/20], Loss: 1.6186\n",
      "Epoch [13/20], Loss: 1.4686\n",
      "Epoch [14/20], Loss: 1.6936\n",
      "Epoch [15/20], Loss: 1.5936\n",
      "Epoch [16/20], Loss: 1.5936\n",
      "Epoch [17/20], Loss: 1.6686\n",
      "Epoch [18/20], Loss: 1.7686\n",
      "Epoch [19/20], Loss: 1.7936\n",
      "Epoch [20/20], Loss: 1.7686\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class DNNModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(DNNModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, 30)\n",
    "        self.fc3 = nn.Linear(30, 20)\n",
    "        self.fc4 = nn.Linear(20, output_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "# You need to know the input and output size used in your trained model\n",
    "input_size = 33\n",
    "output_size = 6\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "model = DNNModel(input_size, output_size).to(device)\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model.parameters(), lr=0.01)\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs.squeeze(), y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f446c5b3-3920-4855-8fac-835fd60470ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from a2pm import A2PMethod\n",
    "from a2pm.callbacks import BaseCallback, MetricCallback, TimeCallback\n",
    "from a2pm.patterns import BasePattern, CombinationPattern, IntervalPattern\n",
    "from a2pm.wrappers import BaseWrapper, KerasWrapper, SklearnWrapper, TorchWrapper\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34532d06-ddf7-43a8-9015-967ca007d3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_binary_columns(X_train):\n",
    "    binary_columns = []\n",
    "    for col in range(X_train.shape[1]):\n",
    "        unique_values = np.unique(X_train[:, col])\n",
    "        if set(unique_values).issubset({0, 1}):\n",
    "            binary_columns.append(col)\n",
    "    return binary_columns\n",
    "\n",
    "binary_columns = find_binary_columns(x_train)\n",
    "\n",
    "numerical_columns = []\n",
    "for i in range(0,32):\n",
    "    if i not in binary_columns:\n",
    "        numerical_columns.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "344f79bc-0ddf-44b6-841e-345d035684dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
    "# Assuming your model and TorchWrapper setup is correct and as provided previously\n",
    "dnn_classifier = TorchWrapper(model)\n",
    "\n",
    "\n",
    "pattern = (\n",
    "    {\n",
    "        \"type\": \"interval\",\n",
    "        \"features\": numerical_columns,\n",
    "        \"ratio\": 0.1,\n",
    "        \"max_ratio\": 0.3,\n",
    "        \"missing_value\": 0.0,\n",
    "        \"probability\": 0.6,\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"combination\",\n",
    "        \"features\": binary_columns,\n",
    "        \"probability\": 0.4,\n",
    "    },\n",
    ")\n",
    "method = A2PMethod(pattern)\n",
    "start_time = time.time()\n",
    "\n",
    "# Ensure tensors are on CPU and convert them to NumPy before passing to fit_generate\n",
    "X_tensor = torch.tensor(X_combined, dtype=torch.float32).to('cpu').numpy()\n",
    "y_tensor = torch.tensor(y_combined, dtype=torch.long).to('cpu').numpy()\n",
    "\n",
    "X_adversarial = method.fit_generate(dnn_classifier, X_tensor, y_tensor)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "if len(y_combined.shape) > 1 and y_combined.shape[1] > 1:\n",
    "    y_test_indices = np.argmax(y_combined, axis=1)\n",
    "else:\n",
    "    y_test_indices = y_combined\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "X_adversarial_tensor = torch.tensor(X_adversarial, dtype=torch.float32).to(device)\n",
    "# Disable gradient computation for inference\n",
    "with torch.no_grad():\n",
    "    preds = model(X_adversarial_tensor)\n",
    "\n",
    "# Convert model outputs to class indices if necessary\n",
    "preds_indices = torch.argmax(preds, dim=1)\n",
    "\n",
    "# Convert the indices back to CPU and numpy for use with sklearn metrics\n",
    "preds_indices_np = preds_indices.cpu().numpy()\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision_micro, recall_micro, fscore_micro, _ = precision_recall_fscore_support(\n",
    "    y_test_indices, preds_indices_np, average='micro')\n",
    "precision_macro, recall_macro, fscore_macro, _ = precision_recall_fscore_support(\n",
    "    y_test_indices, preds_indices_np, average='macro')\n",
    "\n",
    "# Calculate accuracy\n",
    "acc = np.mean(preds_indices_np == y_test_indices)\n",
    "\n",
    "# Compute the confusion matrix and derived metrics\n",
    "conf_matrix = confusion_matrix(y_test_indices, preds_indices_np)\n",
    "FP = conf_matrix.sum(axis=0) - np.diag(conf_matrix)\n",
    "FN = conf_matrix.sum(axis=1) - np.diag(conf_matrix)\n",
    "TP = np.diag(conf_matrix)\n",
    "TN = conf_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "TPR = TP / (TP + FN)  # True Positive Rate\n",
    "TNR = TN / (TN + FP)  # True Negative Rate\n",
    "FPR = FP / (FP + TN)  # False Positive Rate\n",
    "FNR = FN / (FN + TP)  # False Negative Rate\n",
    "\n",
    "# Calculate averages\n",
    "TPR_avg = np.mean(TPR)\n",
    "TNR_avg = np.mean(TNR)\n",
    "FPR_avg = np.mean(FPR)\n",
    "FNR_avg = np.mean(FNR)\n",
    "\n",
    "# Prepare a dictionary for the results\n",
    "result_dict = {\n",
    "    'Accuracy': acc,\n",
    "    'Micro Precision': precision_micro,\n",
    "    'Macro Precision': precision_macro,\n",
    "    'Micro Recall': recall_micro,\n",
    "    'Macro Recall': recall_macro,\n",
    "    'Micro F1 Score': fscore_micro,\n",
    "    'Macro F1 Score': fscore_macro,\n",
    "    'Average TNR': TNR_avg,\n",
    "    'Average FPR': FPR_avg,\n",
    "    'Average FNR': FNR_avg,\n",
    "    'Macro TNR': TNR_avg,\n",
    "    'Macro FNR': FNR_avg,\n",
    "    'Macro FPR': FPR_avg\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb93b90f-4a98-4899-a44e-846bde2b1c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.3935292624555805,\n",
       " 'Micro Precision': 0.3935292624555805,\n",
       " 'Macro Precision': 0.06558821040926342,\n",
       " 'Micro Recall': 0.3935292624555805,\n",
       " 'Macro Recall': 0.16666666666666666,\n",
       " 'Micro F1 Score': 0.39352926245558045,\n",
       " 'Macro F1 Score': 0.09413251974872554,\n",
       " 'Average TNR': 0.8333333333333334,\n",
       " 'Average FPR': 0.16666666666666666,\n",
       " 'Average FNR': 0.8333333333333334,\n",
       " 'Macro TNR': 0.8333333333333334,\n",
       " 'Macro FNR': 0.8333333333333334,\n",
       " 'Macro FPR': 0.16666666666666666}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0ddcc0e-ae76-4113-b843-3887546f430a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330936, 33)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_adversarial.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "525b934e-14be-4bc6-9757-4cd22dafd90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.defences.transformer.evasion import DefensiveDistillation\n",
    "# Initialize the ART classifier for the teacher model\n",
    "teacher_classifier = PyTorchClassifier(\n",
    "    model=model,\n",
    "    loss=criterion,\n",
    "    optimizer=optimizer,\n",
    "    input_shape=(input_size,),\n",
    "    nb_classes=output_size\n",
    ")\n",
    "\n",
    "\n",
    "# Define the student model\n",
    "student_model = DNNModel(input_size, output_size)\n",
    "\n",
    "# Define loss function and optimizer for the student model\n",
    "student_optimizer = optim.Adam(student_model.parameters(), lr=0.001)\n",
    "\n",
    "# Initialize the ART classifier for the student model\n",
    "student_classifier = PyTorchClassifier(\n",
    "    model=student_model,\n",
    "    loss=criterion,\n",
    "    optimizer=student_optimizer,\n",
    "    input_shape=(input_size,),\n",
    "    nb_classes=output_size\n",
    ")\n",
    "\n",
    "# Perform defensive distillation\n",
    "defensive_distillation = DefensiveDistillation(\n",
    "    classifier=teacher_classifier\n",
    ")\n",
    "student_classifier = defensive_distillation(X_adversarial, student_classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cb3abff-5d7a-48c9-af03-2807088d137e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.3935292624555805,\n",
       " 'Micro Precision': 0.3935292624555805,\n",
       " 'Macro Precision': 0.06558821040926342,\n",
       " 'Micro Recall': 0.3935292624555805,\n",
       " 'Macro Recall': 0.16666666666666666,\n",
       " 'Micro F1 Score': 0.39352926245558045,\n",
       " 'Macro F1 Score': 0.09413251974872554,\n",
       " 'Average TNR': 0.8333333333333334,\n",
       " 'Average FPR': 0.16666666666666666,\n",
       " 'Average FNR': 0.8333333333333334,\n",
       " 'Macro TNR': 0.8333333333333334,\n",
       " 'Macro FNR': 0.8333333333333334,\n",
       " 'Macro FPR': 0.16666666666666666}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "X_adversarial_tensor = torch.tensor(X_adversarial, dtype=torch.float32).to(device)\n",
    "# Disable gradient computation for inference\n",
    "preds_indices = student_classifier.predict(X_adversarial)\n",
    "\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision_micro, recall_micro, fscore_micro, _ = precision_recall_fscore_support(\n",
    "    y_test_indices, preds_indices_np, average='micro')\n",
    "precision_macro, recall_macro, fscore_macro, _ = precision_recall_fscore_support(\n",
    "    y_test_indices, preds_indices_np, average='macro')\n",
    "\n",
    "# Calculate accuracy\n",
    "acc = np.mean(preds_indices_np == y_test_indices)\n",
    "\n",
    "# Compute the confusion matrix and derived metrics\n",
    "conf_matrix = confusion_matrix(y_test_indices, preds_indices_np)\n",
    "FP = conf_matrix.sum(axis=0) - np.diag(conf_matrix)\n",
    "FN = conf_matrix.sum(axis=1) - np.diag(conf_matrix)\n",
    "TP = np.diag(conf_matrix)\n",
    "TN = conf_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "TPR = TP / (TP + FN)  # True Positive Rate\n",
    "TNR = TN / (TN + FP)  # True Negative Rate\n",
    "FPR = FP / (FP + TN)  # False Positive Rate\n",
    "FNR = FN / (FN + TP)  # False Negative Rate\n",
    "\n",
    "# Calculate averages\n",
    "TPR_avg = np.mean(TPR)\n",
    "TNR_avg = np.mean(TNR)\n",
    "FPR_avg = np.mean(FPR)\n",
    "FNR_avg = np.mean(FNR)\n",
    "\n",
    "# Prepare a dictionary for the results\n",
    "result_dict = {\n",
    "    'Accuracy': acc,\n",
    "    'Micro Precision': precision_micro,\n",
    "    'Macro Precision': precision_macro,\n",
    "    'Micro Recall': recall_micro,\n",
    "    'Macro Recall': recall_macro,\n",
    "    'Micro F1 Score': fscore_micro,\n",
    "    'Macro F1 Score': fscore_macro,\n",
    "    'Average TNR': TNR_avg,\n",
    "    'Average FPR': FPR_avg,\n",
    "    'Average FNR': FNR_avg,\n",
    "    'Macro TNR': TNR_avg,\n",
    "    'Macro FNR': FNR_avg,\n",
    "    'Macro FPR': FPR_avg\n",
    "}\n",
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2812424-b33d-4dbd-8268-a5b46d6daaba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
