{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5033146-a51e-4837-8c52-63d279a3719e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from art.attacks.evasion import SimBA, SpatialTransformation, DeepFool, BasicIterativeMethod, FastGradientMethod, ProjectedGradientDescent\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf5d70f2-0d73-4197-afcc-6b0826748c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.load('/home/jovyan/Wustl_iiot/x_test.npy')\n",
    "x_train = np.load('/home/jovyan/Wustl_iiot/x_train.npy')\n",
    "x_val = np.load('/home/jovyan/Wustl_iiot/x_val.npy')\n",
    "y_test = np.load('/home/jovyan/Wustl_iiot/y_test.npy')\n",
    "y_train = np.load('/home/jovyan/Wustl_iiot/y_train.npy')\n",
    "y_val = np.load('/home/jovyan/Wustl_iiot/y_val.npy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83b531ff-ca2b-4d0a-8f97-8602de5d4ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyperparameters\n",
    "epochs = 50\n",
    "training_batch_size = 128\n",
    "validation_batch_size = 128\n",
    "learning_rate = 0.01\n",
    "baseline_temperature = 1\n",
    "distilled_temperature = 100\n",
    "\n",
    "\n",
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "\n",
    "x_val_tensor = torch.tensor(x_val, dtype=torch.float32).to(device)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long).to(device)\n",
    "\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(x_val_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "\n",
    "input_shape = x_train.shape[1]\n",
    "output_shape = len(np.unique(y_train))\n",
    "\n",
    "class DNNModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(DNNModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, 30)\n",
    "        self.fc3 = nn.Linear(30, 20)\n",
    "        self.fc4 = nn.Linear(20, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# Initialize models\n",
    "teacher_model = DNNModel(input_shape, output_shape).to(device)\n",
    "student_model = DNNModel(input_shape, output_shape).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fca48ce-e435-4b70-8ef0-51d6ba296dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function for the teacher model\n",
    "def train_teacher_model(model, train_loader, epochs, temperature):\n",
    "    min_delta = 0.001\n",
    "    patience = 5\n",
    "    patience_counter = 0\n",
    "    best_loss = float('100000000')\n",
    "\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    train_loss = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs / temperature, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        \n",
    "        model.eval()\n",
    "        val_train_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_train_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "    \n",
    "        avg_val_loss = val_train_loss / len(val_loader)\n",
    "        val_accuracy = correct_predictions / len(val_dataset)\n",
    "    \n",
    "        print(f\"Epoch {epoch+1}, Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    \n",
    "        # Early stopping check using min_delta\n",
    "        if best_loss - avg_val_loss > min_delta:\n",
    "            best_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "    \n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "    torch.save(model.state_dict(), 'teacher_model.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8d6cb94-44c9-4639-b78b-c07ecf5c06b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 0.0000, Validation Loss: 0.0007, Validation Accuracy: 0.9999\n",
      "Epoch 2, Training Loss: 0.0000, Validation Loss: 0.0006, Validation Accuracy: 0.9999\n",
      "Epoch 3, Training Loss: 0.0000, Validation Loss: 0.0005, Validation Accuracy: 0.9999\n",
      "Epoch 4, Training Loss: 0.0000, Validation Loss: 0.0003, Validation Accuracy: 0.9999\n",
      "Epoch 5, Training Loss: 0.0000, Validation Loss: 0.0004, Validation Accuracy: 0.9999\n",
      "Epoch 6, Training Loss: 0.0000, Validation Loss: 0.0008, Validation Accuracy: 0.9999\n",
      "Early stopping triggered\n"
     ]
    }
   ],
   "source": [
    "# Train the teacher model\n",
    "train_teacher_model(teacher_model, train_loader, epochs, baseline_temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fe75af1-670e-4616-bd84-fc328f39b63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distillation loss function\n",
    "def distillation_loss(student_outputs, teacher_outputs, temperature, alpha):\n",
    "    soft_targets = F.softmax(teacher_outputs / temperature, dim=1)\n",
    "    student_log_probs = F.log_softmax(student_outputs / temperature, dim=1)\n",
    "    distillation_loss = nn.KLDivLoss()(student_log_probs, soft_targets) * (temperature ** 2)\n",
    "    return distillation_loss\n",
    "\n",
    "# Training function for the student model using distillation\n",
    "def train_student_model(student_model, teacher_model, train_loader, epochs, temperature, alpha=0.5):\n",
    "    min_delta = 0.001\n",
    "    patience = 5\n",
    "    patience_counter = 0\n",
    "    best_loss = float('100000000')\n",
    "    \n",
    "    student_model.train()\n",
    "    teacher_model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(student_model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    train_loss = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            teacher_outputs = teacher_model(inputs).detach()\n",
    "            student_outputs = student_model(inputs)\n",
    "            loss = distillation_loss(student_outputs, teacher_outputs, temperature, alpha) + criterion(student_outputs, labels) * (1. - alpha)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        \n",
    "        student_model.eval()\n",
    "        val_train_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                teacher_outputs = teacher_model(inputs).detach()\n",
    "                student_outputs = student_model(inputs)\n",
    "                loss = distillation_loss(student_outputs, teacher_outputs, temperature, alpha) + criterion(student_outputs, labels) * (1. - alpha)\n",
    "                val_train_loss += loss.item()\n",
    "                _, predicted = torch.max(student_outputs.data, 1)\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "    \n",
    "        avg_val_loss = val_train_loss / len(val_loader)\n",
    "        val_accuracy = correct_predictions / len(val_dataset)\n",
    "    \n",
    "        print(f\"Epoch {epoch+1}, Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    \n",
    "        # Early stopping check using min_delta\n",
    "        if best_loss - avg_val_loss > min_delta:\n",
    "            best_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "    \n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "    torch.save(student_model.state_dict(), 'student_model.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2a9de13-2bd6-4537-bf9f-f2bddb8f6023",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/nn/functional.py:2943: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 0.0000, Validation Loss: 0.0023, Validation Accuracy: 0.9999\n",
      "Epoch 2, Training Loss: 0.0000, Validation Loss: 0.0012, Validation Accuracy: 0.9999\n",
      "Epoch 3, Training Loss: 0.0000, Validation Loss: 0.0012, Validation Accuracy: 0.9999\n",
      "Epoch 4, Training Loss: 0.0000, Validation Loss: 0.0011, Validation Accuracy: 0.9999\n",
      "Epoch 5, Training Loss: 0.0000, Validation Loss: 0.0083, Validation Accuracy: 0.9999\n",
      "Epoch 6, Training Loss: 0.0000, Validation Loss: 0.0008, Validation Accuracy: 0.9999\n",
      "Epoch 7, Training Loss: 0.0000, Validation Loss: 0.0011, Validation Accuracy: 0.9999\n",
      "Early stopping triggered\n"
     ]
    }
   ],
   "source": [
    "# Train the student model\n",
    "train_student_model(student_model, teacher_model, train_loader, epochs, distilled_temperature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5c70d87-0e0f-4a4e-8c3e-a8d4de364a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_performance_metrics(X_test, y_true, model, model_name, attack_name, eps):\n",
    "    model.eval()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    probabilities = []\n",
    "\n",
    "    num_classes = len(np.unique(y_true))\n",
    "    \n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    test_loader = DataLoader(dataset=test_dataset)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            probabilities.extend(torch.nn.functional.softmax(outputs, dim=1).cpu().numpy())\n",
    "        \n",
    "        all_preds = np.array(all_preds)\n",
    "        all_labels = np.array(all_labels)\n",
    "        probabilities = np.array(probabilities)\n",
    "        \n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "        precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(all_labels, all_preds, average='macro')\n",
    "        precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "        # macro_auc = roc_auc_score(label_binarize(all_labels, classes=range(num_classes)), probabilities[:,1], average='macro')\n",
    "        # weighted_auc = roc_auc_score(label_binarize(all_labels, classes=range(num_classes)), probabilities[:,1], average='weighted')\n",
    "\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "        def calculate_class_metrics_macro(cm, class_index):\n",
    "            TP = cm[class_index, class_index]\n",
    "            FP = cm[:, class_index].sum() - TP\n",
    "            FN = cm[class_index, :].sum() - TP\n",
    "            TN = cm.sum() - (TP + FP + FN)\n",
    "            \n",
    "            TPR = TP / (TP + FN) if (TP + FN) != 0 else 0  \n",
    "            TNR = TN / (TN + FP) if (TN + FP) != 0 else 0  \n",
    "            FPR = FP / (FP + TN) if (FP + TN) != 0 else 0  \n",
    "            FNR = FN / (FN + TP) if (FN + TP) != 0 else 0  \n",
    "            \n",
    "            return TPR, TNR, FPR, FNR\n",
    "            \n",
    "        metrics = np.array([calculate_class_metrics_macro(cm, i) for i in range(num_classes)])\n",
    "        TPR_macro, TNR_macro, FPR_macro, FNR_macro = np.mean(metrics, axis=0)\n",
    "\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        \n",
    "        print(\"\\nmacro\")\n",
    "        print(f\"Precision: {precision_macro}\\nRecall: {recall_macro}\\nF1 Score: {f1_macro}\")\n",
    "    \n",
    "        print(\"\\nweighted\")\n",
    "        print(f\"Precision: {precision_weighted}\\nRecall: {recall_weighted}\\nF1 Score: {f1_weighted}\")\n",
    "        print()\n",
    "        \n",
    "        print(f\"Mean FNR: {FNR_macro}\\nMean TNR: {TNR_macro}\\nMean FPR: {FPR_macro}\\nMean TPR: {TPR_macro}\")\n",
    "\n",
    "        new_row = {\n",
    "            \"model\" : model_name,\n",
    "            \"attack_model\" : attack_name,\n",
    "            'epsilon': eps,\n",
    "            'Accuracy': accuracy,\n",
    "            'Macro Precision': precision_macro,\n",
    "            'Weighted Precision': precision_weighted,\n",
    "            'Macro Recall': recall_macro,\n",
    "            'Weighted Recall': recall_weighted,\n",
    "            'Macro F1': f1_macro,\n",
    "            'Weighted F1': f1_weighted,\n",
    "            # 'Macro AUC': macro_auc,\n",
    "            # 'Weighted AUC': weighted_auc,\n",
    "            'TPR': TPR_macro,\n",
    "            'FNR': FNR_macro,\n",
    "            'TNR': TNR_macro,\n",
    "            'FPR': FPR_macro,\n",
    "        }\n",
    "        new_row_df = pd.DataFrame([new_row])\n",
    "        new_row_df.to_csv(\"/home/jovyan/A2PM/def_distillation.csv\", mode='a', index=False, header=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "262ce9e9-ff34-44e0-a0e1-5aaba05d0b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9998952892738521\n",
      "\n",
      "macro\n",
      "Precision: 0.9545933311218772\n",
      "Recall: 0.9054552902183112\n",
      "F1 Score: 0.9215962548192097\n",
      "\n",
      "weighted\n",
      "Precision: 0.9999020543434537\n",
      "Recall: 0.9998952892738521\n",
      "F1 Score: 0.9998910456831952\n",
      "\n",
      "Mean FNR: 0.0945447097816888\n",
      "Mean TNR: 0.9999789326313706\n",
      "Mean FPR: 2.106736862934945e-05\n",
      "Mean TPR: 0.9054552902183112\n"
     ]
    }
   ],
   "source": [
    "calculate_performance_metrics(x_test, y_test, student_model, 'DNN', 'DD_Baseline', '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9814807-09fa-4aa6-9633-70314c5a22c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start BIM\n",
      "Accuracy: 0.9997863901186582\n",
      "\n",
      "macro\n",
      "Precision: 0.8879544696453074\n",
      "Recall: 0.8904269929215953\n",
      "F1 Score: 0.8778257814500092\n",
      "\n",
      "weighted\n",
      "Precision: 0.9998332492654327\n",
      "Recall: 0.9997863901186582\n",
      "F1 Score: 0.9997984450638658\n",
      "\n",
      "Mean FNR: 0.10957300707840471\n",
      "Mean TNR: 0.9999571481609871\n",
      "Mean FPR: 4.285183901281716e-05\n",
      "Mean TPR: 0.8904269929215953\n",
      "Accuracy: 0.803390952155575\n",
      "\n",
      "macro\n",
      "Precision: 0.3893695282438201\n",
      "Recall: 0.4113589608945848\n",
      "F1 Score: 0.24353203745987848\n",
      "\n",
      "weighted\n",
      "Precision: 0.9582247552124776\n",
      "Recall: 0.803390952155575\n",
      "F1 Score: 0.8570938630147998\n",
      "\n",
      "Mean FNR: 0.5886410391054151\n",
      "Mean TNR: 0.8955812034287713\n",
      "Mean FPR: 0.10441879657122848\n",
      "Mean TPR: 0.4113589608945848\n",
      "Accuracy: 0.005897308096652188\n",
      "\n",
      "macro\n",
      "Precision: 0.03303886264716427\n",
      "Recall: 0.05507291315541676\n",
      "F1 Score: 0.025042406711314184\n",
      "\n",
      "weighted\n",
      "Precision: 0.07761370647461702\n",
      "Recall: 0.005897308096652188\n",
      "F1 Score: 0.010690252601538162\n",
      "\n",
      "Mean FNR: 0.9449270868445833\n",
      "Mean TNR: 0.6429913911256616\n",
      "Mean FPR: 0.3570086088743385\n",
      "Mean TPR: 0.05507291315541676\n",
      "Accuracy: 0.002224055823382324\n",
      "\n",
      "macro\n",
      "Precision: 0.009126444949713288\n",
      "Recall: 0.03859152693308346\n",
      "F1 Score: 0.0041487131163618195\n",
      "\n",
      "weighted\n",
      "Precision: 0.031525316703838444\n",
      "Recall: 0.002224055823382324\n",
      "F1 Score: 0.004098858464044737\n",
      "\n",
      "Mean FNR: 0.9614084730669166\n",
      "Mean TNR: 0.6414667928371489\n",
      "Mean FPR: 0.3585332071628511\n",
      "Mean TPR: 0.03859152693308346\n",
      "start FGSM\n",
      "Accuracy: 0.9998408396962551\n",
      "\n",
      "macro\n",
      "Precision: 0.924433068741606\n",
      "Recall: 0.891787485531089\n",
      "F1 Score: 0.8985042746458515\n",
      "\n",
      "weighted\n",
      "Precision: 0.9998581197160482\n",
      "Recall: 0.9998408396962551\n",
      "F1 Score: 0.999840582126759\n",
      "\n",
      "Mean FNR: 0.10821251446891098\n",
      "Mean TNR: 0.9999679174930977\n",
      "Mean FPR: 3.208250690228508e-05\n",
      "Mean TPR: 0.891787485531089\n",
      "Accuracy: 0.02346776794427714\n",
      "\n",
      "macro\n",
      "Precision: 0.1427621158860072\n",
      "Recall: 0.28047328034752045\n",
      "F1 Score: 0.039419768056360924\n",
      "\n",
      "weighted\n",
      "Precision: 0.37230249209704386\n",
      "Recall: 0.02346776794427714\n",
      "F1 Score: 0.04220225786520546\n",
      "\n",
      "Mean FNR: 0.7195267196524795\n",
      "Mean TNR: 0.7188968393860595\n",
      "Mean FPR: 0.2811031606139405\n",
      "Mean TPR: 0.28047328034752045\n",
      "Accuracy: 0.006169555984636842\n",
      "\n",
      "macro\n",
      "Precision: 0.02875522293388482\n",
      "Recall: 0.2238358200728129\n",
      "F1 Score: 0.012862258521857614\n",
      "\n",
      "weighted\n",
      "Precision: 0.09124974705103418\n",
      "Recall: 0.006169555984636842\n",
      "F1 Score: 0.011174445401144529\n",
      "\n",
      "Mean FNR: 0.7761641799271871\n",
      "Mean TNR: 0.6620899265341813\n",
      "Mean FPR: 0.3379100734658187\n",
      "Mean TPR: 0.2238358200728129\n",
      "Accuracy: 0.005947569245203201\n",
      "\n",
      "macro\n",
      "Precision: 0.024582552244734802\n",
      "Recall: 0.1333170419881809\n",
      "F1 Score: 0.006707918286058617\n",
      "\n",
      "weighted\n",
      "Precision: 0.08421263003581013\n",
      "Recall: 0.005947569245203201\n",
      "F1 Score: 0.01086495213187847\n",
      "\n",
      "Mean FNR: 0.8666829580118192\n",
      "Mean TNR: 0.65235878398133\n",
      "Mean FPR: 0.34764121601867\n",
      "Mean TPR: 0.1333170419881809\n",
      "start PGD\n",
      "Accuracy: 0.9997863901186582\n",
      "\n",
      "macro\n",
      "Precision: 0.8879544696453074\n",
      "Recall: 0.8904269929215953\n",
      "F1 Score: 0.8778257814500092\n",
      "\n",
      "weighted\n",
      "Precision: 0.9998332492654327\n",
      "Recall: 0.9997863901186582\n",
      "F1 Score: 0.9997984450638658\n",
      "\n",
      "Mean FNR: 0.10957300707840471\n",
      "Mean TNR: 0.9999571481609871\n",
      "Mean FPR: 4.285183901281716e-05\n",
      "Mean TPR: 0.8904269929215953\n",
      "Accuracy: 0.803390952155575\n",
      "\n",
      "macro\n",
      "Precision: 0.3893695282438201\n",
      "Recall: 0.4113589608945848\n",
      "F1 Score: 0.24353203745987848\n",
      "\n",
      "weighted\n",
      "Precision: 0.9582247552124776\n",
      "Recall: 0.803390952155575\n",
      "F1 Score: 0.8570938630147998\n",
      "\n",
      "Mean FNR: 0.5886410391054151\n",
      "Mean TNR: 0.8955812034287713\n",
      "Mean FPR: 0.10441879657122848\n",
      "Mean TPR: 0.4113589608945848\n",
      "Accuracy: 0.005897308096652188\n",
      "\n",
      "macro\n",
      "Precision: 0.03303886264716427\n",
      "Recall: 0.05507291315541676\n",
      "F1 Score: 0.025042406711314184\n",
      "\n",
      "weighted\n",
      "Precision: 0.07761370647461702\n",
      "Recall: 0.005897308096652188\n",
      "F1 Score: 0.010690252601538162\n",
      "\n",
      "Mean FNR: 0.9449270868445833\n",
      "Mean TNR: 0.6429913911256616\n",
      "Mean FPR: 0.3570086088743385\n",
      "Mean TPR: 0.05507291315541676\n",
      "Accuracy: 0.002224055823382324\n",
      "\n",
      "macro\n",
      "Precision: 0.009126444949713288\n",
      "Recall: 0.03859152693308346\n",
      "F1 Score: 0.0041487131163618195\n",
      "\n",
      "weighted\n",
      "Precision: 0.031525316703838444\n",
      "Recall: 0.002224055823382324\n",
      "F1 Score: 0.004098858464044737\n",
      "\n",
      "Mean FNR: 0.9614084730669166\n",
      "Mean TNR: 0.6414667928371489\n",
      "Mean FPR: 0.3585332071628511\n",
      "Mean TPR: 0.03859152693308346\n",
      "start DF\n",
      "Accuracy: 0.0013067898623263373\n",
      "\n",
      "macro\n",
      "Precision: 0.011096773490702528\n",
      "Recall: 0.08287633218520955\n",
      "F1 Score: 0.012772583907692547\n",
      "\n",
      "weighted\n",
      "Precision: 0.00018583400111096487\n",
      "Recall: 0.0013067898623263373\n",
      "F1 Score: 0.00018382994835552304\n",
      "\n",
      "Mean FNR: 0.9171236678147905\n",
      "Mean TNR: 0.6737951412040591\n",
      "Mean FPR: 0.32620485879594086\n",
      "Mean TPR: 0.08287633218520955\n",
      "Accuracy: 0.0005905684954744024\n",
      "\n",
      "macro\n",
      "Precision: 0.013981246005273654\n",
      "Recall: 0.0806925635880574\n",
      "F1 Score: 0.013566430797945903\n",
      "\n",
      "weighted\n",
      "Precision: 0.000138141640983987\n",
      "Recall: 0.0005905684954744024\n",
      "F1 Score: 9.001376214149128e-05\n",
      "\n",
      "Mean FNR: 0.9193074364119426\n",
      "Mean TNR: 0.6734701822536936\n",
      "Mean FPR: 0.32652981774630635\n",
      "Mean TPR: 0.0806925635880574\n",
      "Accuracy: 9.63338680561082e-05\n",
      "\n",
      "macro\n",
      "Precision: 0.006149690391907812\n",
      "Recall: 0.07918563555025648\n",
      "F1 Score: 0.009443580415393197\n",
      "\n",
      "weighted\n",
      "Precision: 9.435200181838365e-05\n",
      "Recall: 9.63338680561082e-05\n",
      "F1 Score: 2.016199086385581e-05\n",
      "\n",
      "Mean FNR: 0.9208143644497435\n",
      "Mean TNR: 0.673030812691859\n",
      "Mean FPR: 0.326969187308141\n",
      "Mean TPR: 0.07918563555025648\n",
      "Accuracy: 7.539172282651946e-05\n",
      "\n",
      "macro\n",
      "Precision: 0.012539205741616866\n",
      "Recall: 0.07912178266729883\n",
      "F1 Score: 0.01318210572944246\n",
      "\n",
      "weighted\n",
      "Precision: 9.958821465457391e-05\n",
      "Recall: 7.539172282651946e-05\n",
      "F1 Score: 2.1423802999923518e-05\n",
      "\n",
      "Mean FNR: 0.9208782173327013\n",
      "Mean TNR: 0.6727387062717052\n",
      "Mean FPR: 0.3272612937282949\n",
      "Mean TPR: 0.07912178266729883\n"
     ]
    }
   ],
   "source": [
    "epsilon_values = [0.01, 0.1, 0.2, 0.3]\n",
    "\n",
    "# Iterate over epsilon values\n",
    "print(\"start BIM\")\n",
    "for epsilon in epsilon_values:\n",
    "    filename = f'/home/jovyan/Wustl_iiot/transfer_attack/x_test_adv_BIM_eps_{epsilon}.npy'\n",
    "    x_test_adv = np.load(filename)\n",
    "\n",
    "    calculate_performance_metrics(x_test_adv, y_test, student_model, 'DNN', 'DD_BIM', epsilon)\n",
    "\n",
    "print(\"start FGSM\")\n",
    "for epsilon in epsilon_values:\n",
    "    filename = f'/home/jovyan/Wustl_iiot/transfer_attack/x_test_adv_FGSM_eps_{epsilon}.npy'\n",
    "    x_test_adv = np.load(filename)\n",
    "\n",
    "    calculate_performance_metrics(x_test_adv, y_test, student_model, 'DNN', 'DD_FGSM', epsilon)\n",
    "\n",
    "print(\"start PGD\")\n",
    "for epsilon in epsilon_values:\n",
    "    filename = f'/home/jovyan/Wustl_iiot/transfer_attack/x_test_adv_PGD_eps_{epsilon}.npy'\n",
    "    x_test_adv = np.load(filename)\n",
    "\n",
    "    calculate_performance_metrics(x_test_adv, y_test, student_model, 'DNN', 'DD_PGD', epsilon)\n",
    "\n",
    "print(\"start DF\")\n",
    "# DF_eps = [0.01, 0.1, 0.2, 0.3]\n",
    "for epsilon in epsilon_values:\n",
    "    filename = f'/home/jovyan/Wustl_iiot/transfer_attack/x_test_adv_DF_eps_{epsilon}.npy'\n",
    "    x_test_adv = np.load(filename)\n",
    "\n",
    "    calculate_performance_metrics(x_test_adv, y_test, student_model, 'DNN', 'DD_DF', epsilon)\n",
    "# calculate_performance_metrics(x_test_adv, y_test_adv, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
