{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54147517-f7f8-4ab3-ba93-d9f684cde54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "from joblib import load\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34a29571-7a9e-4d15-81ff-6cf908343fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_indices=np.load('y_test_indices.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e314d2df-3235-4b4e-a68d-06a87688263a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dt = load('model_dt.joblib')\n",
    "model_knn = load('model_knn.joblib')\n",
    "model_lr = load('model_lr.joblib')\n",
    "model_nb = load('model_nb.joblib')\n",
    "model_rf = load('model_rf.joblib')\n",
    "model_svc = load('model_svc.joblib')\n",
    "model_xgb = load('model_xgb.joblib')\n",
    "models = [\n",
    "    model_dt, model_knn, model_lr, \n",
    "    model_nb, model_rf, model_svc, model_xgb\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f3168d-7f08-4e51-9ffa-62b01a6d38f1",
   "metadata": {},
   "source": [
    "## BIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "855c9f30-713b-4804-8b8c-1f98eb33dd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_BIM_001= np.load('x_test_adv_BIM_eps_0.01.npy')\n",
    "x_BIM_001 = np.nan_to_num(x_BIM_001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "210602e9-4f35-493d-be88-9c5586fb896b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DecisionTreeClassifier(max_depth=10, min_samples_split=12)\n",
      "Accuracy: 0.4213680605623648\n",
      "Micro Precision: 0.42\n",
      "Macro Precision: 0.66\n",
      "Micro Recall: 0.42\n",
      "Macro Recall: 0.60\n",
      "Micro F1 Score: 0.42\n",
      "Macro F1 Score: 0.41\n",
      "Average TNR: 0.60, Average FPR: 0.40, Average FNR: 0.40\n",
      "\n",
      "Macro TNR: 0.60, Macro FNR: 0.40,Macro FPR: 0.40\n",
      "\n",
      "Model: KNeighborsClassifier(n_neighbors=1)\n",
      "Accuracy: 0.5260454217736121\n",
      "Micro Precision: 0.53\n",
      "Macro Precision: 0.68\n",
      "Micro Recall: 0.53\n",
      "Macro Recall: 0.67\n",
      "Micro F1 Score: 0.53\n",
      "Macro F1 Score: 0.53\n",
      "Average TNR: 0.67, Average FPR: 0.33, Average FNR: 0.33\n",
      "\n",
      "Macro TNR: 0.67, Macro FNR: 0.33,Macro FPR: 0.33\n",
      "\n",
      "Model: LogisticRegression(max_iter=5000, verbose=1)\n",
      "Accuracy: 0.4781407714491709\n",
      "Micro Precision: 0.48\n",
      "Macro Precision: 0.65\n",
      "Micro Recall: 0.48\n",
      "Macro Recall: 0.63\n",
      "Micro F1 Score: 0.48\n",
      "Macro F1 Score: 0.48\n",
      "Average TNR: 0.63, Average FPR: 0.37, Average FNR: 0.37\n",
      "\n",
      "Macro TNR: 0.63, Macro FNR: 0.37,Macro FPR: 0.37\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: GaussianNB()\n",
      "Accuracy: 0.8054253785147801\n",
      "Micro Precision: 0.81\n",
      "Macro Precision: 0.89\n",
      "Micro Recall: 0.81\n",
      "Macro Recall: 0.64\n",
      "Micro F1 Score: 0.81\n",
      "Macro F1 Score: 0.66\n",
      "Average TNR: 0.64, Average FPR: 0.36, Average FNR: 0.36\n",
      "\n",
      "Macro TNR: 0.64, Macro FNR: 0.36,Macro FPR: 0.36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestClassifier()\n",
      "Accuracy: 0.4158480533525595\n",
      "Micro Precision: 0.42\n",
      "Macro Precision: 0.66\n",
      "Micro Recall: 0.42\n",
      "Macro Recall: 0.60\n",
      "Micro F1 Score: 0.42\n",
      "Macro F1 Score: 0.41\n",
      "Average TNR: 0.60, Average FPR: 0.40, Average FNR: 0.40\n",
      "\n",
      "Macro TNR: 0.60, Macro FNR: 0.40,Macro FPR: 0.40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SVC(shrinking=False, verbose=True)\n",
      "Accuracy: 0.2753469718817592\n",
      "Micro Precision: 0.28\n",
      "Macro Precision: 0.64\n",
      "Micro Recall: 0.28\n",
      "Macro Recall: 0.50\n",
      "Micro F1 Score: 0.28\n",
      "Macro F1 Score: 0.22\n",
      "Average TNR: 0.50, Average FPR: 0.50, Average FNR: 0.50\n",
      "\n",
      "Macro TNR: 0.50, Macro FNR: 0.50,Macro FPR: 0.50\n",
      "\n",
      "Model: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='mlogloss',\n",
      "              feature_types=None, gamma=None, grow_policy=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.2, max_bin=None, max_cat_threshold=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
      "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)\n",
      "Accuracy: 0.2716204037490988\n",
      "Micro Precision: 0.27\n",
      "Macro Precision: 0.64\n",
      "Micro Recall: 0.27\n",
      "Macro Recall: 0.50\n",
      "Micro F1 Score: 0.27\n",
      "Macro F1 Score: 0.21\n",
      "Average TNR: 0.50, Average FPR: 0.50, Average FNR: 0.50\n",
      "\n",
      "Macro TNR: 0.50, Macro FNR: 0.50,Macro FPR: 0.50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_accuracies = {}\n",
    "\n",
    "# Evaluate each model\n",
    "for model in models:\n",
    "    \n",
    "    # Make predictions with the loaded model\n",
    "    predictions = model.predict(x_BIM_001)\n",
    "    \n",
    "     # Calculate micro and macro precision, recall, and F1 score\n",
    "    precision_micro, recall_micro, fscore_micro, _ = precision_recall_fscore_support(\n",
    "        y_test_indices, predictions, average='micro')\n",
    "    precision_macro, recall_macro, fscore_macro, _ = precision_recall_fscore_support(\n",
    "        y_test_indices, predictions, average='macro')\n",
    "    acc = np.sum(predictions == y_test_indices) / y_test_indices.shape[0]\n",
    "    # Calculate confusion matrix and then TPR, TNR, FPR, FNR for each class\n",
    "    conf_matrix = confusion_matrix(y_test_indices, predictions)\n",
    "    FP = conf_matrix.sum(axis=0) - np.diag(conf_matrix)  \n",
    "    FN = conf_matrix.sum(axis=1) - np.diag(conf_matrix)\n",
    "    TP = np.diag(conf_matrix)\n",
    "    TN = conf_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "    TPR = TP / (TP + FN)\n",
    "    TNR = TN / (TN + FP)\n",
    "    FPR = FP / (FP + TN)\n",
    "    FNR = FN / (TP + FN)\n",
    "\n",
    "    # Averaging TPR, TNR, FPR, FNR\n",
    "    TPR_avg = np.mean(TPR)\n",
    "    TNR_avg = np.mean(TNR)\n",
    "    FPR_avg = np.mean(FPR)\n",
    "    FNR_avg = np.mean(FNR)\n",
    "    TP_micro = np.sum(TP)\n",
    "    FP_micro = np.sum(FP)\n",
    "    FN_micro = np.sum(FN)\n",
    "    TN_micro = np.sum(TN)\n",
    "\n",
    "    # Micro averages for applicable metrics\n",
    "    TPR_micro = TP_micro / (TP_micro + FN_micro)\n",
    "    FPR_micro = FP_micro / (FP_micro + TN_micro)\n",
    "\n",
    "    \n",
    "    # Print the results for each epsilon\n",
    "    print(f\"Model: {model}\")\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "    print(f\"Micro Precision: {precision_micro:.2f}\")\n",
    "    print(f\"Macro Precision: {precision_macro:.2f}\")\n",
    "    print(f\"Micro Recall: {recall_micro:.2f}\")\n",
    "    print(f\"Macro Recall: {recall_macro:.2f}\")\n",
    "    print(f\"Micro F1 Score: {fscore_micro:.2f}\")\n",
    "    print(f\"Macro F1 Score: {fscore_macro:.2f}\")\n",
    "    print(f\"Average TNR: {TNR_avg:.2f}, Average FPR: {FPR_avg:.2f}, Average FNR: {FNR_avg:.2f}\\n\")\n",
    "    print(f\"Macro TNR: {TNR_avg:.2f}, Macro FNR: {FNR_avg:.2f},Macro FPR: {FPR_avg:.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6ada6c5-b6d1-435f-88cd-1bf8ddc98677",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_BIM_01= np.load('x_test_adv_BIM_eps_0.1.npy')\n",
    "x_BIM_01 = np.nan_to_num(x_BIM_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f858725-196e-4651-be3d-d07afed779c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DecisionTreeClassifier(max_depth=10, min_samples_split=12)\n",
      "Accuracy: 0.4213680605623648\n",
      "Micro Precision: 0.42\n",
      "Macro Precision: 0.66\n",
      "Micro Recall: 0.42\n",
      "Macro Recall: 0.60\n",
      "Micro F1 Score: 0.42\n",
      "Macro F1 Score: 0.41\n",
      "Average TNR: 0.60, Average FPR: 0.40, Average FNR: 0.40\n",
      "\n",
      "Macro TNR: 0.60, Macro FNR: 0.40,Macro FPR: 0.40\n",
      "\n",
      "Model: KNeighborsClassifier(n_neighbors=1)\n",
      "Accuracy: 0.5093096611391492\n",
      "Micro Precision: 0.51\n",
      "Macro Precision: 0.68\n",
      "Micro Recall: 0.51\n",
      "Macro Recall: 0.66\n",
      "Micro F1 Score: 0.51\n",
      "Macro F1 Score: 0.51\n",
      "Average TNR: 0.66, Average FPR: 0.34, Average FNR: 0.34\n",
      "\n",
      "Macro TNR: 0.66, Macro FNR: 0.34,Macro FPR: 0.34\n",
      "\n",
      "Model: LogisticRegression(max_iter=5000, verbose=1)\n",
      "Accuracy: 0.47891131939437637\n",
      "Micro Precision: 0.48\n",
      "Macro Precision: 0.65\n",
      "Micro Recall: 0.48\n",
      "Macro Recall: 0.63\n",
      "Micro F1 Score: 0.48\n",
      "Macro F1 Score: 0.48\n",
      "Average TNR: 0.63, Average FPR: 0.37, Average FNR: 0.37\n",
      "\n",
      "Macro TNR: 0.63, Macro FNR: 0.37,Macro FPR: 0.37\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: GaussianNB()\n",
      "Accuracy: 0.8061643835616439\n",
      "Micro Precision: 0.81\n",
      "Macro Precision: 0.90\n",
      "Micro Recall: 0.81\n",
      "Macro Recall: 0.64\n",
      "Micro F1 Score: 0.81\n",
      "Macro F1 Score: 0.66\n",
      "Average TNR: 0.64, Average FPR: 0.36, Average FNR: 0.36\n",
      "\n",
      "Macro TNR: 0.64, Macro FNR: 0.36,Macro FPR: 0.36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestClassifier()\n",
      "Accuracy: 0.4158480533525595\n",
      "Micro Precision: 0.42\n",
      "Macro Precision: 0.66\n",
      "Micro Recall: 0.42\n",
      "Macro Recall: 0.60\n",
      "Micro F1 Score: 0.42\n",
      "Macro F1 Score: 0.41\n",
      "Average TNR: 0.60, Average FPR: 0.40, Average FNR: 0.40\n",
      "\n",
      "Macro TNR: 0.60, Macro FNR: 0.40,Macro FPR: 0.40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SVC(shrinking=False, verbose=True)\n",
      "Accuracy: 0.27796953857245854\n",
      "Micro Precision: 0.28\n",
      "Macro Precision: 0.64\n",
      "Micro Recall: 0.28\n",
      "Macro Recall: 0.51\n",
      "Micro F1 Score: 0.28\n",
      "Macro F1 Score: 0.22\n",
      "Average TNR: 0.51, Average FPR: 0.49, Average FNR: 0.49\n",
      "\n",
      "Macro TNR: 0.51, Macro FNR: 0.49,Macro FPR: 0.49\n",
      "\n",
      "Model: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='mlogloss',\n",
      "              feature_types=None, gamma=None, grow_policy=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.2, max_bin=None, max_cat_threshold=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
      "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)\n",
      "Accuracy: 0.2716204037490988\n",
      "Micro Precision: 0.27\n",
      "Macro Precision: 0.64\n",
      "Micro Recall: 0.27\n",
      "Macro Recall: 0.50\n",
      "Micro F1 Score: 0.27\n",
      "Macro F1 Score: 0.21\n",
      "Average TNR: 0.50, Average FPR: 0.50, Average FNR: 0.50\n",
      "\n",
      "Macro TNR: 0.50, Macro FNR: 0.50,Macro FPR: 0.50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_accuracies = {}\n",
    "\n",
    "# Evaluate each model\n",
    "for model in models:\n",
    "    \n",
    "    # Make predictions with the loaded model\n",
    "    predictions = model.predict(x_BIM_01)\n",
    "    \n",
    "     # Calculate micro and macro precision, recall, and F1 score\n",
    "    precision_micro, recall_micro, fscore_micro, _ = precision_recall_fscore_support(\n",
    "        y_test_indices, predictions, average='micro')\n",
    "    precision_macro, recall_macro, fscore_macro, _ = precision_recall_fscore_support(\n",
    "        y_test_indices, predictions, average='macro')\n",
    "    acc = np.sum(predictions == y_test_indices) / y_test_indices.shape[0]\n",
    "    # Calculate confusion matrix and then TPR, TNR, FPR, FNR for each class\n",
    "    conf_matrix = confusion_matrix(y_test_indices, predictions)\n",
    "    FP = conf_matrix.sum(axis=0) - np.diag(conf_matrix)  \n",
    "    FN = conf_matrix.sum(axis=1) - np.diag(conf_matrix)\n",
    "    TP = np.diag(conf_matrix)\n",
    "    TN = conf_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "    TPR = TP / (TP + FN)\n",
    "    TNR = TN / (TN + FP)\n",
    "    FPR = FP / (FP + TN)\n",
    "    FNR = FN / (TP + FN)\n",
    "\n",
    "    # Averaging TPR, TNR, FPR, FNR\n",
    "    TPR_avg = np.mean(TPR)\n",
    "    TNR_avg = np.mean(TNR)\n",
    "    FPR_avg = np.mean(FPR)\n",
    "    FNR_avg = np.mean(FNR)\n",
    "    TP_micro = np.sum(TP)\n",
    "    FP_micro = np.sum(FP)\n",
    "    FN_micro = np.sum(FN)\n",
    "    TN_micro = np.sum(TN)\n",
    "\n",
    "    # Micro averages for applicable metrics\n",
    "    TPR_micro = TP_micro / (TP_micro + FN_micro)\n",
    "    FPR_micro = FP_micro / (FP_micro + TN_micro)\n",
    "\n",
    "    \n",
    "    # Print the results for each epsilon\n",
    "    print(f\"Model: {model}\")\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "    print(f\"Micro Precision: {precision_micro:.2f}\")\n",
    "    print(f\"Macro Precision: {precision_macro:.2f}\")\n",
    "    print(f\"Micro Recall: {recall_micro:.2f}\")\n",
    "    print(f\"Macro Recall: {recall_macro:.2f}\")\n",
    "    print(f\"Micro F1 Score: {fscore_micro:.2f}\")\n",
    "    print(f\"Macro F1 Score: {fscore_macro:.2f}\")\n",
    "    print(f\"Average TNR: {TNR_avg:.2f}, Average FPR: {FPR_avg:.2f}, Average FNR: {FNR_avg:.2f}\\n\")\n",
    "    print(f\"Macro TNR: {TNR_avg:.2f}, Macro FNR: {FNR_avg:.2f},Macro FPR: {FPR_avg:.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5e20f4-6ecc-4dee-9949-5d51e1a5abb5",
   "metadata": {},
   "source": [
    "## DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e36aaafd-994f-4182-b283-b87d487ac80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_DF_001= np.load('x_test_adv_DF_eps_0.01.npy')\n",
    "x_DF_001 = np.nan_to_num(x_DF_001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74f0a74c-b974-4012-a33f-db0cb3c7cf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DecisionTreeClassifier(max_depth=10, min_samples_split=12)\n",
      "Accuracy: 0.2706290555155011\n",
      "Micro Precision: 0.27\n",
      "Macro Precision: 0.14\n",
      "Micro Recall: 0.27\n",
      "Macro Recall: 0.50\n",
      "Micro F1 Score: 0.27\n",
      "Macro F1 Score: 0.21\n",
      "Average TNR: 0.50, Average FPR: 0.50, Average FNR: 0.50\n",
      "\n",
      "Macro TNR: 0.50, Macro FNR: 0.50,Macro FPR: 0.50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: KNeighborsClassifier(n_neighbors=1)\n",
      "Accuracy: 0.2706290555155011\n",
      "Micro Precision: 0.27\n",
      "Macro Precision: 0.14\n",
      "Micro Recall: 0.27\n",
      "Macro Recall: 0.50\n",
      "Micro F1 Score: 0.27\n",
      "Macro F1 Score: 0.21\n",
      "Average TNR: 0.50, Average FPR: 0.50, Average FNR: 0.50\n",
      "\n",
      "Macro TNR: 0.50, Macro FNR: 0.50,Macro FPR: 0.50\n",
      "\n",
      "Model: LogisticRegression(max_iter=5000, verbose=1)\n",
      "Accuracy: 0.2706290555155011\n",
      "Micro Precision: 0.27\n",
      "Macro Precision: 0.14\n",
      "Micro Recall: 0.27\n",
      "Macro Recall: 0.50\n",
      "Micro F1 Score: 0.27\n",
      "Macro F1 Score: 0.21\n",
      "Average TNR: 0.50, Average FPR: 0.50, Average FNR: 0.50\n",
      "\n",
      "Macro TNR: 0.50, Macro FNR: 0.50,Macro FPR: 0.50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: GaussianNB()\n",
      "Accuracy: 0.2706290555155011\n",
      "Micro Precision: 0.27\n",
      "Macro Precision: 0.14\n",
      "Micro Recall: 0.27\n",
      "Macro Recall: 0.50\n",
      "Micro F1 Score: 0.27\n",
      "Macro F1 Score: 0.21\n",
      "Average TNR: 0.50, Average FPR: 0.50, Average FNR: 0.50\n",
      "\n",
      "Macro TNR: 0.50, Macro FNR: 0.50,Macro FPR: 0.50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestClassifier()\n",
      "Accuracy: 0.2706290555155011\n",
      "Micro Precision: 0.27\n",
      "Macro Precision: 0.14\n",
      "Micro Recall: 0.27\n",
      "Macro Recall: 0.50\n",
      "Micro F1 Score: 0.27\n",
      "Macro F1 Score: 0.21\n",
      "Average TNR: 0.50, Average FPR: 0.50, Average FNR: 0.50\n",
      "\n",
      "Macro TNR: 0.50, Macro FNR: 0.50,Macro FPR: 0.50\n",
      "\n",
      "Model: SVC(shrinking=False, verbose=True)\n",
      "Accuracy: 0.2706290555155011\n",
      "Micro Precision: 0.27\n",
      "Macro Precision: 0.14\n",
      "Micro Recall: 0.27\n",
      "Macro Recall: 0.50\n",
      "Micro F1 Score: 0.27\n",
      "Macro F1 Score: 0.21\n",
      "Average TNR: 0.50, Average FPR: 0.50, Average FNR: 0.50\n",
      "\n",
      "Macro TNR: 0.50, Macro FNR: 0.50,Macro FPR: 0.50\n",
      "\n",
      "Model: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='mlogloss',\n",
      "              feature_types=None, gamma=None, grow_policy=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.2, max_bin=None, max_cat_threshold=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
      "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)\n",
      "Accuracy: 0.2706290555155011\n",
      "Micro Precision: 0.27\n",
      "Macro Precision: 0.14\n",
      "Micro Recall: 0.27\n",
      "Macro Recall: 0.50\n",
      "Micro F1 Score: 0.27\n",
      "Macro F1 Score: 0.21\n",
      "Average TNR: 0.50, Average FPR: 0.50, Average FNR: 0.50\n",
      "\n",
      "Macro TNR: 0.50, Macro FNR: 0.50,Macro FPR: 0.50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model_accuracies = {}\n",
    "\n",
    "# Evaluate each model\n",
    "for model in models:\n",
    "    \n",
    "    # Make predictions with the loaded model\n",
    "    predictions = model.predict(x_DF_001)\n",
    "    \n",
    "     # Calculate micro and macro precision, recall, and F1 score\n",
    "    precision_micro, recall_micro, fscore_micro, _ = precision_recall_fscore_support(\n",
    "        y_test_indices, predictions, average='micro')\n",
    "    precision_macro, recall_macro, fscore_macro, _ = precision_recall_fscore_support(\n",
    "        y_test_indices, predictions, average='macro')\n",
    "    acc = np.sum(predictions == y_test_indices) / y_test_indices.shape[0]\n",
    "    # Calculate confusion matrix and then TPR, TNR, FPR, FNR for each class\n",
    "    conf_matrix = confusion_matrix(y_test_indices, predictions)\n",
    "    FP = conf_matrix.sum(axis=0) - np.diag(conf_matrix)  \n",
    "    FN = conf_matrix.sum(axis=1) - np.diag(conf_matrix)\n",
    "    TP = np.diag(conf_matrix)\n",
    "    TN = conf_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "    TPR = TP / (TP + FN)\n",
    "    TNR = TN / (TN + FP)\n",
    "    FPR = FP / (FP + TN)\n",
    "    FNR = FN / (TP + FN)\n",
    "\n",
    "    # Averaging TPR, TNR, FPR, FNR\n",
    "    TPR_avg = np.mean(TPR)\n",
    "    TNR_avg = np.mean(TNR)\n",
    "    FPR_avg = np.mean(FPR)\n",
    "    FNR_avg = np.mean(FNR)\n",
    "    TP_micro = np.sum(TP)\n",
    "    FP_micro = np.sum(FP)\n",
    "    FN_micro = np.sum(FN)\n",
    "    TN_micro = np.sum(TN)\n",
    "\n",
    "    # Micro averages for applicable metrics\n",
    "    TPR_micro = TP_micro / (TP_micro + FN_micro)\n",
    "    FPR_micro = FP_micro / (FP_micro + TN_micro)\n",
    "\n",
    "    \n",
    "    # Print the results for each epsilon\n",
    "    print(f\"Model: {model}\")\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "    print(f\"Micro Precision: {precision_micro:.2f}\")\n",
    "    print(f\"Macro Precision: {precision_macro:.2f}\")\n",
    "    print(f\"Micro Recall: {recall_micro:.2f}\")\n",
    "    print(f\"Macro Recall: {recall_macro:.2f}\")\n",
    "    print(f\"Micro F1 Score: {fscore_micro:.2f}\")\n",
    "    print(f\"Macro F1 Score: {fscore_macro:.2f}\")\n",
    "    print(f\"Average TNR: {TNR_avg:.2f}, Average FPR: {FPR_avg:.2f}, Average FNR: {FNR_avg:.2f}\\n\")\n",
    "    print(f\"Macro TNR: {TNR_avg:.2f}, Macro FNR: {FNR_avg:.2f},Macro FPR: {FPR_avg:.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "489d0bde-d432-488c-91e9-7d08f3d74c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_DF_01= np.load('x_test_adv_DF_eps_0.1.npy')\n",
    "x_DF_01 = np.nan_to_num(x_DF_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "849350ac-0921-475d-ac89-9ee193305efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DecisionTreeClassifier(max_depth=10, min_samples_split=12)\n",
      "Accuracy: 0.2706290555155011\n",
      "Micro Precision: 0.27\n",
      "Macro Precision: 0.14\n",
      "Micro Recall: 0.27\n",
      "Macro Recall: 0.50\n",
      "Micro F1 Score: 0.27\n",
      "Macro F1 Score: 0.21\n",
      "Average TNR: 0.50, Average FPR: 0.50, Average FNR: 0.50\n",
      "\n",
      "Macro TNR: 0.50, Macro FNR: 0.50,Macro FPR: 0.50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: KNeighborsClassifier(n_neighbors=1)\n",
      "Accuracy: 0.2706290555155011\n",
      "Micro Precision: 0.27\n",
      "Macro Precision: 0.14\n",
      "Micro Recall: 0.27\n",
      "Macro Recall: 0.50\n",
      "Micro F1 Score: 0.27\n",
      "Macro F1 Score: 0.21\n",
      "Average TNR: 0.50, Average FPR: 0.50, Average FNR: 0.50\n",
      "\n",
      "Macro TNR: 0.50, Macro FNR: 0.50,Macro FPR: 0.50\n",
      "\n",
      "Model: LogisticRegression(max_iter=5000, verbose=1)\n",
      "Accuracy: 0.2706290555155011\n",
      "Micro Precision: 0.27\n",
      "Macro Precision: 0.14\n",
      "Micro Recall: 0.27\n",
      "Macro Recall: 0.50\n",
      "Micro F1 Score: 0.27\n",
      "Macro F1 Score: 0.21\n",
      "Average TNR: 0.50, Average FPR: 0.50, Average FNR: 0.50\n",
      "\n",
      "Macro TNR: 0.50, Macro FNR: 0.50,Macro FPR: 0.50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: GaussianNB()\n",
      "Accuracy: 0.2706290555155011\n",
      "Micro Precision: 0.27\n",
      "Macro Precision: 0.14\n",
      "Micro Recall: 0.27\n",
      "Macro Recall: 0.50\n",
      "Micro F1 Score: 0.27\n",
      "Macro F1 Score: 0.21\n",
      "Average TNR: 0.50, Average FPR: 0.50, Average FNR: 0.50\n",
      "\n",
      "Macro TNR: 0.50, Macro FNR: 0.50,Macro FPR: 0.50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestClassifier()\n",
      "Accuracy: 0.2706290555155011\n",
      "Micro Precision: 0.27\n",
      "Macro Precision: 0.14\n",
      "Micro Recall: 0.27\n",
      "Macro Recall: 0.50\n",
      "Micro F1 Score: 0.27\n",
      "Macro F1 Score: 0.21\n",
      "Average TNR: 0.50, Average FPR: 0.50, Average FNR: 0.50\n",
      "\n",
      "Macro TNR: 0.50, Macro FNR: 0.50,Macro FPR: 0.50\n",
      "\n",
      "Model: SVC(shrinking=False, verbose=True)\n",
      "Accuracy: 0.2706290555155011\n",
      "Micro Precision: 0.27\n",
      "Macro Precision: 0.14\n",
      "Micro Recall: 0.27\n",
      "Macro Recall: 0.50\n",
      "Micro F1 Score: 0.27\n",
      "Macro F1 Score: 0.21\n",
      "Average TNR: 0.50, Average FPR: 0.50, Average FNR: 0.50\n",
      "\n",
      "Macro TNR: 0.50, Macro FNR: 0.50,Macro FPR: 0.50\n",
      "\n",
      "Model: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='mlogloss',\n",
      "              feature_types=None, gamma=None, grow_policy=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.2, max_bin=None, max_cat_threshold=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
      "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)\n",
      "Accuracy: 0.2706290555155011\n",
      "Micro Precision: 0.27\n",
      "Macro Precision: 0.14\n",
      "Micro Recall: 0.27\n",
      "Macro Recall: 0.50\n",
      "Micro F1 Score: 0.27\n",
      "Macro F1 Score: 0.21\n",
      "Average TNR: 0.50, Average FPR: 0.50, Average FNR: 0.50\n",
      "\n",
      "Macro TNR: 0.50, Macro FNR: 0.50,Macro FPR: 0.50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model_accuracies = {}\n",
    "\n",
    "# Evaluate each model\n",
    "for model in models:\n",
    "    \n",
    "    # Make predictions with the loaded model\n",
    "    predictions = model.predict(x_DF_01)\n",
    "    \n",
    "     # Calculate micro and macro precision, recall, and F1 score\n",
    "    precision_micro, recall_micro, fscore_micro, _ = precision_recall_fscore_support(\n",
    "        y_test_indices, predictions, average='micro')\n",
    "    precision_macro, recall_macro, fscore_macro, _ = precision_recall_fscore_support(\n",
    "        y_test_indices, predictions, average='macro')\n",
    "    acc = np.sum(predictions == y_test_indices) / y_test_indices.shape[0]\n",
    "    # Calculate confusion matrix and then TPR, TNR, FPR, FNR for each class\n",
    "    conf_matrix = confusion_matrix(y_test_indices, predictions)\n",
    "    FP = conf_matrix.sum(axis=0) - np.diag(conf_matrix)  \n",
    "    FN = conf_matrix.sum(axis=1) - np.diag(conf_matrix)\n",
    "    TP = np.diag(conf_matrix)\n",
    "    TN = conf_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "    TPR = TP / (TP + FN)\n",
    "    TNR = TN / (TN + FP)\n",
    "    FPR = FP / (FP + TN)\n",
    "    FNR = FN / (TP + FN)\n",
    "\n",
    "    # Averaging TPR, TNR, FPR, FNR\n",
    "    TPR_avg = np.mean(TPR)\n",
    "    TNR_avg = np.mean(TNR)\n",
    "    FPR_avg = np.mean(FPR)\n",
    "    FNR_avg = np.mean(FNR)\n",
    "    TP_micro = np.sum(TP)\n",
    "    FP_micro = np.sum(FP)\n",
    "    FN_micro = np.sum(FN)\n",
    "    TN_micro = np.sum(TN)\n",
    "\n",
    "    # Micro averages for applicable metrics\n",
    "    TPR_micro = TP_micro / (TP_micro + FN_micro)\n",
    "    FPR_micro = FP_micro / (FP_micro + TN_micro)\n",
    "\n",
    "    \n",
    "    # Print the results for each epsilon\n",
    "    print(f\"Model: {model}\")\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "    print(f\"Micro Precision: {precision_micro:.2f}\")\n",
    "    print(f\"Macro Precision: {precision_macro:.2f}\")\n",
    "    print(f\"Micro Recall: {recall_micro:.2f}\")\n",
    "    print(f\"Macro Recall: {recall_macro:.2f}\")\n",
    "    print(f\"Micro F1 Score: {fscore_micro:.2f}\")\n",
    "    print(f\"Macro F1 Score: {fscore_macro:.2f}\")\n",
    "    print(f\"Average TNR: {TNR_avg:.2f}, Average FPR: {FPR_avg:.2f}, Average FNR: {FNR_avg:.2f}\\n\")\n",
    "    print(f\"Macro TNR: {TNR_avg:.2f}, Macro FNR: {FNR_avg:.2f},Macro FPR: {FPR_avg:.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2d69ff-dc0e-4209-b601-c92ede56d92c",
   "metadata": {},
   "source": [
    "## FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3240a568-ca38-4128-ba5f-d18e7cfb5d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_FGSM_001= np.load('x_test_FGSM_eps_0.01.npy')\n",
    "x_FGSM_001 = np.nan_to_num(x_FGSM_001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a21c3fb2-f43d-4bbb-8210-6612d5b13c00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DecisionTreeClassifier(max_depth=10, min_samples_split=12)\n",
      "Accuracy: 0.4213680605623648\n",
      "Micro Precision: 0.42\n",
      "Macro Precision: 0.66\n",
      "Micro Recall: 0.42\n",
      "Macro Recall: 0.60\n",
      "Micro F1 Score: 0.42\n",
      "Macro F1 Score: 0.41\n",
      "Average TNR: 0.60, Average FPR: 0.40, Average FNR: 0.40\n",
      "\n",
      "Macro TNR: 0.60, Macro FNR: 0.40,Macro FPR: 0.40\n",
      "\n",
      "Model: KNeighborsClassifier(n_neighbors=1)\n",
      "Accuracy: 0.5260454217736121\n",
      "Micro Precision: 0.53\n",
      "Macro Precision: 0.68\n",
      "Micro Recall: 0.53\n",
      "Macro Recall: 0.67\n",
      "Micro F1 Score: 0.53\n",
      "Macro F1 Score: 0.53\n",
      "Average TNR: 0.67, Average FPR: 0.33, Average FNR: 0.33\n",
      "\n",
      "Macro TNR: 0.67, Macro FNR: 0.33,Macro FPR: 0.33\n",
      "\n",
      "Model: LogisticRegression(max_iter=5000, verbose=1)\n",
      "Accuracy: 0.4781407714491709\n",
      "Micro Precision: 0.48\n",
      "Macro Precision: 0.65\n",
      "Micro Recall: 0.48\n",
      "Macro Recall: 0.63\n",
      "Micro F1 Score: 0.48\n",
      "Macro F1 Score: 0.48\n",
      "Average TNR: 0.63, Average FPR: 0.37, Average FNR: 0.37\n",
      "\n",
      "Macro TNR: 0.63, Macro FNR: 0.37,Macro FPR: 0.37\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: GaussianNB()\n",
      "Accuracy: 0.8054253785147801\n",
      "Micro Precision: 0.81\n",
      "Macro Precision: 0.89\n",
      "Micro Recall: 0.81\n",
      "Macro Recall: 0.64\n",
      "Micro F1 Score: 0.81\n",
      "Macro F1 Score: 0.66\n",
      "Average TNR: 0.64, Average FPR: 0.36, Average FNR: 0.36\n",
      "\n",
      "Macro TNR: 0.64, Macro FNR: 0.36,Macro FPR: 0.36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestClassifier()\n",
      "Accuracy: 0.4158480533525595\n",
      "Micro Precision: 0.42\n",
      "Macro Precision: 0.66\n",
      "Micro Recall: 0.42\n",
      "Macro Recall: 0.60\n",
      "Micro F1 Score: 0.42\n",
      "Macro F1 Score: 0.41\n",
      "Average TNR: 0.60, Average FPR: 0.40, Average FNR: 0.40\n",
      "\n",
      "Macro TNR: 0.60, Macro FNR: 0.40,Macro FPR: 0.40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SVC(shrinking=False, verbose=True)\n",
      "Accuracy: 0.2753469718817592\n",
      "Micro Precision: 0.28\n",
      "Macro Precision: 0.64\n",
      "Micro Recall: 0.28\n",
      "Macro Recall: 0.50\n",
      "Micro F1 Score: 0.28\n",
      "Macro F1 Score: 0.22\n",
      "Average TNR: 0.50, Average FPR: 0.50, Average FNR: 0.50\n",
      "\n",
      "Macro TNR: 0.50, Macro FNR: 0.50,Macro FPR: 0.50\n",
      "\n",
      "Model: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='mlogloss',\n",
      "              feature_types=None, gamma=None, grow_policy=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.2, max_bin=None, max_cat_threshold=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
      "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)\n",
      "Accuracy: 0.2716204037490988\n",
      "Micro Precision: 0.27\n",
      "Macro Precision: 0.64\n",
      "Micro Recall: 0.27\n",
      "Macro Recall: 0.50\n",
      "Micro F1 Score: 0.27\n",
      "Macro F1 Score: 0.21\n",
      "Average TNR: 0.50, Average FPR: 0.50, Average FNR: 0.50\n",
      "\n",
      "Macro TNR: 0.50, Macro FNR: 0.50,Macro FPR: 0.50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_accuracies = {}\n",
    "\n",
    "# Evaluate each model\n",
    "for model in models:\n",
    "    \n",
    "    # Make predictions with the loaded model\n",
    "    predictions = model.predict(x_FGSM_001)\n",
    "    \n",
    "     # Calculate micro and macro precision, recall, and F1 score\n",
    "    precision_micro, recall_micro, fscore_micro, _ = precision_recall_fscore_support(\n",
    "        y_test_indices, predictions, average='micro')\n",
    "    precision_macro, recall_macro, fscore_macro, _ = precision_recall_fscore_support(\n",
    "        y_test_indices, predictions, average='macro')\n",
    "    acc = np.sum(predictions == y_test_indices) / y_test_indices.shape[0]\n",
    "    # Calculate confusion matrix and then TPR, TNR, FPR, FNR for each class\n",
    "    conf_matrix = confusion_matrix(y_test_indices, predictions)\n",
    "    FP = conf_matrix.sum(axis=0) - np.diag(conf_matrix)  \n",
    "    FN = conf_matrix.sum(axis=1) - np.diag(conf_matrix)\n",
    "    TP = np.diag(conf_matrix)\n",
    "    TN = conf_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "    TPR = TP / (TP + FN)\n",
    "    TNR = TN / (TN + FP)\n",
    "    FPR = FP / (FP + TN)\n",
    "    FNR = FN / (TP + FN)\n",
    "\n",
    "    # Averaging TPR, TNR, FPR, FNR\n",
    "    TPR_avg = np.mean(TPR)\n",
    "    TNR_avg = np.mean(TNR)\n",
    "    FPR_avg = np.mean(FPR)\n",
    "    FNR_avg = np.mean(FNR)\n",
    "    TP_micro = np.sum(TP)\n",
    "    FP_micro = np.sum(FP)\n",
    "    FN_micro = np.sum(FN)\n",
    "    TN_micro = np.sum(TN)\n",
    "\n",
    "    # Micro averages for applicable metrics\n",
    "    TPR_micro = TP_micro / (TP_micro + FN_micro)\n",
    "    FPR_micro = FP_micro / (FP_micro + TN_micro)\n",
    "\n",
    "    \n",
    "    # Print the results for each epsilon\n",
    "    print(f\"Model: {model}\")\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "    print(f\"Micro Precision: {precision_micro:.2f}\")\n",
    "    print(f\"Macro Precision: {precision_macro:.2f}\")\n",
    "    print(f\"Micro Recall: {recall_micro:.2f}\")\n",
    "    print(f\"Macro Recall: {recall_macro:.2f}\")\n",
    "    print(f\"Micro F1 Score: {fscore_micro:.2f}\")\n",
    "    print(f\"Macro F1 Score: {fscore_macro:.2f}\")\n",
    "    print(f\"Average TNR: {TNR_avg:.2f}, Average FPR: {FPR_avg:.2f}, Average FNR: {FNR_avg:.2f}\\n\")\n",
    "    print(f\"Macro TNR: {TNR_avg:.2f}, Macro FNR: {FNR_avg:.2f},Macro FPR: {FPR_avg:.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3b6533b-2606-46b8-9465-203315bf4f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_FGSM_01= np.load('x_test_FGSM_eps_0.1.npy')\n",
    "x_FGSM_01 = np.nan_to_num(x_FGSM_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f89d7970-9477-4d15-8c3d-82fd426a4e6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DecisionTreeClassifier(max_depth=10, min_samples_split=12)\n",
      "Accuracy: 0.4213680605623648\n",
      "Micro Precision: 0.42\n",
      "Macro Precision: 0.66\n",
      "Micro Recall: 0.42\n",
      "Macro Recall: 0.60\n",
      "Micro F1 Score: 0.42\n",
      "Macro F1 Score: 0.41\n",
      "Average TNR: 0.60, Average FPR: 0.40, Average FNR: 0.40\n",
      "\n",
      "Macro TNR: 0.60, Macro FNR: 0.40,Macro FPR: 0.40\n",
      "\n",
      "Model: KNeighborsClassifier(n_neighbors=1)\n",
      "Accuracy: 0.5260454217736121\n",
      "Micro Precision: 0.53\n",
      "Macro Precision: 0.68\n",
      "Micro Recall: 0.53\n",
      "Macro Recall: 0.67\n",
      "Micro F1 Score: 0.53\n",
      "Macro F1 Score: 0.53\n",
      "Average TNR: 0.67, Average FPR: 0.33, Average FNR: 0.33\n",
      "\n",
      "Macro TNR: 0.67, Macro FNR: 0.33,Macro FPR: 0.33\n",
      "\n",
      "Model: LogisticRegression(max_iter=5000, verbose=1)\n",
      "Accuracy: 0.4781407714491709\n",
      "Micro Precision: 0.48\n",
      "Macro Precision: 0.65\n",
      "Micro Recall: 0.48\n",
      "Macro Recall: 0.63\n",
      "Micro F1 Score: 0.48\n",
      "Macro F1 Score: 0.48\n",
      "Average TNR: 0.63, Average FPR: 0.37, Average FNR: 0.37\n",
      "\n",
      "Macro TNR: 0.63, Macro FNR: 0.37,Macro FPR: 0.37\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: GaussianNB()\n",
      "Accuracy: 0.8054253785147801\n",
      "Micro Precision: 0.81\n",
      "Macro Precision: 0.89\n",
      "Micro Recall: 0.81\n",
      "Macro Recall: 0.64\n",
      "Micro F1 Score: 0.81\n",
      "Macro F1 Score: 0.66\n",
      "Average TNR: 0.64, Average FPR: 0.36, Average FNR: 0.36\n",
      "\n",
      "Macro TNR: 0.64, Macro FNR: 0.36,Macro FPR: 0.36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestClassifier()\n",
      "Accuracy: 0.4158480533525595\n",
      "Micro Precision: 0.42\n",
      "Macro Precision: 0.66\n",
      "Micro Recall: 0.42\n",
      "Macro Recall: 0.60\n",
      "Micro F1 Score: 0.42\n",
      "Macro F1 Score: 0.41\n",
      "Average TNR: 0.60, Average FPR: 0.40, Average FNR: 0.40\n",
      "\n",
      "Macro TNR: 0.60, Macro FNR: 0.40,Macro FPR: 0.40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SVC(shrinking=False, verbose=True)\n",
      "Accuracy: 0.2753469718817592\n",
      "Micro Precision: 0.28\n",
      "Macro Precision: 0.64\n",
      "Micro Recall: 0.28\n",
      "Macro Recall: 0.50\n",
      "Micro F1 Score: 0.28\n",
      "Macro F1 Score: 0.22\n",
      "Average TNR: 0.50, Average FPR: 0.50, Average FNR: 0.50\n",
      "\n",
      "Macro TNR: 0.50, Macro FNR: 0.50,Macro FPR: 0.50\n",
      "\n",
      "Model: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='mlogloss',\n",
      "              feature_types=None, gamma=None, grow_policy=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.2, max_bin=None, max_cat_threshold=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
      "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)\n",
      "Accuracy: 0.2716204037490988\n",
      "Micro Precision: 0.27\n",
      "Macro Precision: 0.64\n",
      "Micro Recall: 0.27\n",
      "Macro Recall: 0.50\n",
      "Micro F1 Score: 0.27\n",
      "Macro F1 Score: 0.21\n",
      "Average TNR: 0.50, Average FPR: 0.50, Average FNR: 0.50\n",
      "\n",
      "Macro TNR: 0.50, Macro FNR: 0.50,Macro FPR: 0.50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_accuracies = {}\n",
    "\n",
    "# Evaluate each model\n",
    "for model in models:\n",
    "    \n",
    "    # Make predictions with the loaded model\n",
    "    predictions = model.predict(x_FGSM_001)\n",
    "    \n",
    "     # Calculate micro and macro precision, recall, and F1 score\n",
    "    precision_micro, recall_micro, fscore_micro, _ = precision_recall_fscore_support(\n",
    "        y_test_indices, predictions, average='micro')\n",
    "    precision_macro, recall_macro, fscore_macro, _ = precision_recall_fscore_support(\n",
    "        y_test_indices, predictions, average='macro')\n",
    "    acc = np.sum(predictions == y_test_indices) / y_test_indices.shape[0]\n",
    "    # Calculate confusion matrix and then TPR, TNR, FPR, FNR for each class\n",
    "    conf_matrix = confusion_matrix(y_test_indices, predictions)\n",
    "    FP = conf_matrix.sum(axis=0) - np.diag(conf_matrix)  \n",
    "    FN = conf_matrix.sum(axis=1) - np.diag(conf_matrix)\n",
    "    TP = np.diag(conf_matrix)\n",
    "    TN = conf_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "    TPR = TP / (TP + FN)\n",
    "    TNR = TN / (TN + FP)\n",
    "    FPR = FP / (FP + TN)\n",
    "    FNR = FN / (TP + FN)\n",
    "\n",
    "    # Averaging TPR, TNR, FPR, FNR\n",
    "    TPR_avg = np.mean(TPR)\n",
    "    TNR_avg = np.mean(TNR)\n",
    "    FPR_avg = np.mean(FPR)\n",
    "    FNR_avg = np.mean(FNR)\n",
    "    TP_micro = np.sum(TP)\n",
    "    FP_micro = np.sum(FP)\n",
    "    FN_micro = np.sum(FN)\n",
    "    TN_micro = np.sum(TN)\n",
    "\n",
    "    # Micro averages for applicable metrics\n",
    "    TPR_micro = TP_micro / (TP_micro + FN_micro)\n",
    "    FPR_micro = FP_micro / (FP_micro + TN_micro)\n",
    "\n",
    "    \n",
    "    # Print the results for each epsilon\n",
    "    print(f\"Model: {model}\")\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "    print(f\"Micro Precision: {precision_micro:.2f}\")\n",
    "    print(f\"Macro Precision: {precision_macro:.2f}\")\n",
    "    print(f\"Micro Recall: {recall_micro:.2f}\")\n",
    "    print(f\"Macro Recall: {recall_macro:.2f}\")\n",
    "    print(f\"Micro F1 Score: {fscore_micro:.2f}\")\n",
    "    print(f\"Macro F1 Score: {fscore_macro:.2f}\")\n",
    "    print(f\"Average TNR: {TNR_avg:.2f}, Average FPR: {FPR_avg:.2f}, Average FNR: {FNR_avg:.2f}\\n\")\n",
    "    print(f\"Macro TNR: {TNR_avg:.2f}, Macro FNR: {FNR_avg:.2f},Macro FPR: {FPR_avg:.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed46a9a-8334-410b-953a-66234e28f3f1",
   "metadata": {},
   "source": [
    "## PGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11323ff1-db15-490b-8413-4a7b9dade46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_PGD_001= np.load('x_test_adv_PGD_eps_0.01.npy')\n",
    "x_PGD_001 = np.nan_to_num(x_PGD_001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30bdc6df-59c9-42db-b924-5b7160ee9a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DecisionTreeClassifier(max_depth=10, min_samples_split=12)\n",
      "Accuracy: 0.4213680605623648\n",
      "Micro Precision: 0.42\n",
      "Macro Precision: 0.66\n",
      "Micro Recall: 0.42\n",
      "Macro Recall: 0.60\n",
      "Micro F1 Score: 0.42\n",
      "Macro F1 Score: 0.41\n",
      "Average TNR: 0.60, Average FPR: 0.40, Average FNR: 0.40\n",
      "\n",
      "Macro TNR: 0.60, Macro FNR: 0.40,Macro FPR: 0.40\n",
      "\n",
      "Model: KNeighborsClassifier(n_neighbors=1)\n",
      "Accuracy: 0.5260454217736121\n",
      "Micro Precision: 0.53\n",
      "Macro Precision: 0.68\n",
      "Micro Recall: 0.53\n",
      "Macro Recall: 0.67\n",
      "Micro F1 Score: 0.53\n",
      "Macro F1 Score: 0.53\n",
      "Average TNR: 0.67, Average FPR: 0.33, Average FNR: 0.33\n",
      "\n",
      "Macro TNR: 0.67, Macro FNR: 0.33,Macro FPR: 0.33\n",
      "\n",
      "Model: LogisticRegression(max_iter=5000, verbose=1)\n",
      "Accuracy: 0.4781407714491709\n",
      "Micro Precision: 0.48\n",
      "Macro Precision: 0.65\n",
      "Micro Recall: 0.48\n",
      "Macro Recall: 0.63\n",
      "Micro F1 Score: 0.48\n",
      "Macro F1 Score: 0.48\n",
      "Average TNR: 0.63, Average FPR: 0.37, Average FNR: 0.37\n",
      "\n",
      "Macro TNR: 0.63, Macro FNR: 0.37,Macro FPR: 0.37\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: GaussianNB()\n",
      "Accuracy: 0.8054253785147801\n",
      "Micro Precision: 0.81\n",
      "Macro Precision: 0.89\n",
      "Micro Recall: 0.81\n",
      "Macro Recall: 0.64\n",
      "Micro F1 Score: 0.81\n",
      "Macro F1 Score: 0.66\n",
      "Average TNR: 0.64, Average FPR: 0.36, Average FNR: 0.36\n",
      "\n",
      "Macro TNR: 0.64, Macro FNR: 0.36,Macro FPR: 0.36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestClassifier()\n",
      "Accuracy: 0.4158480533525595\n",
      "Micro Precision: 0.42\n",
      "Macro Precision: 0.66\n",
      "Micro Recall: 0.42\n",
      "Macro Recall: 0.60\n",
      "Micro F1 Score: 0.42\n",
      "Macro F1 Score: 0.41\n",
      "Average TNR: 0.60, Average FPR: 0.40, Average FNR: 0.40\n",
      "\n",
      "Macro TNR: 0.60, Macro FNR: 0.40,Macro FPR: 0.40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SVC(shrinking=False, verbose=True)\n",
      "Accuracy: 0.2753469718817592\n",
      "Micro Precision: 0.28\n",
      "Macro Precision: 0.64\n",
      "Micro Recall: 0.28\n",
      "Macro Recall: 0.50\n",
      "Micro F1 Score: 0.28\n",
      "Macro F1 Score: 0.22\n",
      "Average TNR: 0.50, Average FPR: 0.50, Average FNR: 0.50\n",
      "\n",
      "Macro TNR: 0.50, Macro FNR: 0.50,Macro FPR: 0.50\n",
      "\n",
      "Model: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='mlogloss',\n",
      "              feature_types=None, gamma=None, grow_policy=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.2, max_bin=None, max_cat_threshold=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
      "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)\n",
      "Accuracy: 0.2716204037490988\n",
      "Micro Precision: 0.27\n",
      "Macro Precision: 0.64\n",
      "Micro Recall: 0.27\n",
      "Macro Recall: 0.50\n",
      "Micro F1 Score: 0.27\n",
      "Macro F1 Score: 0.21\n",
      "Average TNR: 0.50, Average FPR: 0.50, Average FNR: 0.50\n",
      "\n",
      "Macro TNR: 0.50, Macro FNR: 0.50,Macro FPR: 0.50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_accuracies = {}\n",
    "\n",
    "# Evaluate each model\n",
    "for model in models:\n",
    "    \n",
    "    # Make predictions with the loaded model\n",
    "    predictions = model.predict(x_PGD_001)\n",
    "    \n",
    "     # Calculate micro and macro precision, recall, and F1 score\n",
    "    precision_micro, recall_micro, fscore_micro, _ = precision_recall_fscore_support(\n",
    "        y_test_indices, predictions, average='micro')\n",
    "    precision_macro, recall_macro, fscore_macro, _ = precision_recall_fscore_support(\n",
    "        y_test_indices, predictions, average='macro')\n",
    "    acc = np.sum(predictions == y_test_indices) / y_test_indices.shape[0]\n",
    "    # Calculate confusion matrix and then TPR, TNR, FPR, FNR for each class\n",
    "    conf_matrix = confusion_matrix(y_test_indices, predictions)\n",
    "    FP = conf_matrix.sum(axis=0) - np.diag(conf_matrix)  \n",
    "    FN = conf_matrix.sum(axis=1) - np.diag(conf_matrix)\n",
    "    TP = np.diag(conf_matrix)\n",
    "    TN = conf_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "    TPR = TP / (TP + FN)\n",
    "    TNR = TN / (TN + FP)\n",
    "    FPR = FP / (FP + TN)\n",
    "    FNR = FN / (TP + FN)\n",
    "\n",
    "    # Averaging TPR, TNR, FPR, FNR\n",
    "    TPR_avg = np.mean(TPR)\n",
    "    TNR_avg = np.mean(TNR)\n",
    "    FPR_avg = np.mean(FPR)\n",
    "    FNR_avg = np.mean(FNR)\n",
    "    TP_micro = np.sum(TP)\n",
    "    FP_micro = np.sum(FP)\n",
    "    FN_micro = np.sum(FN)\n",
    "    TN_micro = np.sum(TN)\n",
    "\n",
    "    # Micro averages for applicable metrics\n",
    "    TPR_micro = TP_micro / (TP_micro + FN_micro)\n",
    "    FPR_micro = FP_micro / (FP_micro + TN_micro)\n",
    "\n",
    "    \n",
    "    # Print the results for each epsilon\n",
    "    print(f\"Model: {model}\")\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "    print(f\"Micro Precision: {precision_micro:.2f}\")\n",
    "    print(f\"Macro Precision: {precision_macro:.2f}\")\n",
    "    print(f\"Micro Recall: {recall_micro:.2f}\")\n",
    "    print(f\"Macro Recall: {recall_macro:.2f}\")\n",
    "    print(f\"Micro F1 Score: {fscore_micro:.2f}\")\n",
    "    print(f\"Macro F1 Score: {fscore_macro:.2f}\")\n",
    "    print(f\"Average TNR: {TNR_avg:.2f}, Average FPR: {FPR_avg:.2f}, Average FNR: {FNR_avg:.2f}\\n\")\n",
    "    print(f\"Macro TNR: {TNR_avg:.2f}, Macro FNR: {FNR_avg:.2f},Macro FPR: {FPR_avg:.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5df2214-1346-455f-b158-7959e3eeb766",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_PGD_01= np.load('x_test_adv_PGD_eps_0.1.npy')\n",
    "x_PGD_01 = np.nan_to_num(x_PGD_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dc475b-c286-4358-9f63-ddb2b1071a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DecisionTreeClassifier(max_depth=10, min_samples_split=12)\n",
      "Accuracy: 0.4213680605623648\n",
      "Micro Precision: 0.42\n",
      "Macro Precision: 0.66\n",
      "Micro Recall: 0.42\n",
      "Macro Recall: 0.60\n",
      "Micro F1 Score: 0.42\n",
      "Macro F1 Score: 0.41\n",
      "Average TNR: 0.60, Average FPR: 0.40, Average FNR: 0.40\n",
      "\n",
      "Macro TNR: 0.60, Macro FNR: 0.40,Macro FPR: 0.40\n",
      "\n",
      "Model: KNeighborsClassifier(n_neighbors=1)\n",
      "Accuracy: 0.5093096611391492\n",
      "Micro Precision: 0.51\n",
      "Macro Precision: 0.68\n",
      "Micro Recall: 0.51\n",
      "Macro Recall: 0.66\n",
      "Micro F1 Score: 0.51\n",
      "Macro F1 Score: 0.51\n",
      "Average TNR: 0.66, Average FPR: 0.34, Average FNR: 0.34\n",
      "\n",
      "Macro TNR: 0.66, Macro FNR: 0.34,Macro FPR: 0.34\n",
      "\n",
      "Model: LogisticRegression(max_iter=5000, verbose=1)\n",
      "Accuracy: 0.47891131939437637\n",
      "Micro Precision: 0.48\n",
      "Macro Precision: 0.65\n",
      "Micro Recall: 0.48\n",
      "Macro Recall: 0.63\n",
      "Micro F1 Score: 0.48\n",
      "Macro F1 Score: 0.48\n",
      "Average TNR: 0.63, Average FPR: 0.37, Average FNR: 0.37\n",
      "\n",
      "Macro TNR: 0.63, Macro FNR: 0.37,Macro FPR: 0.37\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: GaussianNB()\n",
      "Accuracy: 0.8061643835616439\n",
      "Micro Precision: 0.81\n",
      "Macro Precision: 0.90\n",
      "Micro Recall: 0.81\n",
      "Macro Recall: 0.64\n",
      "Micro F1 Score: 0.81\n",
      "Macro F1 Score: 0.66\n",
      "Average TNR: 0.64, Average FPR: 0.36, Average FNR: 0.36\n",
      "\n",
      "Macro TNR: 0.64, Macro FNR: 0.36,Macro FPR: 0.36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestClassifier()\n",
      "Accuracy: 0.4158480533525595\n",
      "Micro Precision: 0.42\n",
      "Macro Precision: 0.66\n",
      "Micro Recall: 0.42\n",
      "Macro Recall: 0.60\n",
      "Micro F1 Score: 0.42\n",
      "Macro F1 Score: 0.41\n",
      "Average TNR: 0.60, Average FPR: 0.40, Average FNR: 0.40\n",
      "\n",
      "Macro TNR: 0.60, Macro FNR: 0.40,Macro FPR: 0.40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_accuracies = {}\n",
    "\n",
    "# Evaluate each model\n",
    "for model in models:\n",
    "    \n",
    "    # Make predictions with the loaded model\n",
    "    predictions = model.predict(x_PGD_01)\n",
    "    \n",
    "     # Calculate micro and macro precision, recall, and F1 score\n",
    "    precision_micro, recall_micro, fscore_micro, _ = precision_recall_fscore_support(\n",
    "        y_test_indices, predictions, average='micro')\n",
    "    precision_macro, recall_macro, fscore_macro, _ = precision_recall_fscore_support(\n",
    "        y_test_indices, predictions, average='macro')\n",
    "    acc = np.sum(predictions == y_test_indices) / y_test_indices.shape[0]\n",
    "    # Calculate confusion matrix and then TPR, TNR, FPR, FNR for each class\n",
    "    conf_matrix = confusion_matrix(y_test_indices, predictions)\n",
    "    FP = conf_matrix.sum(axis=0) - np.diag(conf_matrix)  \n",
    "    FN = conf_matrix.sum(axis=1) - np.diag(conf_matrix)\n",
    "    TP = np.diag(conf_matrix)\n",
    "    TN = conf_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "    TPR = TP / (TP + FN)\n",
    "    TNR = TN / (TN + FP)\n",
    "    FPR = FP / (FP + TN)\n",
    "    FNR = FN / (TP + FN)\n",
    "\n",
    "    # Averaging TPR, TNR, FPR, FNR\n",
    "    TPR_avg = np.mean(TPR)\n",
    "    TNR_avg = np.mean(TNR)\n",
    "    FPR_avg = np.mean(FPR)\n",
    "    FNR_avg = np.mean(FNR)\n",
    "    TP_micro = np.sum(TP)\n",
    "    FP_micro = np.sum(FP)\n",
    "    FN_micro = np.sum(FN)\n",
    "    TN_micro = np.sum(TN)\n",
    "\n",
    "    # Micro averages for applicable metrics\n",
    "    TPR_micro = TP_micro / (TP_micro + FN_micro)\n",
    "    FPR_micro = FP_micro / (FP_micro + TN_micro)\n",
    "\n",
    "    \n",
    "    # Print the results for each epsilon\n",
    "    print(f\"Model: {model}\")\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "    print(f\"Micro Precision: {precision_micro:.2f}\")\n",
    "    print(f\"Macro Precision: {precision_macro:.2f}\")\n",
    "    print(f\"Micro Recall: {recall_micro:.2f}\")\n",
    "    print(f\"Macro Recall: {recall_macro:.2f}\")\n",
    "    print(f\"Micro F1 Score: {fscore_micro:.2f}\")\n",
    "    print(f\"Macro F1 Score: {fscore_macro:.2f}\")\n",
    "    print(f\"Average TNR: {TNR_avg:.2f}, Average FPR: {FPR_avg:.2f}, Average FNR: {FNR_avg:.2f}\\n\")\n",
    "    print(f\"Macro TNR: {TNR_avg:.2f}, Macro FNR: {FNR_avg:.2f},Macro FPR: {FPR_avg:.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cf922b-4f7c-4537-a1ce-b1763137a0ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
