{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "980cd33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c9e3ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24749/2769549640.py:1: DtypeWarning: Columns (2,3,6,11,13,14,15,16,17,31,32,34,39,45,51,54,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('DNN-EdgeIIoT-dataset.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('DNN-EdgeIIoT-dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74bf277f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame.time</th>\n",
       "      <th>ip.src_host</th>\n",
       "      <th>ip.dst_host</th>\n",
       "      <th>arp.dst.proto_ipv4</th>\n",
       "      <th>arp.opcode</th>\n",
       "      <th>arp.hw.size</th>\n",
       "      <th>arp.src.proto_ipv4</th>\n",
       "      <th>icmp.checksum</th>\n",
       "      <th>icmp.seq_le</th>\n",
       "      <th>icmp.transmit_timestamp</th>\n",
       "      <th>...</th>\n",
       "      <th>mqtt.proto_len</th>\n",
       "      <th>mqtt.protoname</th>\n",
       "      <th>mqtt.topic</th>\n",
       "      <th>mqtt.topic_len</th>\n",
       "      <th>mqtt.ver</th>\n",
       "      <th>mbtcp.len</th>\n",
       "      <th>mbtcp.trans_id</th>\n",
       "      <th>mbtcp.unit_id</th>\n",
       "      <th>Attack_label</th>\n",
       "      <th>Attack_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021 11:44:10.081753000</td>\n",
       "      <td>192.168.0.128</td>\n",
       "      <td>192.168.0.101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021 11:44:10.162218000</td>\n",
       "      <td>192.168.0.101</td>\n",
       "      <td>192.168.0.128</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>MQTT</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021 11:44:10.162271000</td>\n",
       "      <td>192.168.0.128</td>\n",
       "      <td>192.168.0.101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021 11:44:10.162641000</td>\n",
       "      <td>192.168.0.128</td>\n",
       "      <td>192.168.0.101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021 11:44:10.166132000</td>\n",
       "      <td>192.168.0.101</td>\n",
       "      <td>192.168.0.128</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Temperature_and_Humidity</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219196</th>\n",
       "      <td>2021 23:24:32.816050000</td>\n",
       "      <td>166.75.162.225</td>\n",
       "      <td>192.168.0.128</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31814.0</td>\n",
       "      <td>45620.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DDoS_ICMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219197</th>\n",
       "      <td>2021 23:24:32.816595000</td>\n",
       "      <td>70.162.34.183</td>\n",
       "      <td>192.168.0.128</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>27718.0</td>\n",
       "      <td>45636.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DDoS_ICMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219198</th>\n",
       "      <td>2021 23:24:32.818043000</td>\n",
       "      <td>40.13.95.244</td>\n",
       "      <td>192.168.0.128</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>18502.0</td>\n",
       "      <td>45672.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DDoS_ICMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219199</th>\n",
       "      <td>2021 23:24:32.820831000</td>\n",
       "      <td>18.132.75.125</td>\n",
       "      <td>192.168.0.128</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1862.0</td>\n",
       "      <td>45737.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DDoS_ICMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219200</th>\n",
       "      <td>2021 23:24:32.823654000</td>\n",
       "      <td>82.173.42.163</td>\n",
       "      <td>192.168.0.128</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>50245.0</td>\n",
       "      <td>45804.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DDoS_ICMP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2219201 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        frame.time     ip.src_host    ip.dst_host  \\\n",
       "0         2021 11:44:10.081753000    192.168.0.128  192.168.0.101   \n",
       "1         2021 11:44:10.162218000    192.168.0.101  192.168.0.128   \n",
       "2         2021 11:44:10.162271000    192.168.0.128  192.168.0.101   \n",
       "3         2021 11:44:10.162641000    192.168.0.128  192.168.0.101   \n",
       "4         2021 11:44:10.166132000    192.168.0.101  192.168.0.128   \n",
       "...                            ...             ...            ...   \n",
       "2219196   2021 23:24:32.816050000   166.75.162.225  192.168.0.128   \n",
       "2219197   2021 23:24:32.816595000    70.162.34.183  192.168.0.128   \n",
       "2219198   2021 23:24:32.818043000     40.13.95.244  192.168.0.128   \n",
       "2219199   2021 23:24:32.820831000    18.132.75.125  192.168.0.128   \n",
       "2219200   2021 23:24:32.823654000    82.173.42.163  192.168.0.128   \n",
       "\n",
       "        arp.dst.proto_ipv4  arp.opcode  arp.hw.size arp.src.proto_ipv4  \\\n",
       "0                        0         0.0          0.0                  0   \n",
       "1                        0         0.0          0.0                  0   \n",
       "2                        0         0.0          0.0                  0   \n",
       "3                        0         0.0          0.0                  0   \n",
       "4                        0         0.0          0.0                  0   \n",
       "...                    ...         ...          ...                ...   \n",
       "2219196                  0         0.0          0.0                  0   \n",
       "2219197                  0         0.0          0.0                  0   \n",
       "2219198                  0         0.0          0.0                  0   \n",
       "2219199                  0         0.0          0.0                  0   \n",
       "2219200                  0         0.0          0.0                  0   \n",
       "\n",
       "         icmp.checksum  icmp.seq_le  icmp.transmit_timestamp  ...  \\\n",
       "0                  0.0          0.0                      0.0  ...   \n",
       "1                  0.0          0.0                      0.0  ...   \n",
       "2                  0.0          0.0                      0.0  ...   \n",
       "3                  0.0          0.0                      0.0  ...   \n",
       "4                  0.0          0.0                      0.0  ...   \n",
       "...                ...          ...                      ...  ...   \n",
       "2219196        31814.0      45620.0                      0.0  ...   \n",
       "2219197        27718.0      45636.0                      0.0  ...   \n",
       "2219198        18502.0      45672.0                      0.0  ...   \n",
       "2219199         1862.0      45737.0                      0.0  ...   \n",
       "2219200        50245.0      45804.0                      0.0  ...   \n",
       "\n",
       "         mqtt.proto_len mqtt.protoname                mqtt.topic  \\\n",
       "0                   0.0              0                         0   \n",
       "1                   4.0           MQTT                         0   \n",
       "2                   0.0              0                         0   \n",
       "3                   0.0              0                         0   \n",
       "4                   0.0              0  Temperature_and_Humidity   \n",
       "...                 ...            ...                       ...   \n",
       "2219196             0.0            0.0                       0.0   \n",
       "2219197             0.0            0.0                       0.0   \n",
       "2219198             0.0            0.0                       0.0   \n",
       "2219199             0.0            0.0                       0.0   \n",
       "2219200             0.0            0.0                       0.0   \n",
       "\n",
       "        mqtt.topic_len mqtt.ver mbtcp.len mbtcp.trans_id mbtcp.unit_id  \\\n",
       "0                  0.0      0.0       0.0            0.0           0.0   \n",
       "1                  0.0      4.0       0.0            0.0           0.0   \n",
       "2                  0.0      0.0       0.0            0.0           0.0   \n",
       "3                  0.0      0.0       0.0            0.0           0.0   \n",
       "4                 24.0      0.0       0.0            0.0           0.0   \n",
       "...                ...      ...       ...            ...           ...   \n",
       "2219196            0.0      0.0       0.0            0.0           0.0   \n",
       "2219197            0.0      0.0       0.0            0.0           0.0   \n",
       "2219198            0.0      0.0       0.0            0.0           0.0   \n",
       "2219199            0.0      0.0       0.0            0.0           0.0   \n",
       "2219200            0.0      0.0       0.0            0.0           0.0   \n",
       "\n",
       "         Attack_label  Attack_type  \n",
       "0                   0       Normal  \n",
       "1                   0       Normal  \n",
       "2                   0       Normal  \n",
       "3                   0       Normal  \n",
       "4                   0       Normal  \n",
       "...               ...          ...  \n",
       "2219196             1    DDoS_ICMP  \n",
       "2219197             1    DDoS_ICMP  \n",
       "2219198             1    DDoS_ICMP  \n",
       "2219199             1    DDoS_ICMP  \n",
       "2219200             1    DDoS_ICMP  \n",
       "\n",
       "[2219201 rows x 63 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d29e96d",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "520fe863",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/extmath.py:1069: RuntimeWarning: overflow encountered in square\n",
      "  temp **= 2\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/extmath.py:1075: RuntimeWarning: overflow encountered in square\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/extmath.py:1075: RuntimeWarning: invalid value encountered in subtract\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/preprocessing/_data.py:83: RuntimeWarning: overflow encountered in square\n",
      "  upper_bound = n_samples * eps * var + (n_samples * mean * eps) ** 2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Assuming df is your pandas DataFrame\n",
    "# Separate features and target variable\n",
    "\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "midpoint = len(df) // 2\n",
    "df = df.iloc[:midpoint, :]\n",
    "\n",
    "for col in df.columns:\n",
    "    \n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "df = df.fillna(0)\n",
    "\n",
    "X = df.drop(columns=['Attack_label','Attack_type'])\n",
    "y = df['Attack_label']\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "y_train_tensor = torch.LongTensor(y_train.values).to(device)\n",
    "X_val_tensor = torch.FloatTensor(X_val).to(device)\n",
    "y_val_tensor = torch.LongTensor(y_val.values).to(device)\n",
    "X_test_tensor = torch.FloatTensor(X_test).to(device)\n",
    "y_test_tensor = torch.LongTensor(y_test.values).to(device)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 64  # You can adjust this\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a0bc098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNN(\n",
       "  (layer1): Linear(in_features=61, out_features=128, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (layer2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (layer3): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (output): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(DNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(128, 64)\n",
    "        self.layer3 = nn.Linear(64, 32)\n",
    "        self.output = nn.Linear(32, 2)  # Assuming binary classification for Attack_label\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.relu(self.layer3(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# Determine the input size for the first layer of the network\n",
    "input_size = X_train_tensor.shape[1]\n",
    "\n",
    "# Instantiate the model\n",
    "dnn_model = DNN(input_size)\n",
    "\n",
    "dnn_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c2d4b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tensor.device)\n",
    "print(y_train_tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f842cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: nan\n",
      "Epoch [2/10], Loss: nan\n",
      "Epoch [3/10], Loss: nan\n",
      "Epoch [4/10], Loss: nan\n",
      "Epoch [5/10], Loss: nan\n",
      "Epoch [6/10], Loss: nan\n",
      "Epoch [7/10], Loss: nan\n",
      "Epoch [8/10], Loss: nan\n",
      "Epoch [9/10], Loss: nan\n",
      "Epoch [10/10], Loss: nan\n",
      "Training completed\n"
     ]
    }
   ],
   "source": [
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(dnn_model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10  # You can adjust this\n",
    "for epoch in range(num_epochs):\n",
    "    dnn_model.train()  # Set the model to training mode\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = dnn_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # Optionally, you can add a validation step here\n",
    "\n",
    "print('Training completed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdd6e9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Ensure the model is in evaluation mode\n",
    "dnn_model.eval()\n",
    "\n",
    "# No gradient is needed for evaluation\n",
    "with torch.no_grad():\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = dnn_model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "# Convert lists to numpy arrays for metric calculation\n",
    "y_pred = np.array(y_pred)\n",
    "y_true = np.array(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bfa92f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of DNN: 0.7294\n",
      "Precision of DNN: 0.0000\n",
      "Recall (TPR) of DNN: 0.0000\n",
      "F1 Score of DNN: 0.0000\n",
      "AUC of DNN: 0.5000\n",
      "FPR of DNN: 0.0000\n",
      "FNR of DNN: 1.0000\n",
      "TNR of DNN: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "# Calculating TPR, FPR, FNR, TNR\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "fnr = fn / (tp + fn)\n",
    "tnr = tn / (tn + fp)\n",
    "\n",
    "# Other metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)  # Same as TPR\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "auc = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Accuracy of DNN: {accuracy:.4f}\")\n",
    "print(f\"Precision of DNN: {precision:.4f}\")\n",
    "print(f\"Recall (TPR) of DNN: {recall:.4f}\")\n",
    "print(f\"F1 Score of DNN: {f1:.4f}\")\n",
    "print(f\"AUC of DNN: {auc:.4f}\")\n",
    "print(f\"FPR of DNN: {fpr:.4f}\")\n",
    "print(f\"FNR of DNN: {fnr:.4f}\")\n",
    "print(f\"TNR of DNN: {tnr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f827cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "all_true = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to('cuda')\n",
    "        outputs = dnn_model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_true.extend(labels.cpu().numpy())\n",
    "# Convert to numpy arrays\n",
    "all_predictions = np.array(all_preds)\n",
    "all_labels = np.array(all_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1ea0525-bf36-4357-adba-5a6a90e63f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7294\n",
      "Precision: 0.5320\n",
      "Recall: 0.7294\n",
      "F1 Score: 0.6152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "precision = precision_score(all_labels, all_predictions, average='weighted')\n",
    "recall = recall_score(all_labels, all_predictions, average='weighted')\n",
    "f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "\n",
    "# Print the metrics\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0963d4d-e7f9-4eb5-8438-054f7c867fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7293709444844989\n",
      "Precision: 0.36468547224224945\n",
      "Recall: 0.5\n",
      "F1 Score: 0.4217550588615412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "precision = precision_score(all_labels, all_predictions, average='macro')\n",
    "recall = recall_score(all_labels, all_predictions, average='macro')\n",
    "f1 = f1_score(all_labels, all_predictions, average='macro')\n",
    "\n",
    "# Print the metrics\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1a458da-3e8c-443d-a41b-29acf75943b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7293709444844989\n",
      "Precision: 0.7293709444844989\n",
      "Recall: 0.7293709444844989\n",
      "F1 Score: 0.7293709444844989\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "precision = precision_score(all_labels, all_predictions, average='micro')\n",
    "recall = recall_score(all_labels, all_predictions, average='micro')\n",
    "f1 = f1_score(all_labels, all_predictions, average='micro')\n",
    "\n",
    "# Print the metrics\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "027b228d-9638-4c73-b74b-7c261a93cb6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Macro True Positive Rate (TPR)': 0.5,\n",
       " 'Macro False Positive Rate (FPR)': 0.5,\n",
       " 'Macro False Negative Rate (FNR)': 0.5,\n",
       " 'Macro True Negative Rate (TNR)': 0.5}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(all_true, all_preds)\n",
    "num_classes = 2\n",
    "total_TPR, total_FPR, total_FNR, total_TNR = 0, 0, 0, 0\n",
    "\n",
    "for i in range(num_classes):\n",
    "    TP = conf_matrix[i, i]\n",
    "    FP = np.sum(conf_matrix[:, i]) - TP\n",
    "    FN = np.sum(conf_matrix[i, :]) - TP\n",
    "    TN = np.sum(conf_matrix) - TP - FP - FN\n",
    "\n",
    "    TPR = TP / (TP + FN) if TP + FN > 0 else 0\n",
    "    FPR = FP / (FP + TN) if FP + TN > 0 else 0\n",
    "    FNR = FN / (FN + TP) if FN + TP > 0 else 0\n",
    "    TNR = TN / (TN + FP) if TN + FP > 0 else 0\n",
    "\n",
    "    total_TPR += TPR\n",
    "    total_FPR += FPR\n",
    "    total_FNR += FNR\n",
    "    total_TNR += TNR\n",
    "\n",
    "macro_TPR = total_TPR / num_classes\n",
    "macro_FPR = total_FPR / num_classes\n",
    "macro_FNR = total_FNR / num_classes\n",
    "macro_TNR = total_TNR / num_classes\n",
    "\n",
    "macro_metrics = {\n",
    "    \"Macro True Positive Rate (TPR)\": round(macro_TPR, 4),\n",
    "    \"Macro False Positive Rate (FPR)\": round(macro_FPR, 4),\n",
    "    \"Macro False Negative Rate (FNR)\": round(macro_FNR, 4),\n",
    "    \"Macro True Negative Rate (TNR)\": round(macro_TNR, 4)\n",
    "}\n",
    "\n",
    "macro_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8db21c98-bb5e-4c04-aa01-07a49f4ea6d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Micro True Positive Rate (TPR)': 0.7294,\n",
       " 'Micro False Positive Rate (FPR)': 0.2706,\n",
       " 'Micro False Negative Rate (FNR)': 0.2706,\n",
       " 'Micro True Negative Rate (TNR)': 0.7294}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 2\n",
    "total_TP, total_FP, total_FN, total_TN = 0, 0, 0, 0\n",
    "\n",
    "for i in range(num_classes):\n",
    "    TP = conf_matrix[i, i]\n",
    "    FP = np.sum(conf_matrix[:, i]) - TP\n",
    "    FN = np.sum(conf_matrix[i, :]) - TP\n",
    "    TN = np.sum(conf_matrix) - TP - FP - FN\n",
    "\n",
    "    total_TP += TP\n",
    "    total_FP += FP\n",
    "    total_FN += FN\n",
    "    total_TN += TN\n",
    "\n",
    "micro_TPR = total_TP / (total_TP + total_FN) if total_TP + total_FN > 0 else 0\n",
    "micro_FPR = total_FP / (total_FP + total_TN) if total_FP + total_TN > 0 else 0\n",
    "micro_FNR = total_FN / (total_FN + total_TP) if total_FN + total_TP > 0 else 0\n",
    "micro_TNR = total_TN / (total_TN + total_FP) if total_TN + total_FP > 0 else 0\n",
    "\n",
    "micro_metrics = {\n",
    "    \"Micro True Positive Rate (TPR)\": round(micro_TPR, 4),\n",
    "    \"Micro False Positive Rate (FPR)\": round(micro_FPR, 4),\n",
    "    \"Micro False Negative Rate (FNR)\": round(micro_FNR, 4),\n",
    "    \"Micro True Negative Rate (TNR)\": round(micro_TNR, 4)\n",
    "}\n",
    "\n",
    "micro_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd022563-b444-420d-9481-c47d76e3a254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Weighted True Positive Rate (TPR)': 0.7294,\n",
       " 'Weighted False Positive Rate (FPR)': 0.7294,\n",
       " 'Weighted False Negative Rate (FNR)': 0.2706,\n",
       " 'Weighted True Negative Rate (TNR)': 0.2706}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 2\n",
    "weighted_TPR, weighted_FPR, weighted_FNR, weighted_TNR = 0, 0, 0, 0\n",
    "total_instances = np.sum(conf_matrix)\n",
    "\n",
    "for i in range(num_classes):\n",
    "    TP = conf_matrix[i, i]\n",
    "    FP = np.sum(conf_matrix[:, i]) - TP\n",
    "    FN = np.sum(conf_matrix[i, :]) - TP\n",
    "    TN = np.sum(conf_matrix) - TP - FP - FN\n",
    "\n",
    "    TPR = TP / (TP + FN) if TP + FN > 0 else 0\n",
    "    FPR = FP / (FP + TN) if FP + TN > 0 else 0\n",
    "    FNR = FN / (FN + TP) if FN + TP > 0 else 0\n",
    "    TNR = TN / (TN + FP) if TN + FP > 0 else 0\n",
    "\n",
    "    class_weight = np.sum(conf_matrix[i, :]) / total_instances\n",
    "\n",
    "    weighted_TPR += TPR * class_weight\n",
    "    weighted_FPR += FPR * class_weight\n",
    "    weighted_FNR += FNR * class_weight\n",
    "    weighted_TNR += TNR * class_weight\n",
    "\n",
    "weighted_metrics = {\n",
    "    \"Weighted True Positive Rate (TPR)\": round(weighted_TPR, 4),\n",
    "    \"Weighted False Positive Rate (FPR)\": round(weighted_FPR, 4),\n",
    "    \"Weighted False Negative Rate (FNR)\": round(weighted_FNR, 4),\n",
    "    \"Weighted True Negative Rate (TNR)\": round(weighted_TNR, 4)\n",
    "}\n",
    "\n",
    "weighted_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c75c28-58cf-4aff-bafa-a621f25e7377",
   "metadata": {},
   "source": [
    "## Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "537cea32-d7a8-46e8-bf44-d75c2407addd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cc89e95-5b02-412c-ab12-25a9849911f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(dnn_model.parameters(), lr=0.001)\n",
    "input_shape = (df.shape[1],)\n",
    "# Wrap the model\n",
    "classifier = PyTorchClassifier(\n",
    "    model=dnn_model,\n",
    "    clip_values=(0, 1),\n",
    "    loss=criterion,\n",
    "    optimizer=optimizer,\n",
    "    input_shape = input_shape,\n",
    "    nb_classes=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c98e84f6-5267-4aa0-bde2-b2bf0f182dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon: 0.01\n",
      "Accuracy: 0.7293709444844989\n",
      "Micro Precision: 0.73\n",
      "Macro Precision: 0.36\n",
      "Micro Recall: 0.73\n",
      "Macro Recall: 0.50\n",
      "Micro F1 Score: 0.73\n",
      "Macro F1 Score: 0.42\n",
      "Average TNR: 0.50, Average FPR: 0.50, Average FNR: 0.50\n",
      "\n",
      "Macro TNR: 0.50, Macro FNR: 0.50,Macro FPR: 0.50\n",
      "\n",
      "Epsilon: 0.1\n",
      "Accuracy: 0.7293709444844989\n",
      "Micro Precision: 0.73\n",
      "Macro Precision: 0.36\n",
      "Micro Recall: 0.73\n",
      "Macro Recall: 0.50\n",
      "Micro F1 Score: 0.73\n",
      "Macro F1 Score: 0.42\n",
      "Average TNR: 0.50, Average FPR: 0.50, Average FNR: 0.50\n",
      "\n",
      "Macro TNR: 0.50, Macro FNR: 0.50,Macro FPR: 0.50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "# Ensure X_test and y_test are correctly prepared before this point\n",
    "if len(y_test.shape) > 1 and y_test.shape[1] > 1:\n",
    "    y_test_indices = np.argmax(y_test, axis=1)\n",
    "else:\n",
    "    y_test_indices = y_test\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "epsilon_values = [0.01, 0.1]\n",
    "\n",
    "for epsilon in epsilon_values:\n",
    "    # Craft adversarial samples with FGSM\n",
    "    adv_crafter = FastGradientMethod(classifier, eps=epsilon)\n",
    "    x_test_adv = adv_crafter.generate(x=X_test)\n",
    "\n",
    "    # Save the adversarial examples to a file\n",
    "    filename = f'x_test_adv_FGSM_eps_{epsilon}.npy'\n",
    "    np.save(filename, x_test_adv)\n",
    "    \n",
    "    # Evaluate the classifier on the adversarial examples\n",
    "    preds_FGSM = np.argmax(classifier.predict(x_test_adv), axis=1)\n",
    "\n",
    "   # Calculate precision, recall, and F1 score\n",
    "    precision_micro, recall_micro, fscore_micro, _ = precision_recall_fscore_support(\n",
    "        y_test_indices, preds_FGSM, average='micro')\n",
    "    precision_macro, recall_macro, fscore_macro, _ = precision_recall_fscore_support(\n",
    "        y_test_indices, preds_FGSM, average='macro')\n",
    "\n",
    "    # Calculate accuracy for reference\n",
    "    acc = np.sum(preds_FGSM == y_test_indices) / y_test_indices.shape[0]\n",
    "\n",
    "    # Calculate confusion matrix and then TPR, TNR, FPR, FNR for each class\n",
    "    conf_matrix = confusion_matrix(y_test_indices, preds_FGSM)\n",
    "    FP = conf_matrix.sum(axis=0) - np.diag(conf_matrix)  \n",
    "    FN = conf_matrix.sum(axis=1) - np.diag(conf_matrix)\n",
    "    TP = np.diag(conf_matrix)\n",
    "    TN = conf_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "    TPR = TP / (TP + FN)\n",
    "    TNR = TN / (TN + FP)\n",
    "    FPR = FP / (FP + TN)\n",
    "    FNR = FN / (TP + FN)\n",
    "\n",
    "    # Averaging TPR, TNR, FPR, FNR\n",
    "    TPR_avg = np.mean(TPR)\n",
    "    TNR_avg = np.mean(TNR)\n",
    "    FPR_avg = np.mean(FPR)\n",
    "    FNR_avg = np.mean(FNR)\n",
    "    TP_micro = np.sum(TP)\n",
    "    FP_micro = np.sum(FP)\n",
    "    FN_micro = np.sum(FN)\n",
    "    TN_micro = np.sum(TN)\n",
    "\n",
    "    # Micro averages for applicable metrics\n",
    "    TPR_micro = TP_micro / (TP_micro + FN_micro)\n",
    "    FPR_micro = FP_micro / (FP_micro + TN_micro)\n",
    "\n",
    "    \n",
    "    # Print the results for each epsilon\n",
    "    print(f\"Epsilon: {epsilon}\")\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "    print(f\"Micro Precision: {precision_micro:.2f}\")\n",
    "    print(f\"Macro Precision: {precision_macro:.2f}\")\n",
    "    print(f\"Micro Recall: {recall_micro:.2f}\")\n",
    "    print(f\"Macro Recall: {recall_macro:.2f}\")\n",
    "    print(f\"Micro F1 Score: {fscore_micro:.2f}\")\n",
    "    print(f\"Macro F1 Score: {fscore_macro:.2f}\")\n",
    "    print(f\"Average TNR: {TNR_avg:.2f}, Average FPR: {FPR_avg:.2f}, Average FNR: {FNR_avg:.2f}\\n\")\n",
    "    print(f\"Macro TNR: {TNR_avg:.2f}, Macro FNR: {FNR_avg:.2f},Macro FPR: {FPR_avg:.2f}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "885fa1b7-8ecf-4783-ac46-116d8a13d0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon: 0.01\n",
      "Accuracy: 0.7293709444844989\n",
      "Micro Precision: 0.73\n",
      "Macro Precision: 0.36\n",
      "Micro Recall: 0.73\n",
      "Macro Recall: 0.50\n",
      "Micro F1 Score: 0.73\n",
      "Macro F1 Score: 0.42\n",
      "Average TNR: 0.50, Average FPR: 0.50, Average FNR: 0.50\n",
      "\n",
      "Macro TNR: 0.50, Macro FNR: 0.50,Macro FPR: 0.50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon: 0.1\n",
      "Accuracy: 0.7293709444844989\n",
      "Micro Precision: 0.73\n",
      "Macro Precision: 0.36\n",
      "Micro Recall: 0.73\n",
      "Macro Recall: 0.50\n",
      "Micro F1 Score: 0.73\n",
      "Macro F1 Score: 0.42\n",
      "Average TNR: 0.50, Average FPR: 0.50, Average FNR: 0.50\n",
      "\n",
      "Macro TNR: 0.50, Macro FNR: 0.50,Macro FPR: 0.50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from art.attacks.evasion import ProjectedGradientDescent\n",
    "eps_step_value = 0.01  \n",
    "max_iter_value = 10 \n",
    "# Convert the one-hot encoded labels to class indices if necessary\n",
    "if len(y_test.shape) > 1 and y_test.shape[1] > 1:\n",
    "    y_test_indices = np.argmax(y_test, axis=1)\n",
    "else:\n",
    "    y_test_indices = y_test  # If y_test is already class indices\n",
    "\n",
    "# Iterate over epsilon values\n",
    "for epsilon in epsilon_values:\n",
    "    # Craft adversarial samples with PGD\n",
    "    adv_crafter = ProjectedGradientDescent(\n",
    "        classifier,\n",
    "        eps=epsilon,\n",
    "        eps_step=eps_step_value,\n",
    "        max_iter=max_iter_value\n",
    "    )\n",
    "    x_test_adv = adv_crafter.generate(x=X_test)\n",
    "\n",
    "    # Evaluate the classifier on the adversarial examples\n",
    "    preds_PDG = np.argmax(classifier.predict(x_test_adv), axis=1)\n",
    "\n",
    "    filename = f'x_test_adv_PGD_eps_{epsilon}.npy'\n",
    "    np.save(filename, x_test_adv)\n",
    "    \n",
    "    # Calculate micro and macro precision, recall, and F1 score\n",
    "    precision_micro, recall_micro, fscore_micro, _ = precision_recall_fscore_support(\n",
    "        y_test_indices, preds_PDG, average='micro')\n",
    "    precision_macro, recall_macro, fscore_macro, _ = precision_recall_fscore_support(\n",
    "        y_test_indices, preds_PDG, average='macro')\n",
    "    \n",
    "        # Calculate accuracy for reference\n",
    "    acc = np.sum(preds_FGSM == y_test_indices) / y_test_indices.shape[0]\n",
    "    \n",
    "    # Calculate confusion matrix and then TPR, TNR, FPR, FNR for each class\n",
    "    conf_matrix = confusion_matrix(y_test_indices, preds_PDG)\n",
    "    FP = conf_matrix.sum(axis=0) - np.diag(conf_matrix)  \n",
    "    FN = conf_matrix.sum(axis=1) - np.diag(conf_matrix)\n",
    "    TP = np.diag(conf_matrix)\n",
    "    TN = conf_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "    TPR = TP / (TP + FN)\n",
    "    TNR = TN / (TN + FP)\n",
    "    FPR = FP / (FP + TN)\n",
    "    FNR = FN / (TP + FN)\n",
    "\n",
    "    # Averaging TPR, TNR, FPR, FNR\n",
    "    TPR_avg = np.mean(TPR)\n",
    "    TNR_avg = np.mean(TNR)\n",
    "    FPR_avg = np.mean(FPR)\n",
    "    FNR_avg = np.mean(FNR)\n",
    "    TP_micro = np.sum(TP)\n",
    "    FP_micro = np.sum(FP)\n",
    "    FN_micro = np.sum(FN)\n",
    "    TN_micro = np.sum(TN)\n",
    "\n",
    "    # Micro averages for applicable metrics\n",
    "    TPR_micro = TP_micro / (TP_micro + FN_micro)\n",
    "    FPR_micro = FP_micro / (FP_micro + TN_micro)\n",
    "\n",
    "    \n",
    "    # Print the results for each epsilon\n",
    "    print(f\"Epsilon: {epsilon}\")\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "    print(f\"Micro Precision: {precision_micro:.2f}\")\n",
    "    print(f\"Macro Precision: {precision_macro:.2f}\")\n",
    "    print(f\"Micro Recall: {recall_micro:.2f}\")\n",
    "    print(f\"Macro Recall: {recall_macro:.2f}\")\n",
    "    print(f\"Micro F1 Score: {fscore_micro:.2f}\")\n",
    "    print(f\"Macro F1 Score: {fscore_macro:.2f}\")\n",
    "    print(f\"Average TNR: {TNR_avg:.2f}, Average FPR: {FPR_avg:.2f}, Average FNR: {FNR_avg:.2f}\\n\")\n",
    "    print(f\"Macro TNR: {TNR_avg:.2f}, Macro FNR: {FNR_avg:.2f},Macro FPR: {FPR_avg:.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7656f13-c164-4fe2-9895-eff49bf9d0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon: 0.01\n",
      "Accuracy: 0.7293709444844989\n",
      "Micro Precision: 0.73\n",
      "Macro Precision: 0.36\n",
      "Micro Recall: 0.73\n",
      "Macro Recall: 0.50\n",
      "Micro F1 Score: 0.73\n",
      "Macro F1 Score: 0.42\n",
      "Average TNR: 0.50, Average FPR: 0.50, Average FNR: 0.50\n",
      "\n",
      "Macro TNR: 0.50, Macro FNR: 0.50,Macro FPR: 0.50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon: 0.1\n",
      "Accuracy: 0.7293709444844989\n",
      "Micro Precision: 0.73\n",
      "Macro Precision: 0.36\n",
      "Micro Recall: 0.73\n",
      "Macro Recall: 0.50\n",
      "Micro F1 Score: 0.73\n",
      "Macro F1 Score: 0.42\n",
      "Average TNR: 0.50, Average FPR: 0.50, Average FNR: 0.50\n",
      "\n",
      "Macro TNR: 0.50, Macro FNR: 0.50,Macro FPR: 0.50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from art.attacks.evasion import BasicIterativeMethod\n",
    "eps_step_value = 0.01  \n",
    "max_iter_value = 10 \n",
    "# Convert the one-hot encoded labels to class indices if necessary\n",
    "if len(y_test.shape) > 1 and y_test.shape[1] > 1:\n",
    "    y_test_indices = np.argmax(y_test, axis=1)\n",
    "else:\n",
    "    y_test_indices = y_test  # If y_test is already class indices\n",
    "\n",
    "# Iterate over epsilon values\n",
    "for epsilon in epsilon_values:\n",
    "    # Craft adversarial samples with PGD\n",
    "    adv_crafter = BasicIterativeMethod(\n",
    "        classifier,\n",
    "        eps=epsilon,\n",
    "    )\n",
    "    x_test_adv = adv_crafter.generate(x=X_test)\n",
    "\n",
    "    # Evaluate the classifier on the adversarial examples\n",
    "    preds_BIM = np.argmax(classifier.predict(x_test_adv), axis=1)\n",
    "    \n",
    "    filename = f'x_test_adv_BIM_eps_{epsilon}.npy'\n",
    "    np.save(filename, x_test_adv)\n",
    "    \n",
    "    # Calculate micro and macro precision, recall, and F1 score\n",
    "    precision_micro, recall_micro, fscore_micro, _ = precision_recall_fscore_support(\n",
    "        y_test_indices, preds_BIM, average='micro')\n",
    "    precision_macro, recall_macro, fscore_macro, _ = precision_recall_fscore_support(\n",
    "        y_test_indices, preds_BIM, average='macro')\n",
    "        # Calculate accuracy for reference\n",
    "    acc = np.sum(preds_FGSM == y_test_indices) / y_test_indices.shape[0]\n",
    "    # Calculate confusion matrix and then TPR, TNR, FPR, FNR for each class\n",
    "    conf_matrix = confusion_matrix(y_test_indices, preds_BIM)\n",
    "    FP = conf_matrix.sum(axis=0) - np.diag(conf_matrix)  \n",
    "    FN = conf_matrix.sum(axis=1) - np.diag(conf_matrix)\n",
    "    TP = np.diag(conf_matrix)\n",
    "    TN = conf_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "    TPR = TP / (TP + FN)\n",
    "    TNR = TN / (TN + FP)\n",
    "    FPR = FP / (FP + TN)\n",
    "    FNR = FN / (TP + FN)\n",
    "\n",
    "    # Averaging TPR, TNR, FPR, FNR\n",
    "    TPR_avg = np.mean(TPR)\n",
    "    TNR_avg = np.mean(TNR)\n",
    "    FPR_avg = np.mean(FPR)\n",
    "    FNR_avg = np.mean(FNR)\n",
    "    TP_micro = np.sum(TP)\n",
    "    FP_micro = np.sum(FP)\n",
    "    FN_micro = np.sum(FN)\n",
    "    TN_micro = np.sum(TN)\n",
    "\n",
    "    # Micro averages for applicable metrics\n",
    "    TPR_micro = TP_micro / (TP_micro + FN_micro)\n",
    "    FPR_micro = FP_micro / (FP_micro + TN_micro)\n",
    "\n",
    "    \n",
    "    # Print the results for each epsilon\n",
    "    print(f\"Epsilon: {epsilon}\")\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "    print(f\"Micro Precision: {precision_micro:.2f}\")\n",
    "    print(f\"Macro Precision: {precision_macro:.2f}\")\n",
    "    print(f\"Micro Recall: {recall_micro:.2f}\")\n",
    "    print(f\"Macro Recall: {recall_macro:.2f}\")\n",
    "    print(f\"Micro F1 Score: {fscore_micro:.2f}\")\n",
    "    print(f\"Macro F1 Score: {fscore_macro:.2f}\")\n",
    "    print(f\"Average TNR: {TNR_avg:.2f}, Average FPR: {FPR_avg:.2f}, Average FNR: {FNR_avg:.2f}\\n\")\n",
    "    print(f\"Macro TNR: {TNR_avg:.2f}, Macro FNR: {FNR_avg:.2f},Macro FPR: {FPR_avg:.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4b25ed6-98ac-48c0-b70a-175aa16f6a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeepFool: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1734/1734 [10:10<00:00,  2.84it/s]\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon: 0.01\n",
      "Accuracy: 0.7293709444844989\n",
      "Micro Precision: 0.73\n",
      "Macro Precision: 0.36\n",
      "Micro Recall: 0.73\n",
      "Macro Recall: 0.50\n",
      "Micro F1 Score: 0.73\n",
      "Macro F1 Score: 0.42\n",
      "Average TNR: 0.50, Average FPR: 0.50, Average FNR: 0.50\n",
      "\n",
      "Macro TNR: 0.50, Macro FNR: 0.50,Macro FPR: 0.50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeepFool: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1734/1734 [09:49<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon: 0.1\n",
      "Accuracy: 0.7293709444844989\n",
      "Micro Precision: 0.73\n",
      "Macro Precision: 0.36\n",
      "Micro Recall: 0.73\n",
      "Macro Recall: 0.50\n",
      "Micro F1 Score: 0.73\n",
      "Macro F1 Score: 0.42\n",
      "Average TNR: 0.50, Average FPR: 0.50, Average FNR: 0.50\n",
      "\n",
      "Macro TNR: 0.50, Macro FNR: 0.50,Macro FPR: 0.50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from art.attacks.evasion import DeepFool\n",
    "\n",
    "eps_step_value = 0.01  \n",
    "max_iter_value = 10 \n",
    "# Convert the one-hot encoded labels to class indices if necessary\n",
    "if len(y_test.shape) > 1 and y_test.shape[1] > 1:\n",
    "    y_test_indices = np.argmax(y_test, axis=1)\n",
    "else:\n",
    "    y_test_indices = y_test  # If y_test is already class indices\n",
    "\n",
    "# Iterate over epsilon values\n",
    "for epsilon in epsilon_values:\n",
    "    # Craft adversarial samples with PGD\n",
    "    adv_crafter = DeepFool(\n",
    "        classifier,\n",
    "        epsilon=epsilon,\n",
    "        batch_size=128\n",
    "    )\n",
    "    x_test_adv = adv_crafter.generate(x=X_test)\n",
    "    \n",
    "    # Evaluate the classifier on the adversarial examples\n",
    "    preds_DF = np.argmax(classifier.predict(x_test_adv), axis=1)\n",
    "    filename = f'x_test_adv_DF_eps_{epsilon}.npy'\n",
    "    np.save(filename, x_test_adv)\n",
    "    \n",
    "    # Calculate micro and macro precision, recall, and F1 score\n",
    "    precision_micro, recall_micro, fscore_micro, _ = precision_recall_fscore_support(\n",
    "        y_test_indices, preds_DF, average='micro')\n",
    "    precision_macro, recall_macro, fscore_macro, _ = precision_recall_fscore_support(\n",
    "        y_test_indices, preds_DF, average='macro')\n",
    "        # Calculate accuracy for reference\n",
    "    acc = np.sum(preds_DF == y_test_indices) / y_test_indices.shape[0]\n",
    "    # Calculate confusion matrix and then TPR, TNR, FPR, FNR for each class\n",
    "    conf_matrix = confusion_matrix(y_test_indices, preds_DF)\n",
    "    FP = conf_matrix.sum(axis=0) - np.diag(conf_matrix)  \n",
    "    FN = conf_matrix.sum(axis=1) - np.diag(conf_matrix)\n",
    "    TP = np.diag(conf_matrix)\n",
    "    TN = conf_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "    TPR = TP / (TP + FN)\n",
    "    TNR = TN / (TN + FP)\n",
    "    FPR = FP / (FP + TN)\n",
    "    FNR = FN / (TP + FN)\n",
    "\n",
    "    # Averaging TPR, TNR, FPR, FNR\n",
    "    TPR_avg = np.mean(TPR)\n",
    "    TNR_avg = np.mean(TNR)\n",
    "    FPR_avg = np.mean(FPR)\n",
    "    FNR_avg = np.mean(FNR)\n",
    "    TP_micro = np.sum(TP)\n",
    "    FP_micro = np.sum(FP)\n",
    "    FN_micro = np.sum(FN)\n",
    "    TN_micro = np.sum(TN)\n",
    "\n",
    "    # Micro averages for applicable metrics\n",
    "    TPR_micro = TP_micro / (TP_micro + FN_micro)\n",
    "    FPR_micro = FP_micro / (FP_micro + TN_micro)\n",
    "\n",
    "    \n",
    "    # Print the results for each epsilon\n",
    "    print(f\"Epsilon: {epsilon}\")\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "    print(f\"Micro Precision: {precision_micro:.2f}\")\n",
    "    print(f\"Macro Precision: {precision_macro:.2f}\")\n",
    "    print(f\"Micro Recall: {recall_micro:.2f}\")\n",
    "    print(f\"Macro Recall: {recall_macro:.2f}\")\n",
    "    print(f\"Micro F1 Score: {fscore_micro:.2f}\")\n",
    "    print(f\"Macro F1 Score: {fscore_macro:.2f}\")\n",
    "    print(f\"Average TNR: {TNR_avg:.2f}, Average FPR: {FPR_avg:.2f}, Average FNR: {FNR_avg:.2f}\\n\")\n",
    "    print(f\"Macro TNR: {TNR_avg:.2f}, Macro FNR: {FNR_avg:.2f},Macro FPR: {FPR_avg:.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa5720f-508b-46a6-bbe2-343b2d12ab91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
