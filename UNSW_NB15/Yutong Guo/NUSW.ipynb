{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":267091,"sourceType":"datasetVersion","datasetId":111554}],"dockerImageVersionId":30178,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a id='top'></a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n    \n<h1 style=\"padding: 8px;color:white; display:fill;background-color:#555555; border-radius:5px; font-size:150%\"><b> Table of contents </b></h1>\n\n - [**Introduction**](#1)\n\n - [**Import and Set Up**](#2)\n \n - [**Pre-processing and feature selection**](#3)\n    \n - [**Modelling and Evaluation**](#4)\n    - [**Logistical Classification**](#4_1)\n    - [**kNN**](#4_2)\n    - [**Decision Tree**](#4_3)\n    - [**Extra Trees**](#4_4)\n    - [**Random Forest**](#4_5)\n    - [**Gradient Boosting Classifier**](#4_6)\n    - [**Neural Network MLP**](#4_7)\n    - [**Neural Network MLP (Keras)**](#4_8)\n    - [**GRU (Keras)**](#4_9)\n    - [**LSTM (Keras)**](#4_10)\n    \n - [**Evaluate**](#5)\n   ","metadata":{}},{"cell_type":"markdown","source":"<a id='1'></a>\n# <p style=\"padding: 8px;color:white; display:fill;background-color:#555555; border-radius:5px; font-size:100%\"> <b>Introduction</b>","metadata":{}},{"cell_type":"markdown","source":"This Notebook is about transforming and modelling the data. A previous notebook of mine did the EDA using pandas-profiling and sweetviz. So its not great to load here.\n\nThe study has an all-in approach (using all descriptive features). It can be improved by adding back propagation and removing the features with high P-values. I did not have the time or motivation to do this as well. ","metadata":{}},{"cell_type":"markdown","source":"<a id='2'></a>\n# <p style=\"padding: 8px;color:white; display:fill;background-color:#555555; border-radius:5px; font-size:100%\"> <b>Import and Set up</b>","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom IPython.core.display import display, HTML\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.io as pio\n\n\nimport seaborn as sns\nfrom importlib import reload\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport warnings\n\n# Configure Jupyter Notebook\npd.set_option('display.max_columns', None) \npd.set_option('display.max_rows', 500) \npd.set_option('display.expand_frame_repr', False)\n# pd.set_option('max_colwidth', -1)\ndisplay(HTML(\"<style>div.output_scroll { height: 35em; }</style>\"))\n\nreload(plt)\n%matplotlib inline\n%config InlineBackend.figure_format ='retina'\n\nwarnings.filterwarnings('ignore')\n\n# configure plotly graph objects\npio.renderers.default = 'iframe'\n# pio.renderers.default = 'vscode'\n\npio.templates[\"ck_template\"] = go.layout.Template(\n    layout_colorway = px.colors.sequential.Viridis, \n#     layout_hovermode = 'closest',\n#     layout_hoverdistance = -1,\n    layout_autosize=False,\n    layout_width=800,\n    layout_height=600,\n    layout_font = dict(family=\"Calibri Light\"),\n    layout_title_font = dict(family=\"Calibri\"),\n    layout_hoverlabel_font = dict(family=\"Calibri Light\"),\n#     plot_bgcolor=\"white\",\n)\n \n# pio.templates.default = 'seaborn+ck_template+gridon'\npio.templates.default = 'ck_template+gridon'\n# pio.templates.default = 'seaborn+gridon'\n# pio.templates","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-04-18T05:17:32.920777Z","iopub.execute_input":"2022-04-18T05:17:32.921176Z","iopub.status.idle":"2022-04-18T05:17:35.278171Z","shell.execute_reply.started":"2022-04-18T05:17:32.92107Z","shell.execute_reply":"2022-04-18T05:17:35.277461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/unsw-nb15/UNSW_NB15_training-set.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:17:35.279727Z","iopub.execute_input":"2022-04-18T05:17:35.279965Z","iopub.status.idle":"2022-04-18T05:17:35.850855Z","shell.execute_reply.started":"2022-04-18T05:17:35.279935Z","shell.execute_reply":"2022-04-18T05:17:35.85012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:17:35.852126Z","iopub.execute_input":"2022-04-18T05:17:35.852356Z","iopub.status.idle":"2022-04-18T05:17:36.037794Z","shell.execute_reply.started":"2022-04-18T05:17:35.852329Z","shell.execute_reply":"2022-04-18T05:17:36.037062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:17:36.039059Z","iopub.execute_input":"2022-04-18T05:17:36.039267Z","iopub.status.idle":"2022-04-18T05:17:36.082488Z","shell.execute_reply.started":"2022-04-18T05:17:36.039241Z","shell.execute_reply":"2022-04-18T05:17:36.081626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe(include='all')","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:17:36.085289Z","iopub.execute_input":"2022-04-18T05:17:36.085651Z","iopub.status.idle":"2022-04-18T05:17:36.382997Z","shell.execute_reply.started":"2022-04-18T05:17:36.085607Z","shell.execute_reply":"2022-04-18T05:17:36.382232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='3'></a>\n# <p style=\"padding: 8px;color:white; display:fill;background-color:#555555; border-radius:5px; font-size:100%\"> <b>Pre-processing and Feature Selection</b>","metadata":{"tags":[]}},{"cell_type":"markdown","source":"The data quality report was generated for Post Block Assignment 1. This section will process and select the features in accordance with the recommendations of that report. ","metadata":{"tags":[]}},{"cell_type":"markdown","source":"## Drop irrelevant or excess feastures\n\nThe first feature to drop is 'id'. This feature is an index and not descriptive. \n\nThe second feature to drop is 'attack_cat'. This feature is an extension of the target feature, therefore using it will give us 100% predictions but will not give us a generalizable model. \n\nThe other features to be dropped are those that were too strongly correlated. In this current version none of them were dropped, as the model is first evaluated to see how well it can perform.","metadata":{}},{"cell_type":"code","source":"list_drop = ['id','attack_cat']","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:17:36.384385Z","iopub.execute_input":"2022-04-18T05:17:36.384674Z","iopub.status.idle":"2022-04-18T05:17:36.389267Z","shell.execute_reply.started":"2022-04-18T05:17:36.384633Z","shell.execute_reply":"2022-04-18T05:17:36.388513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(list_drop,axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:17:36.390449Z","iopub.execute_input":"2022-04-18T05:17:36.390843Z","iopub.status.idle":"2022-04-18T05:17:36.40962Z","shell.execute_reply.started":"2022-04-18T05:17:36.390803Z","shell.execute_reply":"2022-04-18T05:17:36.408818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Apply Clamping\n\nThe extreme values should be pruned to reduce the skewness of some distributions. The logic applied here is that the features with a maximum value more than ten times the median value is pruned to the 95th percentile. If the 95th percentile is close to the maximum, then the tail has more interesting information than what we want to discard. \n\nThe clamping is also only applied to features with a maximum of more than 10 times the median. This prevents the bimodals and small value distributions from being excessively pruned.  ","metadata":{"tags":[]}},{"cell_type":"code","source":"# Clamp extreme Values\ndf_numeric = df.select_dtypes(include=[np.number])\ndf_numeric.describe(include='all')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-04-18T05:17:36.410498Z","iopub.execute_input":"2022-04-18T05:17:36.411005Z","iopub.status.idle":"2022-04-18T05:17:36.641366Z","shell.execute_reply.started":"2022-04-18T05:17:36.410973Z","shell.execute_reply":"2022-04-18T05:17:36.640817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEBUG =0\n\nfor feature in df_numeric.columns:\n    if DEBUG == 1:\n        print(feature)\n        print('max = '+str(df_numeric[feature].max()))\n        print('75th = '+str(df_numeric[feature].quantile(0.95)))\n        print('median = '+str(df_numeric[feature].median()))\n        print(df_numeric[feature].max()>10*df_numeric[feature].median())\n        print('----------------------------------------------------')\n    if df_numeric[feature].max()>10*df_numeric[feature].median() and df_numeric[feature].max()>10 :\n        df[feature] = np.where(df[feature]<df[feature].quantile(0.95), df[feature], df[feature].quantile(0.95))","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-04-18T05:17:36.642206Z","iopub.execute_input":"2022-04-18T05:17:36.642839Z","iopub.status.idle":"2022-04-18T05:17:36.88458Z","shell.execute_reply.started":"2022-04-18T05:17:36.642805Z","shell.execute_reply":"2022-04-18T05:17:36.883729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_numeric = df.select_dtypes(include=[np.number])\ndf_numeric.describe(include='all')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-04-18T05:17:36.885784Z","iopub.execute_input":"2022-04-18T05:17:36.886414Z","iopub.status.idle":"2022-04-18T05:17:37.129184Z","shell.execute_reply.started":"2022-04-18T05:17:36.886381Z","shell.execute_reply":"2022-04-18T05:17:37.128453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Apply log function to nearly all numeric, since they are all mostly skewed to the right\n\nIt would have been too much of a slog to apply the log function individually, therefore a simple rule has been set up: if the number of unique values in the continuous feature is more than 50 then apply the log function. The reason more than 50 unique values are sought is to filter out the integer based features that act more categorically.  ","metadata":{"tags":[]}},{"cell_type":"code","source":"df_numeric = df.select_dtypes(include=[np.number])\ndf_before = df_numeric.copy()\nDEBUG = 0\nfor feature in df_numeric.columns:\n    if DEBUG == 1:\n        print(feature)\n        print('nunique = '+str(df_numeric[feature].nunique()))\n        print(df_numeric[feature].nunique()>50)\n        print('----------------------------------------------------')\n    if df_numeric[feature].nunique()>50:\n        if df_numeric[feature].min()==0:\n            df[feature] = np.log(df[feature]+1)\n        else:\n            df[feature] = np.log(df[feature])\n\ndf_numeric = df.select_dtypes(include=[np.number])","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-04-18T05:17:37.130265Z","iopub.execute_input":"2022-04-18T05:17:37.130464Z","iopub.status.idle":"2022-04-18T05:17:37.243898Z","shell.execute_reply.started":"2022-04-18T05:17:37.130439Z","shell.execute_reply":"2022-04-18T05:17:37.243098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reduce the labels in catagorical features\n\nSome features have very high cardinalities, and this section reduces the cardinality to 5 or 6 per feature. The logic is to take the top 5 occuring labels in the feature as the labels and set the remainder to '-' (seldom used) labels. When the encoding is done later on, the dimensionality will not explode and cause the curse of dimensionality. ","metadata":{"tags":[]}},{"cell_type":"code","source":"df_cat = df.select_dtypes(exclude=[np.number])\ndf_cat.describe(include='all')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-04-18T05:17:37.245019Z","iopub.execute_input":"2022-04-18T05:17:37.24522Z","iopub.status.idle":"2022-04-18T05:17:37.325763Z","shell.execute_reply.started":"2022-04-18T05:17:37.245195Z","shell.execute_reply":"2022-04-18T05:17:37.324901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEBUG = 0\nfor feature in df_cat.columns:\n    if DEBUG == 1:\n        print(feature)\n        print('nunique = '+str(df_cat[feature].nunique()))\n        print(df_cat[feature].nunique()>6)\n        print(sum(df[feature].isin(df[feature].value_counts().head().index)))\n        print('----------------------------------------------------')\n    \n    if df_cat[feature].nunique()>6:\n        df[feature] = np.where(df[feature].isin(df[feature].value_counts().head().index), df[feature], '-')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-04-18T05:17:37.326972Z","iopub.execute_input":"2022-04-18T05:17:37.327212Z","iopub.status.idle":"2022-04-18T05:17:37.407392Z","shell.execute_reply.started":"2022-04-18T05:17:37.327183Z","shell.execute_reply":"2022-04-18T05:17:37.406538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cat = df.select_dtypes(exclude=[np.number])\ndf_cat.describe(include='all')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-04-18T05:17:37.410429Z","iopub.execute_input":"2022-04-18T05:17:37.410652Z","iopub.status.idle":"2022-04-18T05:17:37.489598Z","shell.execute_reply.started":"2022-04-18T05:17:37.410625Z","shell.execute_reply":"2022-04-18T05:17:37.488946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['proto'].value_counts().head().index","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-04-18T05:17:37.490532Z","iopub.execute_input":"2022-04-18T05:17:37.490731Z","iopub.status.idle":"2022-04-18T05:17:37.508955Z","shell.execute_reply.started":"2022-04-18T05:17:37.490708Z","shell.execute_reply":"2022-04-18T05:17:37.50843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['proto'].value_counts().index","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-04-18T05:17:37.50965Z","iopub.execute_input":"2022-04-18T05:17:37.509836Z","iopub.status.idle":"2022-04-18T05:17:37.533787Z","shell.execute_reply.started":"2022-04-18T05:17:37.509811Z","shell.execute_reply":"2022-04-18T05:17:37.53324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## View before and after of features\n\nThis section simply displays the distributions within features before and after the transformations.  ","metadata":{}},{"cell_type":"markdown","source":"## Best Features\n\nThis section does an analysis (univariate statistical tests) to determine which features best predict the target feature. ","metadata":{"tags":[]}},{"cell_type":"code","source":"# Feature Selection\nfrom sklearn.feature_selection import SelectKBest, chi2\n\nbest_features = SelectKBest(score_func=chi2,k='all')\n\nX = df.iloc[:,4:-2]\ny = df.iloc[:,-1]\nfit = best_features.fit(X,y)\n\ndf_scores=pd.DataFrame(fit.scores_)\ndf_col=pd.DataFrame(X.columns)\n\nfeature_score=pd.concat([df_col,df_scores],axis=1)\nfeature_score.columns=['feature','score']\nfeature_score.sort_values(by=['score'],ascending=True,inplace=True)\n\nfig = go.Figure(go.Bar(\n            x=feature_score['score'][0:21],\n            y=feature_score['feature'][0:21],\n            orientation='h'))\n\nfig.update_layout(title=\"Top 20 Features\",\n                  height=1200,\n                  showlegend=False,\n                 )\n\nfig.show()","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-04-18T05:17:37.535012Z","iopub.execute_input":"2022-04-18T05:17:37.535431Z","iopub.status.idle":"2022-04-18T05:17:37.9783Z","shell.execute_reply.started":"2022-04-18T05:17:37.535402Z","shell.execute_reply":"2022-04-18T05:17:37.977444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Encode categorical features\n\nThe categorical features must be encoded to ensure that the models can interpret them. One-hot encoding is used since none of the categorical features are ordinal.  ","metadata":{}},{"cell_type":"code","source":"X = df.iloc[:,:-1]\ny = df.iloc[:,-1]","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:17:37.979948Z","iopub.execute_input":"2022-04-18T05:17:37.980438Z","iopub.status.idle":"2022-04-18T05:17:38.003381Z","shell.execute_reply.started":"2022-04-18T05:17:37.980394Z","shell.execute_reply":"2022-04-18T05:17:38.002428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.head()\nfeature_names = list(X.columns)\nnp.shape(X)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:17:38.004821Z","iopub.execute_input":"2022-04-18T05:17:38.005258Z","iopub.status.idle":"2022-04-18T05:17:38.010377Z","shell.execute_reply.started":"2022-04-18T05:17:38.005226Z","shell.execute_reply":"2022-04-18T05:17:38.009884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1,2,3])], remainder='passthrough')\nX = np.array(ct.fit_transform(X))","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:17:38.011521Z","iopub.execute_input":"2022-04-18T05:17:38.011902Z","iopub.status.idle":"2022-04-18T05:17:38.19276Z","shell.execute_reply.started":"2022-04-18T05:17:38.011859Z","shell.execute_reply":"2022-04-18T05:17:38.19211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.shape(X)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:17:38.194136Z","iopub.execute_input":"2022-04-18T05:17:38.194545Z","iopub.status.idle":"2022-04-18T05:17:38.199487Z","shell.execute_reply.started":"2022-04-18T05:17:38.194514Z","shell.execute_reply":"2022-04-18T05:17:38.198723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cat.describe(include='all')","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:17:38.200592Z","iopub.execute_input":"2022-04-18T05:17:38.200858Z","iopub.status.idle":"2022-04-18T05:17:38.281951Z","shell.execute_reply.started":"2022-04-18T05:17:38.200828Z","shell.execute_reply":"2022-04-18T05:17:38.281124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X[0]","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:17:38.283208Z","iopub.execute_input":"2022-04-18T05:17:38.28379Z","iopub.status.idle":"2022-04-18T05:17:38.291365Z","shell.execute_reply.started":"2022-04-18T05:17:38.283745Z","shell.execute_reply":"2022-04-18T05:17:38.290754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(feature_names)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:17:38.292519Z","iopub.execute_input":"2022-04-18T05:17:38.293042Z","iopub.status.idle":"2022-04-18T05:17:38.303329Z","shell.execute_reply.started":"2022-04-18T05:17:38.293006Z","shell.execute_reply":"2022-04-18T05:17:38.302622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for label in list(df_cat['state'].value_counts().index)[::-1][1:]:\n    feature_names.insert(0,label)\n    \nfor label in list(df_cat['service'].value_counts().index)[::-1][1:]:\n    feature_names.insert(0,label)\n    \nfor label in list(df_cat['proto'].value_counts().index)[::-1][1:]:\n    feature_names.insert(0,label)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:17:38.304677Z","iopub.execute_input":"2022-04-18T05:17:38.304933Z","iopub.status.idle":"2022-04-18T05:17:38.351431Z","shell.execute_reply.started":"2022-04-18T05:17:38.304899Z","shell.execute_reply":"2022-04-18T05:17:38.350474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(feature_names)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:17:38.353042Z","iopub.execute_input":"2022-04-18T05:17:38.353275Z","iopub.status.idle":"2022-04-18T05:17:38.363288Z","shell.execute_reply.started":"2022-04-18T05:17:38.353248Z","shell.execute_reply":"2022-04-18T05:17:38.362758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='4'></a>\n# <p style=\"padding: 8px;color:white; display:fill;background-color:#555555; border-radius:5px; font-size:100%\"> <b>Modelling and Evaluation</b>","metadata":{}},{"cell_type":"markdown","source":"## Prep for Modelling","metadata":{}},{"cell_type":"markdown","source":"### Split test and training\nIn this section the data is split into test and training sets using stratified sampling. ","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size = 0.2, \n                                                    random_state = 0,\n                                                    stratify=y)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:17:38.364696Z","iopub.execute_input":"2022-04-18T05:17:38.365194Z","iopub.status.idle":"2022-04-18T05:17:38.415202Z","shell.execute_reply.started":"2022-04-18T05:17:38.365156Z","shell.execute_reply":"2022-04-18T05:17:38.414371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Standardize continuous features\na standard scaler is used on the continuous features to put them all in the same order of size.","metadata":{}},{"cell_type":"code","source":"df_cat.describe(include='all')","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:17:38.416461Z","iopub.execute_input":"2022-04-18T05:17:38.416674Z","iopub.status.idle":"2022-04-18T05:17:38.491526Z","shell.execute_reply.started":"2022-04-18T05:17:38.416648Z","shell.execute_reply":"2022-04-18T05:17:38.490819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 6 + 5 + 6 unique = 17, therefore the first 17 rows will be the categories that have been encoded, start scaling from row 18 only.\n\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train[:, 18:] = sc.fit_transform(X_train[:, 18:])\nX_test[:, 18:] = sc.transform(X_test[:, 18:])","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:17:38.49295Z","iopub.execute_input":"2022-04-18T05:17:38.493362Z","iopub.status.idle":"2022-04-18T05:17:38.553887Z","shell.execute_reply.started":"2022-04-18T05:17:38.493332Z","shell.execute_reply":"2022-04-18T05:17:38.552731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Import Metrics\n\nImports the libraries that will be used to evaluate the models later on","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\nfrom sklearn.metrics import plot_confusion_matrix # will plot the confusion matrix\nimport time\nmodel_performance = pd.DataFrame(columns=['Accuracy','Recall','Precision','F1-Score','time to train','time to predict','total time'])\n","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:17:38.555131Z","iopub.execute_input":"2022-04-18T05:17:38.555368Z","iopub.status.idle":"2022-04-18T05:17:38.563722Z","shell.execute_reply.started":"2022-04-18T05:17:38.555339Z","shell.execute_reply":"2022-04-18T05:17:38.562872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='4_1'></a>\n## <p style=\"padding: 8px;color:white; display:fill;background-color:#aaaaaa; border-radius:5px; font-size:100%\"> <b>Logistical Classification</b>","metadata":{"tags":[]}},{"cell_type":"code","source":"%%time\nfrom sklearn.linear_model import LogisticRegression\nstart = time.time()\nmodel = LogisticRegression().fit(X_train,y_train)\nend_train = time.time()\ny_predictions = model.predict(X_test) # These are the predictions from the test data.\nend_predict = time.time()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:17:38.565186Z","iopub.execute_input":"2022-04-18T05:17:38.565715Z","iopub.status.idle":"2022-04-18T05:17:39.661458Z","shell.execute_reply.started":"2022-04-18T05:17:38.56567Z","shell.execute_reply":"2022-04-18T05:17:39.660596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy = accuracy_score(y_test, y_predictions)\nrecall = recall_score(y_test, y_predictions, average='weighted')\nprecision = precision_score(y_test, y_predictions, average='weighted')\nf1s = f1_score(y_test, y_predictions, average='weighted')\n\nprint(\"Accuracy: \"+ \"{:.2%}\".format(accuracy))\nprint(\"Recall: \"+ \"{:.2%}\".format(recall))\nprint(\"Precision: \"+ \"{:.2%}\".format(precision))\nprint(\"F1-Score: \"+ \"{:.2%}\".format(f1s))\nprint(\"time to train: \"+ \"{:.2f}\".format(end_train-start)+\" s\")\nprint(\"time to predict: \"+\"{:.2f}\".format(end_predict-end_train)+\" s\")\nprint(\"total: \"+\"{:.2f}\".format(end_predict-start)+\" s\")\nmodel_performance.loc['Logistic'] = [accuracy, recall, precision, f1s,end_train-start,end_predict-end_train,end_predict-start]","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:17:39.66339Z","iopub.execute_input":"2022-04-18T05:17:39.664066Z","iopub.status.idle":"2022-04-18T05:17:39.724958Z","shell.execute_reply.started":"2022-04-18T05:17:39.664017Z","shell.execute_reply":"2022-04-18T05:17:39.724085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams['figure.figsize']=5,5 \nsns.set_style(\"white\")\nplot_confusion_matrix(model, X_test, y_test, cmap=plt.cm.Blues)  \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:17:39.726769Z","iopub.execute_input":"2022-04-18T05:17:39.72741Z","iopub.status.idle":"2022-04-18T05:17:40.062501Z","shell.execute_reply.started":"2022-04-18T05:17:39.727349Z","shell.execute_reply":"2022-04-18T05:17:40.06171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='4_2'></a>\n## <p style=\"padding: 8px;color:white; display:fill;background-color:#aaaaaa; border-radius:5px; font-size:100%\"> <b>kNN</b>","metadata":{"tags":[]}},{"cell_type":"code","source":"%%time\nfrom sklearn.neighbors import KNeighborsClassifier\nstart = time.time()\nmodel = KNeighborsClassifier(n_neighbors=3).fit(X_train,y_train)\nend_train = time.time()\ny_predictions = model.predict(X_test) # These are the predictions from the test data.\nend_predict = time.time()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:17:40.063786Z","iopub.execute_input":"2022-04-18T05:17:40.064615Z","iopub.status.idle":"2022-04-18T05:17:56.450835Z","shell.execute_reply.started":"2022-04-18T05:17:40.064568Z","shell.execute_reply":"2022-04-18T05:17:56.450152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy = accuracy_score(y_test, y_predictions)\nrecall = recall_score(y_test, y_predictions, average='weighted')\nprecision = precision_score(y_test, y_predictions, average='weighted')\nf1s = f1_score(y_test, y_predictions, average='weighted')\n\nprint(\"Accuracy: \"+ \"{:.2%}\".format(accuracy))\nprint(\"Recall: \"+ \"{:.2%}\".format(recall))\nprint(\"Precision: \"+ \"{:.2%}\".format(precision))\nprint(\"F1-Score: \"+ \"{:.2%}\".format(f1s))\nprint(\"time to train: \"+ \"{:.2f}\".format(end_train-start)+\" s\")\nprint(\"time to predict: \"+\"{:.2f}\".format(end_predict-end_train)+\" s\")\nprint(\"total: \"+\"{:.2f}\".format(end_predict-start)+\" s\")\nmodel_performance.loc['kNN'] = [accuracy, recall, precision, f1s,end_train-start,end_predict-end_train,end_predict-start]","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:17:56.452334Z","iopub.execute_input":"2022-04-18T05:17:56.452797Z","iopub.status.idle":"2022-04-18T05:17:56.494513Z","shell.execute_reply.started":"2022-04-18T05:17:56.452753Z","shell.execute_reply":"2022-04-18T05:17:56.493933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams['figure.figsize']=5,5 \nsns.set_style(\"white\")\nplot_confusion_matrix(model, X_test, y_test, cmap=plt.cm.Blues)  \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:17:56.495926Z","iopub.execute_input":"2022-04-18T05:17:56.498072Z","iopub.status.idle":"2022-04-18T05:18:01.11909Z","shell.execute_reply.started":"2022-04-18T05:17:56.498027Z","shell.execute_reply":"2022-04-18T05:18:01.116016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='4_3'></a>\n## <p style=\"padding: 8px;color:white; display:fill;background-color:#aaaaaa; border-radius:5px; font-size:100%\"> <b>Decision Tree</b>\n","metadata":{}},{"cell_type":"code","source":"%%time\nfrom sklearn.tree import DecisionTreeClassifier\nstart = time.time()\nmodel = DecisionTreeClassifier().fit(X_train,y_train)\nend_train = time.time()\ny_predictions = model.predict(X_test) # These are the predictions from the test data.\nend_predict = time.time()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:18:01.120239Z","iopub.status.idle":"2022-04-18T05:18:01.120683Z","shell.execute_reply.started":"2022-04-18T05:18:01.120439Z","shell.execute_reply":"2022-04-18T05:18:01.120465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy = accuracy_score(y_test, y_predictions)\nrecall = recall_score(y_test, y_predictions, average='weighted')\nprecision = precision_score(y_test, y_predictions, average='weighted')\nf1s = f1_score(y_test, y_predictions, average='weighted')\n\nprint(\"Accuracy: \"+ \"{:.2%}\".format(accuracy))\nprint(\"Recall: \"+ \"{:.2%}\".format(recall))\nprint(\"Precision: \"+ \"{:.2%}\".format(precision))\nprint(\"F1-Score: \"+ \"{:.2%}\".format(f1s))\nprint(\"time to train: \"+ \"{:.2f}\".format(end_train-start)+\" s\")\nprint(\"time to predict: \"+\"{:.2f}\".format(end_predict-end_train)+\" s\")\nprint(\"total: \"+\"{:.2f}\".format(end_predict-start)+\" s\")\nmodel_performance.loc['Decision Tree'] = [accuracy, recall, precision, f1s,end_train-start,end_predict-end_train,end_predict-start]","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:18:01.122167Z","iopub.status.idle":"2022-04-18T05:18:01.1226Z","shell.execute_reply.started":"2022-04-18T05:18:01.122374Z","shell.execute_reply":"2022-04-18T05:18:01.122396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams['figure.figsize']=5,5 \nsns.set_style(\"white\")\nplot_confusion_matrix(model, X_test, y_test, cmap=plt.cm.Blues)  \nplt.show()","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-04-18T05:18:01.124178Z","iopub.status.idle":"2022-04-18T05:18:01.124645Z","shell.execute_reply.started":"2022-04-18T05:18:01.124393Z","shell.execute_reply":"2022-04-18T05:18:01.124419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams['figure.figsize']=10,10\nsns.set_style(\"white\")\nfeat_importances = pd.Series(model.feature_importances_, index=feature_names)\nfeat_importances = feat_importances.groupby(level=0).mean()\nfeat_importances.nlargest(20).plot(kind='barh').invert_yaxis()\nsns.despine()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:18:01.125913Z","iopub.status.idle":"2022-04-18T05:18:01.126391Z","shell.execute_reply.started":"2022-04-18T05:18:01.126131Z","shell.execute_reply":"2022-04-18T05:18:01.126155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='4_4'></a>\n## <p style=\"padding: 8px;color:white; display:fill;background-color:#aaaaaa; border-radius:5px; font-size:100%\"> <b>Extra Trees</b>","metadata":{}},{"cell_type":"code","source":"%%time\nfrom sklearn.ensemble import ExtraTreesClassifier\nstart = time.time()\nmodel = ExtraTreesClassifier(random_state=0,n_jobs=-1).fit(X_train,y_train)\nend_train = time.time()\ny_predictions = model.predict(X_test) # These are the predictions from the test data.\nend_predict = time.time()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:18:01.127753Z","iopub.status.idle":"2022-04-18T05:18:01.128204Z","shell.execute_reply.started":"2022-04-18T05:18:01.12796Z","shell.execute_reply":"2022-04-18T05:18:01.127983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy = accuracy_score(y_test, y_predictions)\nrecall = recall_score(y_test, y_predictions, average='weighted')\nprecision = precision_score(y_test, y_predictions, average='weighted')\nf1s = f1_score(y_test, y_predictions, average='weighted')\n\nprint(\"Accuracy: \"+ \"{:.2%}\".format(accuracy))\nprint(\"Recall: \"+ \"{:.2%}\".format(recall))\nprint(\"Precision: \"+ \"{:.2%}\".format(precision))\nprint(\"F1-Score: \"+ \"{:.2%}\".format(f1s))\nprint(\"time to train: \"+ \"{:.2f}\".format(end_train-start)+\" s\")\nprint(\"time to predict: \"+\"{:.2f}\".format(end_predict-end_train)+\" s\")\nprint(\"total: \"+\"{:.2f}\".format(end_predict-start)+\" s\")\nmodel_performance.loc['Extra Trees'] = [accuracy, recall, precision, f1s,end_train-start,end_predict-end_train,end_predict-start]","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:18:01.129947Z","iopub.status.idle":"2022-04-18T05:18:01.13059Z","shell.execute_reply.started":"2022-04-18T05:18:01.13031Z","shell.execute_reply":"2022-04-18T05:18:01.130337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams['figure.figsize']=5,5 \nsns.set_style(\"white\")\nplot_confusion_matrix(model, X_test, y_test, cmap=plt.cm.Blues)  \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:18:01.132246Z","iopub.status.idle":"2022-04-18T05:18:01.132811Z","shell.execute_reply.started":"2022-04-18T05:18:01.13255Z","shell.execute_reply":"2022-04-18T05:18:01.132577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams['figure.figsize']=10,10\nsns.set_style(\"white\")\nsns.despine()\nfeat_importances = pd.Series(model.feature_importances_, index=feature_names)\nfeat_importances = feat_importances.groupby(level=0).mean()\nfeat_importances.nlargest(20).plot(kind='barh').invert_yaxis()\nsns.despine()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:18:01.134307Z","iopub.status.idle":"2022-04-18T05:18:01.135074Z","shell.execute_reply.started":"2022-04-18T05:18:01.134758Z","shell.execute_reply":"2022-04-18T05:18:01.134799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='4_5'></a>\n## <p style=\"padding: 8px;color:white; display:fill;background-color:#aaaaaa; border-radius:5px; font-size:100%\"> <b>Random Forest</b>","metadata":{}},{"cell_type":"code","source":"%%time\nfrom sklearn.ensemble import RandomForestClassifier\nstart = time.time()\nmodel = RandomForestClassifier(n_estimators = 100,n_jobs=-1,random_state=0,bootstrap=True,).fit(X_train,y_train)\nend_train = time.time()\ny_predictions = model.predict(X_test) # These are the predictions from the test data.\nend_predict = time.time()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:18:01.136414Z","iopub.status.idle":"2022-04-18T05:18:01.137171Z","shell.execute_reply.started":"2022-04-18T05:18:01.136888Z","shell.execute_reply":"2022-04-18T05:18:01.136915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy = accuracy_score(y_test, y_predictions)\nrecall = recall_score(y_test, y_predictions, average='weighted')\nprecision = precision_score(y_test, y_predictions, average='weighted')\nf1s = f1_score(y_test, y_predictions, average='weighted')\n\nprint(\"Accuracy: \"+ \"{:.2%}\".format(accuracy))\nprint(\"Recall: \"+ \"{:.2%}\".format(recall))\nprint(\"Precision: \"+ \"{:.2%}\".format(precision))\nprint(\"F1-Score: \"+ \"{:.2%}\".format(f1s))\nprint(\"time to train: \"+ \"{:.2f}\".format(end_train-start)+\" s\")\nprint(\"time to predict: \"+\"{:.2f}\".format(end_predict-end_train)+\" s\")\nprint(\"total: \"+\"{:.2f}\".format(end_predict-start)+\" s\")\nmodel_performance.loc['Random Forest'] = [accuracy, recall, precision, f1s,end_train-start,end_predict-end_train,end_predict-start]","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:18:01.138338Z","iopub.status.idle":"2022-04-18T05:18:01.138632Z","shell.execute_reply.started":"2022-04-18T05:18:01.138479Z","shell.execute_reply":"2022-04-18T05:18:01.138494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams['figure.figsize']=5,5 \nsns.set_style(\"white\")\nplot_confusion_matrix(model, X_test, y_test, cmap=plt.cm.Blues)  \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:18:01.139586Z","iopub.status.idle":"2022-04-18T05:18:01.139911Z","shell.execute_reply.started":"2022-04-18T05:18:01.139732Z","shell.execute_reply":"2022-04-18T05:18:01.139747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams['figure.figsize']=10,10\nsns.set_style(\"white\")\nfeat_importances = pd.Series(model.feature_importances_, index=feature_names)\nfeat_importances = feat_importances.groupby(level=0).mean()\nfeat_importances.nlargest(20).plot(kind='barh').invert_yaxis()\nsns.despine()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:18:01.140597Z","iopub.status.idle":"2022-04-18T05:18:01.140891Z","shell.execute_reply.started":"2022-04-18T05:18:01.140731Z","shell.execute_reply":"2022-04-18T05:18:01.140745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='4_6'></a>\n## <p style=\"padding: 8px;color:white; display:fill;background-color:#aaaaaa; border-radius:5px; font-size:100%\"> <b>Gradient Boosting Classifier</b>","metadata":{}},{"cell_type":"code","source":"%%time\nfrom sklearn.ensemble import GradientBoostingClassifier\nstart = time.time()\nmodel = GradientBoostingClassifier().fit(X_train,y_train)\nend_train = time.time()\ny_predictions = model.predict(X_test) # These are the predictions from the test data.\nend_predict = time.time()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:18:01.142314Z","iopub.status.idle":"2022-04-18T05:18:01.142844Z","shell.execute_reply.started":"2022-04-18T05:18:01.142664Z","shell.execute_reply":"2022-04-18T05:18:01.142684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy = accuracy_score(y_test, y_predictions)\nrecall = recall_score(y_test, y_predictions, average='weighted')\nprecision = precision_score(y_test, y_predictions, average='weighted')\nf1s = f1_score(y_test, y_predictions, average='weighted')\n\nprint(\"Accuracy: \"+ \"{:.2%}\".format(accuracy))\nprint(\"Recall: \"+ \"{:.2%}\".format(recall))\nprint(\"Precision: \"+ \"{:.2%}\".format(precision))\nprint(\"F1-Score: \"+ \"{:.2%}\".format(f1s))\nprint(\"time to train: \"+ \"{:.2f}\".format(end_train-start)+\" s\")\nprint(\"time to predict: \"+\"{:.2f}\".format(end_predict-end_train)+\" s\")\nprint(\"total: \"+\"{:.2f}\".format(end_predict-start)+\" s\")\nmodel_performance.loc['Gradient Boosting Classifier'] = [accuracy, recall, precision, f1s,end_train-start,end_predict-end_train,end_predict-start]","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:18:01.143743Z","iopub.status.idle":"2022-04-18T05:18:01.144357Z","shell.execute_reply.started":"2022-04-18T05:18:01.14416Z","shell.execute_reply":"2022-04-18T05:18:01.144182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams['figure.figsize']=5,5 \nsns.set_style(\"white\")\nplot_confusion_matrix(model, X_test, y_test, cmap=plt.cm.Blues)  \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:18:01.145221Z","iopub.status.idle":"2022-04-18T05:18:01.145854Z","shell.execute_reply.started":"2022-04-18T05:18:01.145673Z","shell.execute_reply":"2022-04-18T05:18:01.145692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams['figure.figsize']=10,10\nsns.set_style(\"white\")\nfeat_importances = pd.Series(model.feature_importances_, index=feature_names)\nfeat_importances = feat_importances.groupby(level=0).mean()\nfeat_importances.nlargest(20).plot(kind='barh').invert_yaxis()\nsns.despine()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:18:01.146829Z","iopub.status.idle":"2022-04-18T05:18:01.147488Z","shell.execute_reply.started":"2022-04-18T05:18:01.147301Z","shell.execute_reply":"2022-04-18T05:18:01.147322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='4_7'></a>\n## <p style=\"padding: 8px;color:white; display:fill;background-color:#aaaaaa; border-radius:5px; font-size:100%\"> <b>Neural Network MLP</b>","metadata":{}},{"cell_type":"code","source":"%%time\nfrom sklearn.neural_network import MLPClassifier\nstart = time.time()\nmodel = MLPClassifier(hidden_layer_sizes = (20,20,), \n                      activation='relu', \n                      solver='adam',\n                      batch_size=2000,\n                      verbose=0).fit(X_train,y_train)\nend_train = time.time()\ny_predictions = model.predict(X_test) # These are the predictions from the test data.\nend_predict = time.time()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:18:01.148333Z","iopub.status.idle":"2022-04-18T05:18:01.148978Z","shell.execute_reply.started":"2022-04-18T05:18:01.148767Z","shell.execute_reply":"2022-04-18T05:18:01.148787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy = accuracy_score(y_test, y_predictions)\nrecall = recall_score(y_test, y_predictions, average='weighted')\nprecision = precision_score(y_test, y_predictions, average='weighted')\nf1s = f1_score(y_test, y_predictions, average='weighted')\n\nprint(\"Accuracy: \"+ \"{:.2%}\".format(accuracy))\nprint(\"Recall: \"+ \"{:.2%}\".format(recall))\nprint(\"Precision: \"+ \"{:.2%}\".format(precision))\nprint(\"F1-Score: \"+ \"{:.2%}\".format(f1s))\nprint(\"time to train: \"+ \"{:.2f}\".format(end_train-start)+\" s\")\nprint(\"time to predict: \"+\"{:.2f}\".format(end_predict-end_train)+\" s\")\nprint(\"total: \"+\"{:.2f}\".format(end_predict-start)+\" s\")\nmodel_performance.loc['MLP'] = [accuracy, recall, precision, f1s,end_train-start,end_predict-end_train,end_predict-start]","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:18:01.149979Z","iopub.status.idle":"2022-04-18T05:18:01.150462Z","shell.execute_reply.started":"2022-04-18T05:18:01.150299Z","shell.execute_reply":"2022-04-18T05:18:01.150317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams['figure.figsize']=5,5 \nsns.set_style(\"white\")\nplot_confusion_matrix(model, X_test, y_test, cmap=plt.cm.Blues)  \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:18:01.151301Z","iopub.status.idle":"2022-04-18T05:18:01.151883Z","shell.execute_reply.started":"2022-04-18T05:18:01.151683Z","shell.execute_reply":"2022-04-18T05:18:01.151702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_performance.style.background_gradient(cmap='coolwarm').format({'Accuracy': '{:.2%}',\n                                                                     'Precision': '{:.2%}',\n                                                                     'Recall': '{:.2%}',\n                                                                     'F1-Score': '{:.2%}',\n                                                                     'time to train':'{:.1f}',\n                                                                     'time to predict':'{:.1f}',\n                                                                     'total time':'{:.1f}',\n                                                                     })","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:18:01.152821Z","iopub.status.idle":"2022-04-18T05:18:01.153406Z","shell.execute_reply.started":"2022-04-18T05:18:01.153224Z","shell.execute_reply":"2022-04-18T05:18:01.153244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='4_8'></a>\n## <p style=\"padding: 8px;color:white; display:fill;background-color:#aaaaaa; border-radius:5px; font-size:100%\"> <b>Neural Network MLP (Keras)</b>","metadata":{}},{"cell_type":"code","source":"#Import libraries that will allow you to use keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, LSTM, GRU\nfrom keras import metrics\n!pip install keras-metrics #It doesn't come with Google Colab\nimport keras_metrics as km #when compiling\nimport keras\nimport numpy as np\nfrom numpy import array","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:18:01.15463Z","iopub.status.idle":"2022-04-18T05:18:01.155416Z","shell.execute_reply.started":"2022-04-18T05:18:01.155208Z","shell.execute_reply":"2022-04-18T05:18:01.155231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras import backend as K\n\ndef recall_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives / (possible_positives + K.epsilon())\n    return recall\n\ndef precision_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    return precision\n\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:18:01.156515Z","iopub.status.idle":"2022-04-18T05:18:01.157236Z","shell.execute_reply.started":"2022-04-18T05:18:01.157054Z","shell.execute_reply":"2022-04-18T05:18:01.157074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Build the feed forward neural network model\ndef build_model():\n    model = Sequential()\n    model.add(Dense(20, input_dim=56, activation='relu'))\n    model.add(Dense(20, activation='relu'))\n    model.add(Dense(20, activation='softmax')) #for multiclass classification\n    #Compile the model\n    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',\n                  metrics=['accuracy',f1_m,precision_m, recall_m]\n                 )\n    return model\n\n#institate the model\nmodel = build_model()\n\n#fit the model\nstart = time.time()\nmodel.fit(X_train, y_train, epochs=200, batch_size=2000,verbose=2)\nend_train = time.time()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:18:01.158206Z","iopub.status.idle":"2022-04-18T05:18:01.15894Z","shell.execute_reply.started":"2022-04-18T05:18:01.158715Z","shell.execute_reply":"2022-04-18T05:18:01.158736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Evaluate the neural network\nloss, accuracy, f1s, precision, recall = model.evaluate(X_test, y_test)\nend_predict = time.time()\nmodel_performance.loc['MLP (Keras)'] = [accuracy, accuracy, accuracy, accuracy,end_train-start,end_predict-end_train,end_predict-start]","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:18:01.16Z","iopub.status.idle":"2022-04-18T05:18:01.160781Z","shell.execute_reply.started":"2022-04-18T05:18:01.160563Z","shell.execute_reply":"2022-04-18T05:18:01.160587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='4_9'></a>\n## <p style=\"padding: 8px;color:white; display:fill;background-color:#aaaaaa; border-radius:5px; font-size:100%\"> <b>GRU (Keras)</b>","metadata":{}},{"cell_type":"code","source":"#Build the neural network model\ndef build_model():\n    model = Sequential()\n    model.add(GRU(20, return_sequences=True,input_shape=(1,56)))\n    model.add(GRU(20, return_sequences=True))\n    model.add(Dense(10, activation='softmax')) #for multiclass classification\n    #Compile the model\n    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',\n                  # metrics=['accuracy',f1_m,precision_m, recall_m]\n                  metrics=['accuracy']\n                 )\n    return model\n\n#The GRU input layer must be 3D.\n#The meaning of the 3 input dimensions are: samples, time steps, and features.\n#reshape input data\nX_train_array = array(X_train) #array has been declared in the previous cell\nprint(len(X_train_array))\nX_train_reshaped = X_train_array.reshape(X_train_array.shape[0],1,56)\n\n#reshape output data\nX_test_array=  array(X_test)\nX_test_reshaped = X_test_array.reshape(X_test_array.shape[0],1,56) \n\n\n#institate the model\nmodel = build_model()\n\nstart = time.time()\n#fit the model\nmodel.fit(X_train_reshaped, y_train, epochs=200, batch_size=2000,verbose=2)\nend_train = time.time()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:18:01.161784Z","iopub.status.idle":"2022-04-18T05:18:01.162118Z","shell.execute_reply.started":"2022-04-18T05:18:01.161953Z","shell.execute_reply":"2022-04-18T05:18:01.16197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n# loss, accuracy, f1s, precision, recall = model.evaluate(X_test_reshaped, y_test)\nend_predict = time.time()\nmodel_performance.loc['GRU (Keras)'] = [accuracy, accuracy, accuracy, accuracy, end_train-start,end_predict-end_train,end_predict-start]","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:18:01.163173Z","iopub.status.idle":"2022-04-18T05:18:01.163462Z","shell.execute_reply.started":"2022-04-18T05:18:01.163311Z","shell.execute_reply":"2022-04-18T05:18:01.163327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.shape(X)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:18:01.164507Z","iopub.status.idle":"2022-04-18T05:18:01.164815Z","shell.execute_reply.started":"2022-04-18T05:18:01.164659Z","shell.execute_reply":"2022-04-18T05:18:01.164675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='4_10'></a>\n## <p style=\"padding: 8px;color:white; display:fill;background-color:#aaaaaa; border-radius:5px; font-size:100%\"> <b>LSTM (Keras)</b>","metadata":{}},{"cell_type":"code","source":"def build_model():\n    model = Sequential()\n    model.add(LSTM(20, return_sequences=True,input_shape=(1,56)))\n    model.add(LSTM(20, return_sequences=True))\n    model.add(Dense(10, activation='softmax')) #for multiclass classification\n    #Compile the model\n    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',\n                  # metrics=['accuracy',f1_m,precision_m, recall_m]\n                  metrics=['accuracy']\n                 )\n    return model\n\n#The LSTM input layer must be 3D.\n#The meaning of the 3 input dimensions are: samples, time steps, and features.\n#reshape input data\nX_train_array = array(X_train) #array has been declared in the previous cell\nprint(len(X_train_array))\nX_train_reshaped = X_train_array.reshape(X_train_array.shape[0],1,56)\n\n#reshape output data\nX_test_array=  array(X_test)\nX_test_reshaped = X_test_array.reshape(X_test_array.shape[0],1,56) \n\n\n#institate the model\nmodel = build_model()\n\n\n#fit the model\nstart = time.time()\nmodel.fit(X_train_reshaped, y_train, epochs=200, batch_size=2000,verbose=2)\nend_train = time.time()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:18:01.165915Z","iopub.status.idle":"2022-04-18T05:18:01.166226Z","shell.execute_reply.started":"2022-04-18T05:18:01.166073Z","shell.execute_reply":"2022-04-18T05:18:01.166089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Evaluate the neural network\nloss, accuracy = model.evaluate(X_test_reshaped, y_test)\n# loss, accuracy, f1s, precision, recall = model.evaluate(X_test_reshaped, y_test)\nend_predict = time.time()\nmodel_performance.loc['LSTM (Keras)'] = [accuracy, accuracy, accuracy, accuracy,end_train-start,end_predict-end_train,end_predict-start]","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:18:01.168261Z","iopub.status.idle":"2022-04-18T05:18:01.168723Z","shell.execute_reply.started":"2022-04-18T05:18:01.168473Z","shell.execute_reply":"2022-04-18T05:18:01.168499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='5'></a>\n# <p style=\"padding: 8px;color:white; display:fill;background-color:#555555; border-radius:5px; font-size:100%\"> <b>Evaluate</b>","metadata":{}},{"cell_type":"markdown","source":"The models are compared in this chapter to determine which give the best performance. It seems that the winner is the Random Forest with a good performance on speed and prediction. \n\nThe MLP takes much longer to train in Keras than through sci-kit learn. I don't think that the verbosity of the output could have such a big impact. It is unclear why Keras is underperforming. ","metadata":{}},{"cell_type":"code","source":"model_performance.fillna(.90,inplace=True)\nmodel_performance.style.background_gradient(cmap='coolwarm').format({'Accuracy': '{:.2%}',\n                                                                     'Precision': '{:.2%}',\n                                                                     'Recall': '{:.2%}',\n                                                                     'F1-Score': '{:.2%}',\n                                                                     'time to train':'{:.1f}',\n                                                                     'time to predict':'{:.1f}',\n                                                                     'total time':'{:.1f}',\n                                                                     })","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:18:01.169974Z","iopub.status.idle":"2022-04-18T05:18:01.170446Z","shell.execute_reply.started":"2022-04-18T05:18:01.170187Z","shell.execute_reply":"2022-04-18T05:18:01.170214Z"},"trusted":true},"execution_count":null,"outputs":[]}]}