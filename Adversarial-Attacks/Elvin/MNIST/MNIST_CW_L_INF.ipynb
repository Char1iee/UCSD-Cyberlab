{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d44270b9-8c2e-4a04-bafe-606555e7ff98",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Carlini And Wagner Inf Attack**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940b5131-623a-4379-b6a7-1bf32e851226",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d463cb14-8876-430a-aefe-4a47bb118253",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0156b815-6a94-4faa-a0c7-8cefbf3407f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from art.attacks.evasion import CarliniLInfMethod\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.utils import load_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59f66ba-b47e-4179-9680-7c870f772b70",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1faa2733-48b5-48e1-a6c8-7b6ddc53c59a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test), min_pixel_value, max_pixel_value = load_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d8c088e-ac28-4c2c-8831-32fd863c46db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = np.transpose(X_train, (0, 3, 1, 2)).astype(np.float32)\n",
    "X_test = np.transpose(X_test, (0, 3, 1, 2)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aedd62-d75b-4d3e-aa9b-03f150591364",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7b076fe-faab-4000-8392-408d1a300d85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MNIST_NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNIST_NN, self).__init__()\n",
    "        self.conv_1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=5, stride=1)\n",
    "        self.conv_2 = nn.Conv2d(in_channels=4, out_channels=10, kernel_size=5, stride=1)\n",
    "        self.fc_1 = nn.Linear(in_features=4 * 4 * 10, out_features=100)\n",
    "        self.fc_2 = nn.Linear(in_features=100, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv_1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv_2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4 * 4 * 10)\n",
    "        x = F.relu(self.fc_1(x))\n",
    "        x = self.fc_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2b1f068-fb55-43a2-bbe3-464b29ac16f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    \n",
    "    classifier = PyTorchClassifier(\n",
    "        model=model,\n",
    "        clip_values=(min_pixel_value, max_pixel_value),\n",
    "        loss=criterion,\n",
    "        optimizer=optimizer,\n",
    "        input_shape=(1, 28, 28),\n",
    "        nb_classes=10,\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    classifier.fit(X_train, y_train, batch_size=64, nb_epochs=5)\n",
    "    \n",
    "    # Prediction on normal X_test samples\n",
    "    predictions_benign = classifier.predict(X_test)\n",
    "    accuracy = np.sum(np.argmax(predictions_benign, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "    print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))\n",
    "    \n",
    "    # Prediction on perturbated samples\n",
    "    attack = CarliniLInfMethod(classifier=classifier)\n",
    "    X_test_adv = attack.generate(x=X_test)\n",
    "    \n",
    "    predictions_adv = classifier.predict(X_test_adv)\n",
    "    accuracy = np.sum(np.argmax(predictions_adv, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "    print(\"Accuracy on adversarial test examples: {}%\".format(accuracy * 100))\n",
    "    \n",
    "    # Time\n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"Time: {training_time:.2f} seconds\")\n",
    "    \n",
    "    predictions_benign_proba = F.softmax(torch.tensor(predictions_benign), dim=1).numpy()\n",
    "    predictions_adv_proba = F.softmax(torch.tensor(predictions_adv), dim=1).numpy()\n",
    "    \n",
    "    return predictions_benign, predictions_adv, predictions_benign_proba, predictions_adv_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0100ca6-df9c-43db-a4ea-fc8e50384597",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on benign test examples: 98.21%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d21f1d7e79dd48b3a71912443a16ae83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_inf:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial test examples: 97.39%\n",
      "Time: 3480.20 seconds\n"
     ]
    }
   ],
   "source": [
    "model = MNIST_NN()\n",
    "predictions_benign, predictions_adv, predictions_benign_proba, predictions_adv_proba = train(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1aaf246-a982-4939-ae7f-cecd6e2056f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9496acdf-1899-4d4d-b2bb-6950ee765a84",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e71ba894-5f80-427f-8281-6d49ec99f390",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_weighted_rates(cm):\n",
    "    num_classes = cm.shape[0]\n",
    "    total_instances = np.sum(cm)\n",
    "    \n",
    "    weighted_TPR = 0\n",
    "    weighted_TNR = 0\n",
    "    weighted_FPR = 0\n",
    "    weighted_FNR = 0\n",
    "    \n",
    "    for class_index in range(num_classes):\n",
    "        TP = cm[class_index, class_index]\n",
    "        FP = cm[:, class_index].sum() - TP\n",
    "        FN = cm[class_index, :].sum() - TP\n",
    "        TN = cm.sum() - (TP + FP + FN)\n",
    "        \n",
    "        class_size = cm[class_index, :].sum()  # Total true instances for the class\n",
    "        \n",
    "        # Calculate rates\n",
    "        TPR = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "        TNR = TN / (TN + FP) if (TN + FP) != 0 else 0\n",
    "        FPR = FP / (FP + TN) if (FP + TN) != 0 else 0\n",
    "        FNR = FN / (FN + TP) if (FN + TP) != 0 else 0\n",
    "        \n",
    "        # Weight by class proportion and accumulate\n",
    "        weighted_TPR += (class_size / total_instances) * TPR\n",
    "        weighted_TNR += (class_size / total_instances) * TNR\n",
    "        weighted_FPR += (class_size / total_instances) * FPR\n",
    "        weighted_FNR += (class_size / total_instances) * FNR\n",
    "\n",
    "    return weighted_TPR, weighted_TNR, weighted_FPR, weighted_FNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b3b9955-0377-4b69-94c2-f21cb03ec2ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_class_metrics_macro(cm, class_index):\n",
    "\n",
    "    TP = cm[class_index, class_index]\n",
    "    FP = cm[:, class_index].sum() - TP\n",
    "    FN = cm[class_index, :].sum() - TP\n",
    "    TN = cm.sum() - (TP + FP + FN)\n",
    "    \n",
    "    TPR = TP / (TP + FN) if (TP + FN) != 0 else 0  \n",
    "    TNR = TN / (TN + FP) if (TN + FP) != 0 else 0  \n",
    "    FPR = FP / (FP + TN) if (FP + TN) != 0 else 0  \n",
    "    FNR = FN / (FN + TP) if (FN + TP) != 0 else 0  \n",
    "    \n",
    "    return TPR, TNR, FPR, FNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cebd6f7e-643d-47ac-be10-754a99dc41f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_metrics_micro(cm):\n",
    "    \n",
    "    TP_sum = np.sum([cm[i, i] for i in range(cm.shape[0])])  # Sum of True Positives\n",
    "    FP_sum = np.sum(cm) - np.sum(np.diag(cm))  # Sum of False Positives (total minus TP)\n",
    "    FN_sum = FP_sum  # In micro-averaging for multi-class, FN and FP are equivalent in sum\n",
    "    TN_sum = np.sum(cm) * (cm.shape[0] - 1) - 2 * FP_sum  # Adjusting TN for multi-class\n",
    "    \n",
    "    TPR_micro = TP_sum / (TP_sum + FN_sum) if (TP_sum + FN_sum) != 0 else 0  \n",
    "    TNR_micro = TN_sum / (TN_sum + FP_sum) if (TN_sum + FP_sum) != 0 else 0  \n",
    "    FPR_micro = FP_sum / (FP_sum + TN_sum) if (FP_sum + TN_sum) != 0 else 0 \n",
    "    FNR_micro = FN_sum / (FN_sum + TP_sum) if (FN_sum + TP_sum) != 0 else 0  \n",
    "    \n",
    "    return TPR_micro, TNR_micro, FPR_micro, FNR_micro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a723cc-b896-40c7-b2e1-6ae4a70f787c",
   "metadata": {},
   "source": [
    "## Weighted, Macro, Micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0543b8c-3a7c-4f61-bf9a-6829476afff2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def metrics_weighted(predictions_benign, predictions_adv):\n",
    "    \n",
    "    # Reshape\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "    y_pred_benign = np.argmax(predictions_benign, axis=1)\n",
    "    y_pred_adv = np.argmax(predictions_adv, axis=1)\n",
    "    \n",
    "    # Acc, Prec, Rec, F1\n",
    "    precision_benign, recall_benign, f1_benign, _ = precision_recall_fscore_support(y_true, y_pred_benign, average='weighted')\n",
    "    accuracy_benign = accuracy_score(y_true, y_pred_benign)\n",
    "\n",
    "    precision_adv, recall_adv, f1_adv, _ = precision_recall_fscore_support(y_true, y_pred_adv, average='weighted')\n",
    "    accuracy_adv = accuracy_score(y_true, y_pred_adv)\n",
    "    \n",
    "    # TPR, TNR, FPR, FNR\n",
    "    cm_benign = confusion_matrix(y_true, y_pred_benign)\n",
    "    cm_adv = confusion_matrix(y_true, y_pred_adv)\n",
    "    \n",
    "    TPR_benign, TNR_benign, FPR_benign, FNR_benign = calculate_weighted_rates(cm_benign)\n",
    "    TPR_adv, TNR_adv, FPR_adv, FNR_adv = calculate_weighted_rates(cm_adv)\n",
    "    \n",
    "    # AUC\n",
    "    auc_benign = roc_auc_score(y_test, predictions_benign_proba, multi_class='ovr', average='weighted')\n",
    "    auc_adv = roc_auc_score(y_test, predictions_adv_proba, multi_class='ovr', average='weighted')\n",
    "    \n",
    "    print(\"Weighted\")\n",
    "    print(f\"Benign Acc: {accuracy_benign:.4f}\")\n",
    "    print(f\"Benign Prec: {precision_benign:.4f}\")\n",
    "    print(f\"Benign Rec: {recall_benign:.4f}\")\n",
    "    print(f\"Benign F1: {f1_benign:.4f}\")\n",
    "    \n",
    "    print(f\"Adv Acc: {accuracy_adv:.4f}\")\n",
    "    print(f\"Adv Prec: {precision_adv:.4f}\")\n",
    "    print(f\"Adv Rec: {recall_adv:.4f}\")\n",
    "    print(f\"Adv F1: {f1_adv:.4f}\")\n",
    "    \n",
    "    print(f\"Benign TPR: {TPR_benign:.4f}\") \n",
    "    print(f\"Benign TNR: {TNR_benign:.4f}\") \n",
    "    print(f\"Benign FPR: {FPR_benign:.4f}\")\n",
    "    print(f\"Benign FNR: {FNR_benign:.4f}\")\n",
    "    \n",
    "    print(f\"Adv TPR: {TPR_adv:.4f}\") \n",
    "    print(f\"Adv TNR: {TNR_adv:.4f}\") \n",
    "    print(f\"Adv FPR: {FPR_adv:.4f}\")\n",
    "    print(f\"Adv FNR: {FNR_adv:.4f}\")\n",
    "    \n",
    "    print(f\"Benign AUC: {auc_benign:.4f}\")\n",
    "    print(f\"Adv AUC: {auc_adv:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "180edcea-05bc-46af-bf7a-0cd9508b121e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted\n",
      "Benign Acc: 0.9821\n",
      "Benign Prec: 0.9822\n",
      "Benign Rec: 0.9821\n",
      "Benign F1: 0.9821\n",
      "Adv Acc: 0.9739\n",
      "Adv Prec: 0.9742\n",
      "Adv Rec: 0.9739\n",
      "Adv F1: 0.9739\n",
      "Benign TPR: 0.9821\n",
      "Benign TNR: 0.9980\n",
      "Benign FPR: 0.0020\n",
      "Benign FNR: 0.0179\n",
      "Adv TPR: 0.9739\n",
      "Adv TNR: 0.9971\n",
      "Adv FPR: 0.0029\n",
      "Adv FNR: 0.0261\n",
      "Benign AUC: 0.9997\n",
      "Adv AUC: 0.9997\n"
     ]
    }
   ],
   "source": [
    "metrics_weighted(predictions_benign, predictions_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b8a08e2-20ae-42f3-9afb-f82ef1e3a6f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def metrics_macro():\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "    y_pred_benign = np.argmax(predictions_benign, axis=1)\n",
    "    y_pred_adv = np.argmax(predictions_adv, axis=1)\n",
    "\n",
    "    \n",
    "    # Acc, Prec, Rec, F1\n",
    "    precision_benign, recall_benign, f1_benign, _ = precision_recall_fscore_support(y_true, y_pred_benign, average='macro')\n",
    "    accuracy_benign = accuracy_score(y_true, y_pred_benign)\n",
    "    \n",
    "    precision_adv, recall_adv, f1_adv, _ = precision_recall_fscore_support(y_true, y_pred_adv, average='macro')\n",
    "    accuracy_adv = accuracy_score(y_true, y_pred_adv)\n",
    "    \n",
    "    cm_benign = confusion_matrix(y_true, y_pred_benign)\n",
    "    cm_adv = confusion_matrix(y_true, y_pred_adv)\n",
    "    \n",
    "    # TPR, TNR, FPR, FNR\n",
    "    TPR_benign, TNR_benign, FPR_benign, FNR_benign = np.mean([calculate_class_metrics_macro(cm_benign, i) for i in range(10)], axis=0)\n",
    "    TPR_adv, TNR_adv, FPR_adv, FNR_adv = np.mean([calculate_class_metrics_macro(cm_adv, i) for i in range(10)], axis=0)\n",
    "    \n",
    "    # AUC\n",
    "    auc_benign = roc_auc_score(y_test, predictions_benign_proba, multi_class='ovr', average='macro')\n",
    "    auc_adv = roc_auc_score(y_test, predictions_adv_proba, multi_class='ovr', average='macro')\n",
    "    \n",
    "    print(\"Macro\")\n",
    "    print(f\"Benign Acc: {accuracy_benign:.4f}\")\n",
    "    print(f\"Benign Prec: {precision_benign:.4f}\")\n",
    "    print(f\"Benign Rec: {recall_benign:.4f}\")\n",
    "    print(f\"Benign F1: {f1_benign:.4f}\")\n",
    "    \n",
    "    print(f\"Adv Acc: {accuracy_adv:.4f}\")\n",
    "    print(f\"Adv Prec: {precision_adv:.4f}\")\n",
    "    print(f\"Adv Rec: {recall_adv:.4f}\")\n",
    "    print(f\"Adv F1: {f1_adv:.4f}\")\n",
    "    \n",
    "    print(f\"Benign TPR: {TPR_benign:.4f}\") \n",
    "    print(f\"Benign TNR: {TNR_benign:.4f}\") \n",
    "    print(f\"Benign FPR: {FPR_benign:.4f}\")\n",
    "    print(f\"Benign FNR: {FNR_benign:.4f}\")\n",
    "    \n",
    "    print(f\"Adv TPR: {TPR_adv:.4f}\") \n",
    "    print(f\"Adv TNR: {TNR_adv:.4f}\") \n",
    "    print(f\"Adv FPR: {FPR_adv:.4f}\")\n",
    "    print(f\"Adv FNR: {FNR_adv:.4f}\")\n",
    "    \n",
    "    print(f\"Benign AUC: {auc_benign:.4f}\")\n",
    "    print(f\"Adv AUC: {auc_adv:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfef3bf6-c0ed-49d2-a957-853b59f8da78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro\n",
      "Benign Acc: 0.9821\n",
      "Benign Prec: 0.9823\n",
      "Benign Rec: 0.9818\n",
      "Benign F1: 0.9820\n",
      "Adv Acc: 0.9739\n",
      "Adv Prec: 0.9742\n",
      "Adv Rec: 0.9734\n",
      "Adv F1: 0.9736\n",
      "Benign TPR: 0.9818\n",
      "Benign TNR: 0.9980\n",
      "Benign FPR: 0.0020\n",
      "Benign FNR: 0.0182\n",
      "Adv TPR: 0.9734\n",
      "Adv TNR: 0.9971\n",
      "Adv FPR: 0.0029\n",
      "Adv FNR: 0.0266\n",
      "Benign AUC: 0.9997\n",
      "Adv AUC: 0.9997\n"
     ]
    }
   ],
   "source": [
    "metrics_macro()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "633c19c6-7096-41a9-bc85-df487ad6c5f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def metrics_micro():\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "    y_pred_benign = np.argmax(predictions_benign, axis=1)\n",
    "    y_pred_adv = np.argmax(predictions_adv, axis=1)\n",
    "\n",
    "    # Acc, Prec, Rec, F1\n",
    "    precision_benign, recall_benign, f1_benign, _ = precision_recall_fscore_support(y_true, y_pred_benign, average='micro')\n",
    "    accuracy_benign = accuracy_score(y_true, y_pred_benign)\n",
    "    \n",
    "    precision_adv, recall_adv, f1_adv, _ = precision_recall_fscore_support(y_true, y_pred_adv, average='micro')\n",
    "    accuracy_adv = accuracy_score(y_true, y_pred_adv)\n",
    "    \n",
    "    # TPR, TNR, FPR, FNR\n",
    "    cm_benign = confusion_matrix(y_true, y_pred_benign)\n",
    "    cm_adv = confusion_matrix(y_true, y_pred_adv)\n",
    "    \n",
    "    TPR_benign, TNR_benign, FPR_benign, FNR_benign = calculate_metrics_micro(cm_benign)\n",
    "    TPR_adv, TNR_adv, FPR_adv, FNR_adv = calculate_metrics_micro(cm_adv)\n",
    "    \n",
    "    # AUC\n",
    "    auc_benign = roc_auc_score(y_test, predictions_benign_proba, multi_class='ovr', average='micro')\n",
    "    auc_adv = roc_auc_score(y_test, predictions_adv_proba, multi_class='ovr', average='micro')\n",
    "    \n",
    "    print(\"Weighted\")\n",
    "    print(f\"Benign Acc: {accuracy_benign:.4f}\")\n",
    "    print(f\"Benign Prec: {precision_benign:.4f}\")\n",
    "    print(f\"Benign Rec: {recall_benign:.4f}\")\n",
    "    print(f\"Benign F1: {f1_benign:.4f}\")\n",
    "    \n",
    "    print(f\"Adv Acc: {accuracy_adv:.4f}\")\n",
    "    print(f\"Adv Prec: {precision_adv:.4f}\")\n",
    "    print(f\"Adv Rec: {recall_adv:.4f}\")\n",
    "    print(f\"Adv F1: {f1_adv:.4f}\")\n",
    "    \n",
    "    print(f\"Benign TPR: {TPR_benign:.4f}\") \n",
    "    print(f\"Benign TNR: {TNR_benign:.4f}\") \n",
    "    print(f\"Benign FPR: {FPR_benign:.4f}\")\n",
    "    print(f\"Benign FNR: {FNR_benign:.4f}\")\n",
    "    \n",
    "    print(f\"Adv TPR: {TPR_adv:.4f}\") \n",
    "    print(f\"Adv TNR: {TNR_adv:.4f}\") \n",
    "    print(f\"Adv FPR: {FPR_adv:.4f}\")\n",
    "    print(f\"Adv FNR: {FNR_adv:.4f}\")\n",
    "    \n",
    "    print(f\"Benign AUC: {auc_benign:.4f}\")\n",
    "    print(f\"Adv AUC: {auc_adv:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e342100-b7bb-4092-ad37-ad5f13075fe7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted\n",
      "Benign Acc: 0.9821\n",
      "Benign Prec: 0.9821\n",
      "Benign Rec: 0.9821\n",
      "Benign F1: 0.9821\n",
      "Adv Acc: 0.9739\n",
      "Adv Prec: 0.9739\n",
      "Adv Rec: 0.9739\n",
      "Adv F1: 0.9739\n",
      "Benign TPR: 0.9821\n",
      "Benign TNR: 0.9980\n",
      "Benign FPR: 0.0020\n",
      "Benign FNR: 0.0179\n",
      "Adv TPR: 0.9739\n",
      "Adv TNR: 0.9971\n",
      "Adv FPR: 0.0029\n",
      "Adv FNR: 0.0261\n",
      "Benign AUC: 0.9996\n",
      "Adv AUC: 0.9996\n"
     ]
    }
   ],
   "source": [
    "metrics_micro()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d622dce-c525-4b96-83cd-eb08ad618105",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
