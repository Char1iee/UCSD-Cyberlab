{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58e43be8-d148-4609-afd7-d9b5637990d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-19 10:24:26.539332: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-19 10:24:26.571443: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-19 10:24:26.571475: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-19 10:24:26.572591: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-19 10:24:26.578254: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-19 10:24:26.578662: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-19 10:24:27.309187: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "from art.attacks.evasion import ElasticNet\n",
    "from art.estimators.classification import TensorFlowV2Classifier\n",
    "from art.utils import load_dataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d506faab-3df5-4d17-bb75-f7c9cceedaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_performance_metrics(x_test, y_test, model):\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    report = metrics.classification_report(y_test, y_pred_classes, output_dict=True, zero_division=1)\n",
    "    \n",
    "    precision_macro = report['macro avg']['precision']\n",
    "    precision_weighted = report['weighted avg']['precision']\n",
    "    accuracy = report['accuracy']\n",
    "    recall_macro = report['macro avg']['recall']\n",
    "    recall_weighted = report['weighted avg']['recall']\n",
    "    f1_macro = report['macro avg']['f1-score']\n",
    "    f1_weighted = report['weighted avg']['f1-score']\n",
    "    auc = metrics.roc_auc_score(y_test, y_pred, multi_class='ovr')\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}\\nAUC: {auc}\")\n",
    "    \n",
    "    print(\"\\nmacro\")\n",
    "    print(f\"Precision: {precision_macro}\\nRecall: {recall_macro}\\nF1 Score: {f1_macro}\")\n",
    "\n",
    "    print(\"\\nweighted\")\n",
    "    print(f\"Precision: {precision_weighted}\\nRecall: {recall_weighted}\\nF1 Score: {f1_weighted}\")\n",
    "    print()\n",
    "    \n",
    "    # Confusion matrix for FNR, TNR, FPR, TPR\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred_classes)\n",
    "    def calculate_rates(conf_matrix, class_index):\n",
    "        tp = conf_matrix[class_index, class_index]\n",
    "        fn = np.sum(conf_matrix[class_index, :]) - tp\n",
    "        fp = np.sum(conf_matrix[:, class_index]) - tp\n",
    "        tn = np.sum(conf_matrix) - (tp + fn + fp)\n",
    "    \n",
    "        fnr = fn / (fn + tp)\n",
    "        tnr = tn / (tn + fp)\n",
    "        fpr = fp / (fp + tn)\n",
    "        tpr = tp / (tp + fn)\n",
    "        return fnr, tnr, fpr, tpr\n",
    "\n",
    "    # Calculate and aggregate rates\n",
    "    fnrs, tnrs, fprs, tprs = [], [], [], []\n",
    "    for i in range(cm.shape[0]):\n",
    "        fnr, tnr, fpr, tpr = calculate_rates(cm, i)\n",
    "        fnrs.append(fnr)\n",
    "        tnrs.append(tnr)\n",
    "        fprs.append(fpr)\n",
    "        tprs.append(tpr)\n",
    "    \n",
    "    mean_fnr = np.mean(fnrs)\n",
    "    mean_tnr = np.mean(tnrs)\n",
    "    mean_fpr = np.mean(fprs)\n",
    "    mean_tpr = np.mean(tprs)\n",
    "\n",
    "    # Printing the mean metrics\n",
    "    print(f\"Mean FNR: {mean_fnr}\\nMean TNR: {mean_tnr}\\nMean FPR: {mean_fpr}\\nMean TPR: {mean_tpr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77d8bb17-ccc8-4faf-b071-99597089c90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('/home/jovyan/WUSTL-IIoT/preprocessed_data/x_train.csv', low_memory=False)\n",
    "y_train = pd.read_csv('/home/jovyan/WUSTL-IIoT/preprocessed_data/y_train.csv', low_memory=False)\n",
    "x_val = pd.read_csv('/home/jovyan/WUSTL-IIoT/preprocessed_data/x_val.csv', low_memory=False)\n",
    "y_val = pd.read_csv('/home/jovyan/WUSTL-IIoT/preprocessed_data/y_val.csv', low_memory=False)\n",
    "x_test = pd.read_csv('/home/jovyan/WUSTL-IIoT/preprocessed_data/x_test.csv', low_memory=False)\n",
    "y_test = pd.read_csv('/home/jovyan/WUSTL-IIoT/preprocessed_data/y_test.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be6cf1c4-f619-4256-88d2-685ef6fbae7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "s1 = preprocessing.MinMaxScaler()\n",
    "s2 = preprocessing.MinMaxScaler()\n",
    "s3 = preprocessing.MinMaxScaler()\n",
    "\n",
    "x_train_scaled = s1.fit_transform(x_train)\n",
    "x_val_scaled = s2.fit_transform(x_val)\n",
    "x_test_scaled = s3.fit_transform(x_test)\n",
    "\n",
    "x_train = np.copy(x_train_scaled)\n",
    "x_val = np.copy(x_val_scaled)\n",
    "x_test = np.copy(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c60690a5-b586-45e9-94db-5b05891a57c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-19 10:24:40.264789: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "model = joblib.load(\"/home/jovyan/WUSTL-IIoT/dl/dl_new/dnn.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cba24094-105e-47f0-9697-1fee2cfc6e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e4f59b3-1c4d-4e09-bd63-cc1d79c7c8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_trimmed = np.concatenate((x_test[55500:55600], x_test[59200:59300]))\n",
    "y_test_trimmed = np.concatenate((y_test[55500:55600], y_test[59200:59300]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd191d50-f6b3-48c7-903e-484272593fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test_trimmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2ed84a1-cf8e-451a-a7b0-4b69421a7280",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = TensorFlowV2Classifier(\n",
    "    model=model,\n",
    "    nb_classes=5,\n",
    "    input_shape=(48,),\n",
    "    loss_object=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbb5e541-db10-4cee-9749-66c672f53e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EAD:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EAD: 100%|██████████| 200/200 [46:24<00:00, 13.92s/it]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Elastic Net attack\n",
    "attack = ElasticNet(classifier=classifier, learning_rate=0.001)\n",
    "\n",
    "# Generate adversarial test examples\n",
    "x_test_adv = attack.generate(x=x_test_trimmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d55125b-1b1a-41ba-a8ca-ebed7fbf0c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 953us/step\n",
      "Accuracy: 0.995\n",
      "AUC: 1.0\n",
      "\n",
      "macro\n",
      "Precision: 0.9\n",
      "Recall: 0.9875\n",
      "F1 Score: 0.9268817204301076\n",
      "\n",
      "weighted\n",
      "Precision: 0.9975\n",
      "Recall: 0.995\n",
      "F1 Score: 0.995752688172043\n",
      "\n",
      "Mean FNR: 0.0125\n",
      "Mean TNR: 0.9989949748743718\n",
      "Mean FPR: 0.0010050251256281408\n",
      "Mean TPR: 0.9875\n"
     ]
    }
   ],
   "source": [
    "calculate_performance_metrics(x_test_adv, y_test_trimmed, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21797adb-a5c9-4df5-95d3-de1e70a76d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EAD: 100%|██████████| 200/200 [46:33<00:00, 13.97s/it]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Elastic Net attack\n",
    "attack = ElasticNet(classifier=classifier, learning_rate=0.01)\n",
    "\n",
    "# Generate adversarial test examples\n",
    "x_test_adv = attack.generate(x=x_test_trimmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5146d16-5f6d-4c7f-a2e6-1b5541bf6aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 848us/step\n",
      "Accuracy: 0.98\n",
      "AUC: 1.0\n",
      "\n",
      "macro\n",
      "Precision: 0.75\n",
      "Recall: 0.95\n",
      "F1 Score: 0.7847619047619048\n",
      "\n",
      "weighted\n",
      "Precision: 0.99375\n",
      "Recall: 0.98\n",
      "F1 Score: 0.983904761904762\n",
      "\n",
      "Mean FNR: 0.05\n",
      "Mean TNR: 0.9959798994974876\n",
      "Mean FPR: 0.004020100502512563\n",
      "Mean TPR: 0.95\n"
     ]
    }
   ],
   "source": [
    "calculate_performance_metrics(x_test_adv, y_test_trimmed, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d6855a3-c4ba-4e7c-b2ba-9c0f76e58a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EAD: 100%|██████████| 200/200 [46:48<00:00, 14.04s/it]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Elastic Net attack\n",
    "attack = ElasticNet(classifier=classifier, learning_rate=0.1)\n",
    "\n",
    "# Generate adversarial test examples\n",
    "x_test_adv = attack.generate(x=x_test_trimmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78b5344b-7824-4d3c-8b1f-5bee0dee3f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 841us/step\n",
      "Accuracy: 0.975\n",
      "AUC: 0.9959798994974876\n",
      "\n",
      "macro\n",
      "Precision: 0.7166666666666666\n",
      "Recall: 0.75\n",
      "F1 Score: 0.5514285714285714\n",
      "\n",
      "weighted\n",
      "Precision: 0.9929166666666667\n",
      "Recall: 0.975\n",
      "F1 Score: 0.9780714285714285\n",
      "\n",
      "Mean FNR: 0.25\n",
      "Mean TNR: 0.9949748743718594\n",
      "Mean FPR: 0.005025125628140703\n",
      "Mean TPR: 0.75\n"
     ]
    }
   ],
   "source": [
    "calculate_performance_metrics(x_test_adv, y_test_trimmed, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d10c144-f60a-476b-bac8-df0e8f275032",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
