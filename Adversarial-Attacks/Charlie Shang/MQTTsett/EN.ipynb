{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58e43be8-d148-4609-afd7-d9b5637990d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "from art.attacks.evasion import ElasticNet\n",
    "from art.estimators.classification import TensorFlowV2Classifier\n",
    "from art.utils import load_dataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import metrics\n",
    "from warnings import simplefilter\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d506faab-3df5-4d17-bb75-f7c9cceedaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_performance_metrics(x_test, y_test, model):\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    report = metrics.classification_report(y_test, y_pred_classes, output_dict=True, zero_division=1)\n",
    "    \n",
    "    precision_macro = report['macro avg']['precision']\n",
    "    precision_weighted = report['weighted avg']['precision']\n",
    "    accuracy = report['accuracy']\n",
    "    recall_macro = report['macro avg']['recall']\n",
    "    recall_weighted = report['weighted avg']['recall']\n",
    "    f1_macro = report['macro avg']['f1-score']\n",
    "    f1_weighted = report['weighted avg']['f1-score']\n",
    "    auc = metrics.roc_auc_score(y_test, y_pred, multi_class='ovr')\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}\\nAUC: {auc}\")\n",
    "    \n",
    "    print(\"\\nmacro\")\n",
    "    print(f\"Precision: {precision_macro}\\nRecall: {recall_macro}\\nF1 Score: {f1_macro}\")\n",
    "\n",
    "    print(\"\\nweighted\")\n",
    "    print(f\"Precision: {precision_weighted}\\nRecall: {recall_weighted}\\nF1 Score: {f1_weighted}\")\n",
    "    print()\n",
    "    \n",
    "    # Confusion matrix for FNR, TNR, FPR, TPR\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred_classes)\n",
    "    def calculate_rates(conf_matrix, class_index):\n",
    "        tp = conf_matrix[class_index, class_index]\n",
    "        fn = np.sum(conf_matrix[class_index, :]) - tp\n",
    "        fp = np.sum(conf_matrix[:, class_index]) - tp\n",
    "        tn = np.sum(conf_matrix) - (tp + fn + fp)\n",
    "    \n",
    "        fnr = fn / (fn + tp)\n",
    "        tnr = tn / (tn + fp)\n",
    "        fpr = fp / (fp + tn)\n",
    "        tpr = tp / (tp + fn)\n",
    "        return fnr, tnr, fpr, tpr\n",
    "\n",
    "    # Calculate and aggregate rates\n",
    "    fnrs, tnrs, fprs, tprs = [], [], [], []\n",
    "    for i in range(cm.shape[0]):\n",
    "        fnr, tnr, fpr, tpr = calculate_rates(cm, i)\n",
    "        fnrs.append(fnr)\n",
    "        tnrs.append(tnr)\n",
    "        fprs.append(fpr)\n",
    "        tprs.append(tpr)\n",
    "    \n",
    "    mean_fnr = np.mean(fnrs)\n",
    "    mean_tnr = np.mean(tnrs)\n",
    "    mean_fpr = np.mean(fprs)\n",
    "    mean_tpr = np.mean(tprs)\n",
    "\n",
    "    # Printing the mean metrics\n",
    "    print(f\"Mean FNR: {mean_fnr}\\nMean TNR: {mean_tnr}\\nMean FPR: {mean_fpr}\\nMean TPR: {mean_tpr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77d8bb17-ccc8-4faf-b071-99597089c90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to generate train and test datasets\n"
     ]
    }
   ],
   "source": [
    "#with two dataset splitted\n",
    "dftrain = pd.read_csv(\"/home/jovyan/MQTTset/train70_reduced.csv\") \n",
    "dftest = pd.read_csv(\"/home/jovyan/MQTTset/test30_reduced.csv\")\n",
    "\n",
    "# dftrain = pd.read_csv(\"train70.csv\", low_memory=False) \n",
    "# dftest = pd.read_csv(\"test30.csv\", low_memory=False)\n",
    "\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "seed = 7\n",
    "\n",
    "#train\n",
    "#print(dftrain.loc[dftrain['target'] == 'legitimate'])\n",
    "class_names = dftrain.target.unique()\n",
    "dftrain=dftrain.astype('category')\n",
    "cat_columns = dftrain.select_dtypes(['category']).columns\n",
    "dftrain[cat_columns] = dftrain[cat_columns].apply(lambda x: x.cat.codes)\n",
    "#print(dftrain.loc[125, 'target'])\n",
    "x_columns = dftrain.columns.drop('target')\n",
    "x_train = dftrain[x_columns].values\n",
    "y_train = dftrain['target']\n",
    "\n",
    "#test\n",
    "class_names = dftest.target.unique()\n",
    "dftest=dftest.astype('category')\n",
    "cat_columns = dftest.select_dtypes(['category']).columns\n",
    "dftest[cat_columns] = dftest[cat_columns].apply(lambda x: x.cat.codes)\n",
    "x_columns = dftest.columns.drop('target')\n",
    "x_test = dftest[x_columns].values\n",
    "y_test = dftest['target']\n",
    "\n",
    "print(\"Ready to generate train and test datasets\")\n",
    "\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "x_train = np.copy(x_train_scaled)\n",
    "x_test = np.copy(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c60690a5-b586-45e9-94db-5b05891a57c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-19 23:20:01.320279: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-02-19 23:20:01.523793: W tensorflow/core/util/tensor_slice_reader.cc:98] Could not open ram://b35343580839493590fefcba8141b90a: INVALID_ARGUMENT: ram://b35343580839493590fefcba8141b90a is a directory.\n"
     ]
    }
   ],
   "source": [
    "model = joblib.load(\"/home/jovyan/MQTTset/dl/new_dl/dnn.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cba24094-105e-47f0-9697-1fee2cfc6e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5], dtype=int8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4e4f59b3-1c4d-4e09-bd63-cc1d79c7c8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_trimmed = x_test[1400:1700]\n",
    "y_test_trimmed = y_test[1400:1700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd191d50-f6b3-48c7-903e-484272593fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5], dtype=int8)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test_trimmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a2ed84a1-cf8e-451a-a7b0-4b69421a7280",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = TensorFlowV2Classifier(\n",
    "    model=model,\n",
    "    nb_classes=6,\n",
    "    input_shape=(33,),\n",
    "    loss_object=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dbb5e541-db10-4cee-9749-66c672f53e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EAD:   0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EAD: 100%|██████████| 300/300 [1:01:58<00:00, 12.39s/it]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Elastic Net attack\n",
    "attack = ElasticNet(classifier=classifier, learning_rate=0.001)\n",
    "\n",
    "# Generate adversarial test examples\n",
    "x_test_adv = attack.generate(x=x_test_trimmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3d55125b-1b1a-41ba-a8ca-ebed7fbf0c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 950us/step\n",
      "Accuracy: 0.6066666666666667\n",
      "AUC: 0.8657284346551569\n",
      "\n",
      "macro\n",
      "Precision: 0.3200356983489514\n",
      "Recall: 0.2758200133200133\n",
      "F1 Score: 0.2733400071027995\n",
      "\n",
      "weighted\n",
      "Precision: 0.6908777331548417\n",
      "Recall: 0.6066666666666667\n",
      "F1 Score: 0.6210135290083898\n",
      "\n",
      "Mean FNR: 0.7241799866799866\n",
      "Mean TNR: 0.9034318261668149\n",
      "Mean FPR: 0.09656817383318506\n",
      "Mean TPR: 0.2758200133200133\n"
     ]
    }
   ],
   "source": [
    "calculate_performance_metrics(x_test_adv, y_test_trimmed, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "21797adb-a5c9-4df5-95d3-de1e70a76d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EAD: 100%|██████████| 300/300 [1:02:10<00:00, 12.43s/it]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Elastic Net attack\n",
    "attack = ElasticNet(classifier=classifier, learning_rate=0.01)\n",
    "\n",
    "# Generate adversarial test examples\n",
    "x_test_adv = attack.generate(x=x_test_trimmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f5146d16-5f6d-4c7f-a2e6-1b5541bf6aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 803us/step\n",
      "Accuracy: 0.5133333333333333\n",
      "AUC: 0.8331955591597183\n",
      "\n",
      "macro\n",
      "Precision: 0.2811751452598681\n",
      "Recall: 0.2703171828171828\n",
      "F1 Score: 0.24392884853498062\n",
      "\n",
      "weighted\n",
      "Precision: 0.6461550994529833\n",
      "Recall: 0.5133333333333333\n",
      "F1 Score: 0.5232798010531319\n",
      "\n",
      "Mean FNR: 0.7296828171828172\n",
      "Mean TNR: 0.8870445289725196\n",
      "Mean FPR: 0.11295547102748027\n",
      "Mean TPR: 0.2703171828171828\n"
     ]
    }
   ],
   "source": [
    "calculate_performance_metrics(x_test_adv, y_test_trimmed, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3d6855a3-c4ba-4e7c-b2ba-9c0f76e58a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EAD: 100%|██████████| 300/300 [1:02:06<00:00, 12.42s/it]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Elastic Net attack\n",
    "attack = ElasticNet(classifier=classifier, learning_rate=0.1)\n",
    "\n",
    "# Generate adversarial test examples\n",
    "x_test_adv = attack.generate(x=x_test_trimmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "78b5344b-7824-4d3c-8b1f-5bee0dee3f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 800us/step\n",
      "Accuracy: 0.46\n",
      "AUC: 0.8072666183181925\n",
      "\n",
      "macro\n",
      "Precision: 0.27217221576977674\n",
      "Recall: 0.25136113886113887\n",
      "F1 Score: 0.2245271593485879\n",
      "\n",
      "weighted\n",
      "Precision: 0.5999625758162345\n",
      "Recall: 0.46\n",
      "F1 Score: 0.4579410688517831\n",
      "\n",
      "Mean FNR: 0.7486388611388611\n",
      "Mean TNR: 0.8791804430508411\n",
      "Mean FPR: 0.12081955694915893\n",
      "Mean TPR: 0.25136113886113887\n"
     ]
    }
   ],
   "source": [
    "calculate_performance_metrics(x_test_adv, y_test_trimmed, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d10c144-f60a-476b-bac8-df0e8f275032",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
